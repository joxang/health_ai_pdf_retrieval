{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import wget\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa6c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from random import randint\n",
    "from random import sample\n",
    "from time import sleep\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14282182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206e1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173ed37",
   "metadata": {},
   "source": [
    "# extract doi list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f084113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_abstracts = pd.read_csv('data/included_abstracts.csv', index_col = 0)\n",
    "#len(all_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2279407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_abstracts['article_date'] = pd.to_datetime(all_abstracts['article_date'])\n",
    "#decade_df = all_abstracts[(all_abstracts['article_date'] > '2012-01-01') & (all_abstracts['article_date'] <'2022-01-01')]\n",
    "#len(decade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ec0f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decade_df.sort_values(by='article_date',  ascending=False, inplace=True)\n",
    "#decade_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f92df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieval_1 = pd.read_csv('output/failed_link_retrieval.csv', index_col = 0)\n",
    "retrieval_2 = pd.read_csv('output/no_links_for_open_access.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643a6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra_df = pd.concat([retrieval_1, retrieval_2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b2090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape_df = extra_df[['pmid', 'doi']].copy()\n",
    "scrape_df = retrieval_2[['pmid', 'doi']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf007002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8377 entries, 4 to 28700\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   pmid    8377 non-null   int64 \n",
      " 1   doi     8377 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 196.3+ KB\n"
     ]
    }
   ],
   "source": [
    "doi_df = scrape_df[~scrape_df['doi'].isnull()]\n",
    "doi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e11db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = dict(zip(doi_df['pmid'], doi_df['doi']))\n",
    "pmid_list = doi_df['pmid'].tolist()\n",
    "doi_list = doi_df['doi'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a9d5c",
   "metadata": {},
   "source": [
    "# create urls for dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7e9e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8377"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = []\n",
    "\n",
    "for doi in doi_list:\n",
    "    link = \"https://doi.org/{}\".format(doi)\n",
    "    url_list.append(link)\n",
    "\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf48140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for manual download!\n",
    "#url_df = pd.DataFrame(url_list, columns=['url'])\n",
    "#url_df.to_csv('output/manual_url_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569704da",
   "metadata": {},
   "source": [
    "# get re-direct urls into new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22e399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = url_list[1000:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a5fc78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79cecf026d349f98e3b9224b6f42410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://link.springer.com/article/10.1007/s00330-021-08250-9\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006223?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s00330-021-08242-9\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S138614252100932X?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1386505621001957?via%3Dihub\n",
      "https://www.giejournal.org/article/S0016-5107(21)01613-8/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004697?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165027021002880?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s00330-021-08239-4\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006235?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/jmri.27909\n",
      "https://ieeexplore.ieee.org/document/9372756\n",
      "https://ieeexplore.ieee.org/document/9130029\n",
      "https://ieeexplore.ieee.org/document/9376950\n",
      "https://ieeexplore.ieee.org/document/9364366\n",
      "https://ieeexplore.ieee.org/document/9390181\n",
      "https://www.nature.com/articles/s41440-021-00738-7\n",
      "https://www.sciencedirect.com/science/article/pii/S0933365721001561?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0925492721001384?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s00330-021-08228-7\n",
      "https://ieeexplore.ieee.org/document/9383834\n",
      "https://link.springer.com/article/10.1007/s00256-021-03897-3\n",
      "https://ieeexplore.ieee.org/document/9416736\n",
      "https://nyaspubs.onlinelibrary.wiley.com/doi/epdf/10.1111/nyas.14685\n",
      "https://ieeexplore.ieee.org/document/9394717\n",
      "https://ieeexplore.ieee.org/document/9529036\n",
      "https://ieeexplore.ieee.org/document/9380678\n",
      "https://link.springer.com/article/10.1007/s11548-021-02488-w\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006193?via%3Dihub\n",
      "https://ieeexplore.ieee.org/document/9440825\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1361841521002693?via%3Dihub\n",
      "https://www.thespinejournalonline.com/article/S1529-9430(21)00879-2/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006181?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006211?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165032721009320?via%3Dihub\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15178\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165032721008958?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S2451902221002329?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s13246-021-01052-9\n",
      "https://ieeexplore.ieee.org/document/9527115\n",
      "https://link.springer.com/article/10.1007/s11548-021-02477-z\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S138650562100191X?via%3Dihub\n",
      "https://www.ajronline.org/doi/10.2214/AJR.20.23490\n",
      "https://www.nature.com/articles/s41416-021-01506-7\n",
      "https://www.ejog.org/article/S0301-2115(21)00442-5/fulltext\n",
      "https://pubs.rsna.org/doi/10.1148/radiol.2021210578\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004405?via%3Dihub\n",
      "https://ieeexplore.ieee.org/document/9411868\n",
      "https://www.ejoncologynursing.com/article/S1462-3889(21)00129-0/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004429?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/adma.202104178\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/jgh.15673\n",
      "https://www.birpublications.org/doi/10.1259/bjr.20210259\n",
      "https://aacrjournals.org/clincancerres/article-abstract/27/22/6135/671770/EpiPanGI-Dx-A-Cell-free-DNA-Methylation?redirectedFrom=fulltext\n",
      "https://link.springer.com/article/10.1007/s00261-021-03235-0\n",
      "https://validate.perfdrive.com/?ssa=3f8333dc-3cbd-4dec-8811-0b9e8b48a508&ssb=18101261242&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1ed0&ssi=cbf2ca6e-8427-4c6d-971a-18ef059c57cc&ssk=support@shieldsquare.com&ssm=46154787311235257102804715207452&ssn=5405959bc6f6d9be3beca3c80e7e8afffbb37b8f5df8-5cee-4130-8a6836&sso=a49dd55b-09d8a6de9691ba4401caecc7c2d4cbb31a8ca8377b0c7e7f&ssp=19424077341654657133165468323174727&ssq=40411474034142678399440341370508334497774&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://ieeexplore.ieee.org/document/9425559\n",
      "https://ieeexplore.ieee.org/document/9420726\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165027021002818?via%3Dihub\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15172\n",
      "https://journals.sagepub.com/doi/10.1177/17085381211040984\n",
      "https://link.springer.com/article/10.1007/s11136-021-02970-7\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15181\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0303846721004480?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004569?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/jmri.27900\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004533?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006065?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004491?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S001048252100593X?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1871402121002836?via%3Dihub\n",
      "https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00468-6/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004557?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/pii/S0933365721001548?via%3Dihub\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15174\n",
      "https://www.onlinecjc.ca/article/S0828-282X(21)00659-0/fulltext\n",
      "https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00500-X/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1078143921003665?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521006089?via%3Dihub\n",
      "https://www.tandfonline.com/doi/full/10.1080/00207454.2021.1941947\n",
      "https://www.eurekaselect.com/article/117534\n",
      "https://link.springer.com/article/10.1007/s00330-021-08221-0\n",
      "https://www.resuscitationjournal.com/article/S0300-9572(21)00333-6/fulltext\n",
      "https://bmccancer.biomedcentral.com/articles/10.1186/s12885-021-08704-9\n",
      "https://validate.perfdrive.com/?ssa=50502f3a-dffd-4ef9-b010-64346e039daf&ssb=56105231346&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6579%2Fac184e&ssi=e6471a4f-8427-4754-ab7a-38f680c7f458&ssk=support@shieldsquare.com&ssm=32078202098975042107974947038881&ssn=26c7dd82d4f89628048892a5d70ae684e8ef1d332310-57c3-4b82-a9dbf7&sso=b0c2fc2f-e4e373fd65e5a966c85036e1e3f22412bacee715d10e0076&ssp=92232513641654643336165461828140607&ssq=42074364046851920488340468984278494925012&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1386505621001891?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165027021002740?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/epdf/10.1111/1475-6773.13871\n",
      "https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/epdf/10.1002/jemt.23908\n",
      "https://validate.perfdrive.com/?ssa=2e133701-20fa-4529-a302-0364e76f8e21&ssb=04661234220&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1d36&ssi=b5b957b8-8427-4b90-b822-5b2b46a6efdd&ssk=support@shieldsquare.com&ssm=45382700939867122107236885042995&ssn=964bcc142642df74dcad7b1ad11a3f9debc34c467671-9f21-4fb8-b979c8&sso=dd2dc7d1-9f0cc8fc36268b82cf5cebf0a2cab5bc3fc225652e08aeba&ssp=82656349751654656555165463230665211&ssq=87326914048710028483940487709017607361979&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165032721008387?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s11548-021-02478-y\n",
      "https://academic.oup.com/biostatistics/advance-article-abstract/doi/10.1093/biostatistics/kxab032/6357844?redirectedFrom=fulltext\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sciencedirect.com/science/article/abs/pii/S138650562100188X?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/acr.24601\n",
      "https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00456-X/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005990?via%3Dihub\n",
      "https://validate.perfdrive.com/?ssa=d144739f-08e6-4e7d-b91b-c2851e0f3e21&ssb=98942260819&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac1835&ssi=a5295086-8427-4e7d-9b2e-030f6bdbe5d1&ssk=support@shieldsquare.com&ssm=52171643032669235101160801513041&ssn=e6f513238f397f4730285797cab24b0f2eb7c94a5ad8-feee-4715-9c863f&sso=c8e7d2bc-2ca56983abcd48093b1575c56d4eaee5d31ab309364405cc&ssp=84199571931654663847165465591220398&ssq=18279824051545996898540515134579869054714&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://link.springer.com/article/10.1007/s12021-021-09535-6\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004326?via%3Dihub\n",
      "https://www.clinicalimaging.org/article/S0899-7071(21)00343-0/fulltext\n",
      "https://link.springer.com/article/10.1007/s11684-021-0828-7\n",
      "https://www.eurekaselect.com/article/117514\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005886?via%3Dihub\n",
      "https://www.liebertpub.com/doi/10.1089/thy.2021.0209\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005837?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s11548-021-02480-4\n",
      "https://validate.perfdrive.com/?ssa=8f1416fc-385f-45fc-a0c9-c52c52fb8f22&ssb=79030210388&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1ade&ssi=309c014b-8427-45fb-8941-c49ac780d447&ssk=support@shieldsquare.com&ssm=98977740076072175108250509853148&ssn=620ba6b4eca22ff3e28c7ac71af072f6348d402b5d1f-dcc6-4aea-8c08fa&sso=aaeb0503-c938385d0bca00dca3ab75604ce8088f5d94a809452b7440&ssp=40872017451654648915165466132358819&ssq=89477374055047317581540550617102850471551&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15079\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005941?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/jum.15816\n",
      "https://onlinelibrary.wiley.com/doi/epdf/10.1111/jcap.12346\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S2405500X21005922?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005898?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1361841521002632?via%3Dihub\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15155\n",
      "https://link.springer.com/article/10.1007/s00330-021-08195-z\n",
      "https://journals.sagepub.com/doi/10.1177/00220345211035775\n",
      "https://www.clinicalnutritionjournal.com/article/S0261-5614(21)00393-9/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165032721008260?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005709?via%3Dihub\n",
      "https://validate.perfdrive.com/?ssa=9e97bd0d-1d39-4806-891f-22d15ac15d25&ssb=02714277962&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac195a&ssi=7fb57b0a-8427-4756-8569-561306487fe1&ssk=support@shieldsquare.com&ssm=27441655144999908100776498379834&ssn=f4e26177d0df1877ed138993e42cef428e18c16a6c6e-6970-481e-8a66d1&sso=8f0313a2-fe0baec0bad142b75b04265fbc23a8a771e299827984f488&ssp=64397162601654690169165462137259031&ssq=42052984059972251407640599876764057987624&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005771?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005849?via%3Dihub\n",
      "https://jnis.bmj.com/content/early/2021/08/22/neurintsurg-2021-017858\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0009912021002265?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165032721008259?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/jbio.202100142\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/jum.15812\n",
      "https://validate.perfdrive.com/?ssa=bac52e03-0c4c-4143-a11e-6e509a0c4ab5&ssb=10519296702&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac16ec&ssi=62a46962-8427-4b3d-b3c3-b442e2025b25&ssk=support@shieldsquare.com&ssm=45376859206599561105264206579912&ssn=7a08e5eba12806df77b17669faf3e87cba562b42bb5d-acc9-4659-b2b508&sso=639081a7-178a38a3ca6d6cc83c5e04676e4bc0ca939c468270330d56&ssp=48402620921654629160165466247239638&ssq=33718754062600106377540626839164155437854&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://www.resuscitationjournal.com/article/S0300-9572(21)00324-5/fulltext\n",
      "https://journals.sagepub.com/doi/10.1177/15500594211036788\n",
      "https://link.springer.com/article/10.1007/s11517-021-02396-w\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0169260721004430?via%3Dihub\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15122\n",
      "https://link.springer.com/article/10.1007/s11682-021-00511-x\n",
      "https://link.springer.com/article/10.1007/s00330-021-08237-6\n",
      "https://link.springer.com/article/10.1007/s11517-021-02415-w\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1386142521008775?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0165027021002697?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S001048252100576X?via%3Dihub\n",
      "https://www.oooojournal.net/article/S2212-4403(21)00585-X/fulltext\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1350453321000965?via%3Dihub\n",
      "https://www.physicamedica.com/article/S1120-1797(21)00291-X/fulltext\n",
      "https://link.springer.com/article/10.1007/s12028-021-01325-x\n",
      "https://obgyn.onlinelibrary.wiley.com/doi/10.1002/ijgo.13888\n",
      "https://www.onlinecjc.ca/article/S0828-282X(21)00648-6/fulltext\n",
      "https://jnis.bmj.com/content/early/2021/08/19/neurintsurg-2021-017714\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0893608021003245?via%3Dihub\n",
      "https://journals.sagepub.com/doi/10.1177/01617346211035315\n",
      "https://link.springer.com/article/10.1007/s12539-021-00470-3\n",
      "https://journals.lww.com/jcrs/Abstract/2022/05000/Lens_Opacities_Classification_System_III_based.3.aspx\n",
      "https://www.internationaljournalofcardiology.com/article/S0167-5273(21)01238-9/fulltext\n",
      "https://doi.apa.org/doiLanding?doi=10.1037/fam0000906\n",
      "https://www.tandfonline.com/doi/full/10.1080/23279095.2021.1962881\n",
      "https://validate.perfdrive.com/?ssa=59e231b0-6ff3-4d6d-9dcc-c4e74fed5f39&ssb=07142206373&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac16e8&ssi=69c1da01-8427-4aec-8802-ab9a0494c397&ssk=support@shieldsquare.com&ssm=94565371019293272109928471312740&ssn=440b9bcf16a8f75ff2302def7a465b0ce71129c45cc6-823f-4110-bbfef4&sso=9efef146-91450a7c5be63aabeb9cb7ad20c4ef985327466752b3ce79&ssp=60680548391654664334165460034816405&ssq=24042784075267967004940752083205819416549&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15136\n",
      "https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-8/issue-4/044502/Lung-nodule-malignancy-classification-with-weakly-supervised-explanation-generation/10.1117/1.JMI.8.4.044502.short?SSO=1\n",
      "https://journals.sagepub.com/doi/10.1177/15353702211031547\n",
      "https://ascopubs.org/doi/10.1200/JCO.20.02810\n",
      "https://link.springer.com/10.1007/s00384-021-04006-5\n",
      "https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15146\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005643?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1424390321005275?via%3Dihub\n",
      "https://link.springer.com/article/10.1007/s00256-021-03893-7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://journals.lww.com/jcrs/Abstract/2022/04000/New_polynomial_regression_formula_to_improve.8.aspx\n",
      "https://validate.perfdrive.com/?ssa=b06407dd-f2e7-4ff9-a919-933a8a4b0e59&ssb=36685228897&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F2057-1976%2Fac1c51&ssi=8d8c54df-8427-4280-b2a6-8a24627f577b&ssk=support@shieldsquare.com&ssm=98677289669768972102333419397246&ssn=e408eec0579fe0193c8b869279d7c80344e5a4e383fc-a0fd-4f75-9173d6&sso=328473ce-7caddcfd31f7becdb9e68a9f1ead4956539734e0b6110cbf&ssp=09143808141654651100165469281395120&ssq=08489314080607349578540806364623598312405&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=\n",
      "https://www.ajronline.org/doi/10.2214/AJR.21.26486\n",
      "https://www.clinicalnutritionjournal.com/article/S0261-5614(21)00374-5/fulltext\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/ccd.29917\n",
      "https://pubs.rsna.org/doi/10.1148/radiol.2021204183\n",
      "https://www.tandfonline.com/doi/full/10.1080/14767058.2021.1963704\n",
      "https://link.springer.com/article/10.1007/s10620-021-07217-6\n",
      "https://www.karger.com/Article/Abstract/517674\n",
      "https://www.arthroscopyjournal.org/article/S0749-8063(21)00742-8/fulltext\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/ocr.12514\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/jop.13227\n",
      "https://link.springer.com/article/10.1007/s13246-021-01046-7\n",
      "https://onlinelibrary.wiley.com/doi/10.1111/jgh.15642\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S153204642100201X?via%3Dihub\n",
      "https://onlinelibrary.wiley.com/doi/10.1002/adma.202103999\n",
      "https://pubs.rsc.org/en/content/articlelanding/2021/TB/D1TB01237A\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S1532046421002185?via%3Dihub\n",
      "https://www.sciencedirect.com/science/article/abs/pii/S0010482521005412?via%3Dihub\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     link \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mcurrent_url\n\u001b[1;32m     10\u001b[0m     driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    425\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m    427\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 428\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:347\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[1;32m    346\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:369\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    366\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/poolmanager.py:375\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    373\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/scraper/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrape_list = []\n",
    "\n",
    "for url in tqdm(url_list):\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        link = driver.current_url\n",
    "        driver.quit()\n",
    "        \n",
    "        print(link)\n",
    "        scrape_list.append(link)\n",
    "        \n",
    "    except Exception:\n",
    "        scrape_list.append(\"error\")\n",
    "        print(\"error\")\n",
    "        pass\n",
    "    \n",
    "len(scrape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e54d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://link.springer.com/article/10.1007/s00330-021-08250-9',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006223?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08242-9',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S138614252100932X?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1386505621001957?via%3Dihub',\n",
       " 'https://www.giejournal.org/article/S0016-5107(21)01613-8/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004697?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165027021002880?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08239-4',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006235?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/jmri.27909',\n",
       " 'https://ieeexplore.ieee.org/document/9372756',\n",
       " 'https://ieeexplore.ieee.org/document/9130029',\n",
       " 'https://ieeexplore.ieee.org/document/9376950',\n",
       " 'https://ieeexplore.ieee.org/document/9364366',\n",
       " 'https://ieeexplore.ieee.org/document/9390181',\n",
       " 'https://www.nature.com/articles/s41440-021-00738-7',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0933365721001561?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0925492721001384?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08228-7',\n",
       " 'https://ieeexplore.ieee.org/document/9383834',\n",
       " 'https://link.springer.com/article/10.1007/s00256-021-03897-3',\n",
       " 'https://ieeexplore.ieee.org/document/9416736',\n",
       " 'https://nyaspubs.onlinelibrary.wiley.com/doi/epdf/10.1111/nyas.14685',\n",
       " 'https://ieeexplore.ieee.org/document/9394717',\n",
       " 'https://ieeexplore.ieee.org/document/9529036',\n",
       " 'https://ieeexplore.ieee.org/document/9380678',\n",
       " 'https://link.springer.com/article/10.1007/s11548-021-02488-w',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006193?via%3Dihub',\n",
       " 'https://ieeexplore.ieee.org/document/9440825',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1361841521002693?via%3Dihub',\n",
       " 'https://www.thespinejournalonline.com/article/S1529-9430(21)00879-2/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006181?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006211?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165032721009320?via%3Dihub',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15178',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165032721008958?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S2451902221002329?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s13246-021-01052-9',\n",
       " 'https://ieeexplore.ieee.org/document/9527115',\n",
       " 'https://link.springer.com/article/10.1007/s11548-021-02477-z',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S138650562100191X?via%3Dihub',\n",
       " 'https://www.ajronline.org/doi/10.2214/AJR.20.23490',\n",
       " 'https://www.nature.com/articles/s41416-021-01506-7',\n",
       " 'https://www.ejog.org/article/S0301-2115(21)00442-5/fulltext',\n",
       " 'https://pubs.rsna.org/doi/10.1148/radiol.2021210578',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004405?via%3Dihub',\n",
       " 'https://ieeexplore.ieee.org/document/9411868',\n",
       " 'https://www.ejoncologynursing.com/article/S1462-3889(21)00129-0/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004429?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/adma.202104178',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1111/jgh.15673',\n",
       " 'https://www.birpublications.org/doi/10.1259/bjr.20210259',\n",
       " 'https://aacrjournals.org/clincancerres/article-abstract/27/22/6135/671770/EpiPanGI-Dx-A-Cell-free-DNA-Methylation?redirectedFrom=fulltext',\n",
       " 'https://link.springer.com/article/10.1007/s00261-021-03235-0',\n",
       " 'https://validate.perfdrive.com/?ssa=3f8333dc-3cbd-4dec-8811-0b9e8b48a508&ssb=18101261242&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1ed0&ssi=cbf2ca6e-8427-4c6d-971a-18ef059c57cc&ssk=support@shieldsquare.com&ssm=46154787311235257102804715207452&ssn=5405959bc6f6d9be3beca3c80e7e8afffbb37b8f5df8-5cee-4130-8a6836&sso=a49dd55b-09d8a6de9691ba4401caecc7c2d4cbb31a8ca8377b0c7e7f&ssp=19424077341654657133165468323174727&ssq=40411474034142678399440341370508334497774&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://ieeexplore.ieee.org/document/9425559',\n",
       " 'https://ieeexplore.ieee.org/document/9420726',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165027021002818?via%3Dihub',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15172',\n",
       " 'https://journals.sagepub.com/doi/10.1177/17085381211040984',\n",
       " 'https://link.springer.com/article/10.1007/s11136-021-02970-7',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15181',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0303846721004480?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004569?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/jmri.27900',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004533?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006065?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004491?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S001048252100593X?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1871402121002836?via%3Dihub',\n",
       " 'https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00468-6/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004557?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0933365721001548?via%3Dihub',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15174',\n",
       " 'https://www.onlinecjc.ca/article/S0828-282X(21)00659-0/fulltext',\n",
       " 'https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00500-X/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1078143921003665?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521006089?via%3Dihub',\n",
       " 'https://www.tandfonline.com/doi/full/10.1080/00207454.2021.1941947',\n",
       " 'https://www.eurekaselect.com/article/117534',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08221-0',\n",
       " 'https://www.resuscitationjournal.com/article/S0300-9572(21)00333-6/fulltext',\n",
       " 'https://bmccancer.biomedcentral.com/articles/10.1186/s12885-021-08704-9',\n",
       " 'https://validate.perfdrive.com/?ssa=50502f3a-dffd-4ef9-b010-64346e039daf&ssb=56105231346&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6579%2Fac184e&ssi=e6471a4f-8427-4754-ab7a-38f680c7f458&ssk=support@shieldsquare.com&ssm=32078202098975042107974947038881&ssn=26c7dd82d4f89628048892a5d70ae684e8ef1d332310-57c3-4b82-a9dbf7&sso=b0c2fc2f-e4e373fd65e5a966c85036e1e3f22412bacee715d10e0076&ssp=92232513641654643336165461828140607&ssq=42074364046851920488340468984278494925012&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1386505621001891?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165027021002740?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/epdf/10.1111/1475-6773.13871',\n",
       " 'https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/epdf/10.1002/jemt.23908',\n",
       " 'https://validate.perfdrive.com/?ssa=2e133701-20fa-4529-a302-0364e76f8e21&ssb=04661234220&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1d36&ssi=b5b957b8-8427-4b90-b822-5b2b46a6efdd&ssk=support@shieldsquare.com&ssm=45382700939867122107236885042995&ssn=964bcc142642df74dcad7b1ad11a3f9debc34c467671-9f21-4fb8-b979c8&sso=dd2dc7d1-9f0cc8fc36268b82cf5cebf0a2cab5bc3fc225652e08aeba&ssp=82656349751654656555165463230665211&ssq=87326914048710028483940487709017607361979&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165032721008387?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s11548-021-02478-y',\n",
       " 'https://academic.oup.com/biostatistics/advance-article-abstract/doi/10.1093/biostatistics/kxab032/6357844?redirectedFrom=fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S138650562100188X?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/acr.24601',\n",
       " 'https://www.journalofsurgicalresearch.com/article/S0022-4804(21)00456-X/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005990?via%3Dihub',\n",
       " 'https://validate.perfdrive.com/?ssa=d144739f-08e6-4e7d-b91b-c2851e0f3e21&ssb=98942260819&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac1835&ssi=a5295086-8427-4e7d-9b2e-030f6bdbe5d1&ssk=support@shieldsquare.com&ssm=52171643032669235101160801513041&ssn=e6f513238f397f4730285797cab24b0f2eb7c94a5ad8-feee-4715-9c863f&sso=c8e7d2bc-2ca56983abcd48093b1575c56d4eaee5d31ab309364405cc&ssp=84199571931654663847165465591220398&ssq=18279824051545996898540515134579869054714&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://link.springer.com/article/10.1007/s12021-021-09535-6',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004326?via%3Dihub',\n",
       " 'https://www.clinicalimaging.org/article/S0899-7071(21)00343-0/fulltext',\n",
       " 'https://link.springer.com/article/10.1007/s11684-021-0828-7',\n",
       " 'https://www.eurekaselect.com/article/117514',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005886?via%3Dihub',\n",
       " 'https://www.liebertpub.com/doi/10.1089/thy.2021.0209',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005837?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s11548-021-02480-4',\n",
       " 'https://validate.perfdrive.com/?ssa=8f1416fc-385f-45fc-a0c9-c52c52fb8f22&ssb=79030210388&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1741-2552%2Fac1ade&ssi=309c014b-8427-45fb-8941-c49ac780d447&ssk=support@shieldsquare.com&ssm=98977740076072175108250509853148&ssn=620ba6b4eca22ff3e28c7ac71af072f6348d402b5d1f-dcc6-4aea-8c08fa&sso=aaeb0503-c938385d0bca00dca3ab75604ce8088f5d94a809452b7440&ssp=40872017451654648915165466132358819&ssq=89477374055047317581540550617102850471551&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15079',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005941?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/jum.15816',\n",
       " 'https://onlinelibrary.wiley.com/doi/epdf/10.1111/jcap.12346',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S2405500X21005922?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005898?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1361841521002632?via%3Dihub',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15155',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08195-z',\n",
       " 'https://journals.sagepub.com/doi/10.1177/00220345211035775',\n",
       " 'https://www.clinicalnutritionjournal.com/article/S0261-5614(21)00393-9/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165032721008260?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005709?via%3Dihub',\n",
       " 'https://validate.perfdrive.com/?ssa=9e97bd0d-1d39-4806-891f-22d15ac15d25&ssb=02714277962&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac195a&ssi=7fb57b0a-8427-4756-8569-561306487fe1&ssk=support@shieldsquare.com&ssm=27441655144999908100776498379834&ssn=f4e26177d0df1877ed138993e42cef428e18c16a6c6e-6970-481e-8a66d1&sso=8f0313a2-fe0baec0bad142b75b04265fbc23a8a771e299827984f488&ssp=64397162601654690169165462137259031&ssq=42052984059972251407640599876764057987624&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005771?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005849?via%3Dihub',\n",
       " 'https://jnis.bmj.com/content/early/2021/08/22/neurintsurg-2021-017858',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0009912021002265?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165032721008259?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/jbio.202100142',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/jum.15812',\n",
       " 'https://validate.perfdrive.com/?ssa=bac52e03-0c4c-4143-a11e-6e509a0c4ab5&ssb=10519296702&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac16ec&ssi=62a46962-8427-4b3d-b3c3-b442e2025b25&ssk=support@shieldsquare.com&ssm=45376859206599561105264206579912&ssn=7a08e5eba12806df77b17669faf3e87cba562b42bb5d-acc9-4659-b2b508&sso=639081a7-178a38a3ca6d6cc83c5e04676e4bc0ca939c468270330d56&ssp=48402620921654629160165466247239638&ssq=33718754062600106377540626839164155437854&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://www.resuscitationjournal.com/article/S0300-9572(21)00324-5/fulltext',\n",
       " 'https://journals.sagepub.com/doi/10.1177/15500594211036788',\n",
       " 'https://link.springer.com/article/10.1007/s11517-021-02396-w',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0169260721004430?via%3Dihub',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15122',\n",
       " 'https://link.springer.com/article/10.1007/s11682-021-00511-x',\n",
       " 'https://link.springer.com/article/10.1007/s00330-021-08237-6',\n",
       " 'https://link.springer.com/article/10.1007/s11517-021-02415-w',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1386142521008775?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0165027021002697?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S001048252100576X?via%3Dihub',\n",
       " 'https://www.oooojournal.net/article/S2212-4403(21)00585-X/fulltext',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1350453321000965?via%3Dihub',\n",
       " 'https://www.physicamedica.com/article/S1120-1797(21)00291-X/fulltext',\n",
       " 'https://link.springer.com/article/10.1007/s12028-021-01325-x',\n",
       " 'https://obgyn.onlinelibrary.wiley.com/doi/10.1002/ijgo.13888',\n",
       " 'https://www.onlinecjc.ca/article/S0828-282X(21)00648-6/fulltext',\n",
       " 'https://jnis.bmj.com/content/early/2021/08/19/neurintsurg-2021-017714',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0893608021003245?via%3Dihub',\n",
       " 'https://journals.sagepub.com/doi/10.1177/01617346211035315',\n",
       " 'https://link.springer.com/article/10.1007/s12539-021-00470-3',\n",
       " 'https://journals.lww.com/jcrs/Abstract/2022/05000/Lens_Opacities_Classification_System_III_based.3.aspx',\n",
       " 'https://www.internationaljournalofcardiology.com/article/S0167-5273(21)01238-9/fulltext',\n",
       " 'https://doi.apa.org/doiLanding?doi=10.1037/fam0000906',\n",
       " 'https://www.tandfonline.com/doi/full/10.1080/23279095.2021.1962881',\n",
       " 'https://validate.perfdrive.com/?ssa=59e231b0-6ff3-4d6d-9dcc-c4e74fed5f39&ssb=07142206373&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F1361-6560%2Fac16e8&ssi=69c1da01-8427-4aec-8802-ab9a0494c397&ssk=support@shieldsquare.com&ssm=94565371019293272109928471312740&ssn=440b9bcf16a8f75ff2302def7a465b0ce71129c45cc6-823f-4110-bbfef4&sso=9efef146-91450a7c5be63aabeb9cb7ad20c4ef985327466752b3ce79&ssp=60680548391654664334165460034816405&ssq=24042784075267967004940752083205819416549&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15136',\n",
       " 'https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-8/issue-4/044502/Lung-nodule-malignancy-classification-with-weakly-supervised-explanation-generation/10.1117/1.JMI.8.4.044502.short?SSO=1',\n",
       " 'https://journals.sagepub.com/doi/10.1177/15353702211031547',\n",
       " 'https://ascopubs.org/doi/10.1200/JCO.20.02810',\n",
       " 'https://link.springer.com/10.1007/s00384-021-04006-5',\n",
       " 'https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.15146',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005643?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1424390321005275?via%3Dihub',\n",
       " 'https://link.springer.com/article/10.1007/s00256-021-03893-7',\n",
       " 'https://journals.lww.com/jcrs/Abstract/2022/04000/New_polynomial_regression_formula_to_improve.8.aspx',\n",
       " 'https://validate.perfdrive.com/?ssa=b06407dd-f2e7-4ff9-a919-933a8a4b0e59&ssb=36685228897&ssc=https%3A%2F%2Fiopscience.iop.org%2Farticle%2F10.1088%2F2057-1976%2Fac1c51&ssi=8d8c54df-8427-4280-b2a6-8a24627f577b&ssk=support@shieldsquare.com&ssm=98677289669768972102333419397246&ssn=e408eec0579fe0193c8b869279d7c80344e5a4e383fc-a0fd-4f75-9173d6&sso=328473ce-7caddcfd31f7becdb9e68a9f1ead4956539734e0b6110cbf&ssp=09143808141654651100165469281395120&ssq=08489314080607349578540806364623598312405&ssr=MTg4LjIxNC44LjE4NQ==&sst=Mozilla/5.0%20(Macintosh;%20Intel%20Mac%20OS%20X%2010_15_7)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20Chrome/102.0.5005.61%20Safari/537.36&ssv=&ssw=&ssx=W10=',\n",
       " 'https://www.ajronline.org/doi/10.2214/AJR.21.26486',\n",
       " 'https://www.clinicalnutritionjournal.com/article/S0261-5614(21)00374-5/fulltext',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/ccd.29917',\n",
       " 'https://pubs.rsna.org/doi/10.1148/radiol.2021204183',\n",
       " 'https://www.tandfonline.com/doi/full/10.1080/14767058.2021.1963704',\n",
       " 'https://link.springer.com/article/10.1007/s10620-021-07217-6',\n",
       " 'https://www.karger.com/Article/Abstract/517674',\n",
       " 'https://www.arthroscopyjournal.org/article/S0749-8063(21)00742-8/fulltext',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1111/ocr.12514',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1111/jop.13227',\n",
       " 'https://link.springer.com/article/10.1007/s13246-021-01046-7',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1111/jgh.15642',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S153204642100201X?via%3Dihub',\n",
       " 'https://onlinelibrary.wiley.com/doi/10.1002/adma.202103999',\n",
       " 'https://pubs.rsc.org/en/content/articlelanding/2021/TB/D1TB01237A',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S1532046421002185?via%3Dihub',\n",
       " 'https://www.sciencedirect.com/science/article/abs/pii/S0010482521005412?via%3Dihub']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mdpi -> add /pdf to end!\n",
    "\n",
    "##DOESNT WORK\n",
    "## onlinelibrary.wiley -> https://onlinelibrary.wiley.com/doi/10.1002/lary.29960',\n",
    "## add /pdfdirect/ after /doi\n",
    "\n",
    "## hindawi -> domain to downloads.hindawi.com, remove last slash and add .pdf\n",
    "\n",
    "## sagepub -> add /pdf/ after /doi\n",
    "## https://journals.sagepub.com/doi/10.1177/20556683211044640\n",
    "## https://journals.sagepub.com/doi/pdf/10.1177/20556683211044640\n",
    "\n",
    "## springer -> change article to content/pdf, and add .pdf on the end\n",
    "## https://link.springer.com/article/10.1007/s00330-021-08250-9\n",
    "## https://link.springer.com/content/pdf/10.1007/s00330-021-08250-9.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547d221",
   "metadata": {},
   "source": [
    "# scrape urls - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f8a64a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\anaconda3\\envs\\scraper\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options, executable_path=r'C:\\chromedriver\\chromedriver.exe')\n",
    "\n",
    "#driver.get(random.choice(url_list))\n",
    "driver.get(\"https://www.mdpi.com/2072-6694/13/23/6138/htm\")\n",
    "\n",
    "page = driver.page_source\n",
    "\n",
    "tree = html.fromstring(page)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da70210",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_text = tree.xpath('//body/descendant-or-self::*/text()')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d7df6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\n            ', '\\n        ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nNext Article in Journal', '\\n', 'Challenges for the Development of Extracellular Vesicle-Based Nucleic Acid Medicines', '\\nNext Article in Special Issue', '\\n', 'Raman Spectroscopy in Prostate Cancer: Techniques, Applications and Advancements', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nPrevious Article in Journal', '\\n', 'Promising Antigens for the New Frontier of Targeted Immunotherapy in Multiple Myeloma', '\\nPrevious Article in Special Issue', '\\n', 'Development of a Radiomic-Based Model Predicting Lymph Node Involvement in Prostate Cancer Patients', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Journals', '\\n', '\\n', '\\n', 'Topics', '\\n', '\\n', '\\n', '\\n', 'Information', '\\n', '\\n', '\\n', '\\n', '\\n', 'For Authors', '\\n', 'For Reviewers', '\\n', 'For Editors', '\\n', 'For Librarians', '\\n', 'For Publishers', '\\n', 'For Societies', '\\n', 'For Conference Organizers', '\\n', '\\n', '\\n', 'Article Processing Charges', '\\n', 'Open Access Policy', '\\n', 'Institutional Open Access Program', '\\n', 'Editorial Process', '\\n', 'Awards', '\\n', 'Research and Publication Ethics', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Author Services', '\\n', '\\n', '\\n', '\\n', 'Initiatives', '\\n', '\\n', '\\n', '\\n', '\\n', 'Sciforum', '\\n', 'MDPI Books', '\\n', 'Preprints', '\\n', 'Scilit', '\\n', 'SciProfiles', '\\n', 'Encyclopedia', '\\n', 'JAMS', '\\n', 'Proceedings Series', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'About', '\\n', '\\n', '\\n', '\\n', '\\n', 'Overview', '\\n', 'Contact', '\\n', 'Careers', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Sign In / Sign Up', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Notice', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nYou can make submissions to other journals\\n', 'here', '.\\n', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Notice', '\\n', '\\nYou are accessing a machine-readable page. In order to be human-readable, please install an RSS reader.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Continue', '\\n', 'Cancel', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', '\\n', '\\nAll articles published by MDPI are made immediately available worldwide under an open access license. No special\\npermission is required to reuse all or part of the article published by MDPI, including figures and tables. For\\narticles published under an open access Creative Common CC BY license, any part of the article may be reused without\\npermission provided that the original article is clearly cited.\\n', '\\n', '\\n', '\\n', '\\nFeature Papers represent the most advanced research with significant potential for high impact in the field. Feature\\nPapers are submitted upon individual invitation or recommendation by the scientific editors and undergo peer review\\nprior to publication.\\n', '\\n', '\\nThe Feature Paper can be either an original research article, a substantial novel research study that often involves\\nseveral techniques or approaches, or a comprehensive review paper with concise and precise updates on the latest\\nprogress in the field that systematically reviews the most exciting advances in scientific literature. This type of\\npaper provides an outlook on future directions of research or possible applications.\\n', '\\n', '\\n', '\\n', '\\nEditor’s Choice articles are based on recommendations by the scientific editors of MDPI journals from around the world.\\nEditors select a small number of articles recently published in the journal that they believe will be particularly\\ninteresting to authors, or important in this field. The aim is to provide a snapshot of some of the most exciting work\\npublished in the various research areas of the journal.\\n', '\\n', '\\n', '\\n', '\\n                    ', \"\\n                        You seem to have javascript disabled. Please note that many of the page functionalities won't work as expected without javascript enabled.\\n                    \", '\\n                ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', 'search', '\\n', '\\n', '\\n', 'menu', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Journals', '\\n', '\\n', '\\n', 'Topics', '\\n', '\\n', '\\n', 'Information', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'For Authors', '\\n', '\\n', '\\n ', 'For Reviewers', '\\n', '\\n', '\\n', 'For Editors', '\\n', '\\n', '\\n', 'For Librarians', '\\n', '\\n', '\\n', 'For Publishers', '\\n', '\\n', '\\n', 'For Societies', '\\n', '\\n', '\\n', 'For Conference Organizers', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Article Processing Charges', '\\n', '\\n', '\\n', 'Open Access Policy', '\\n', '\\n', '\\n', 'Institutional Open Access Program', '\\n', '\\n', '\\n', 'Editorial Process', '\\n', '\\n', '\\n', 'Awards', '\\n', '\\n', '\\n', 'Research and Publication Ethics', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Author Services', '\\n', '\\n', '\\n', 'Initiatives', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nSciforum\\n', '\\n', '\\n', '\\n', '\\nMDPI Books\\n', '\\n', '\\n', '\\n', '\\nPreprints\\n', '\\n', '\\n', '\\n', '\\nScilit\\n', '\\n', '\\n', '\\n', '\\nSciProfiles\\n', '\\n', '\\n', '\\n', '\\nEncyclopedia\\n', '\\n', '\\n', '\\n', '\\nJAMS\\n ', '\\n', '\\n', '\\n', '\\nProceedings Series\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'About', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nOverview\\n', '\\n', '\\n', '\\n', '\\nContact\\n', '\\n', '\\n', '\\n', '\\nCareers\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Sign In / Sign Up', '\\n', 'Submit', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', 'Search', ' for Articles', ':', '\\n', '\\n', '\\n', '\\n', '\\n', 'Title / Keyword', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Author / Affiliation', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Journal', '\\n', '\\n', '\\n', 'All Journals', '\\n', '\\nAcoustics\\n', '\\n', '\\nActuators\\n', '\\n', '\\nAdministrative Sciences\\n', '\\n', '\\nAdolescents\\n', '\\n', '\\nAerospace\\n', '\\n', '\\nAgriculture\\n', '\\n', '\\nAgriEngineering\\n', '\\n', '\\nAgronomy\\n', '\\n', '\\nAI\\n', '\\n', '\\nAlgorithms\\n', '\\n', '\\nAllergies\\n', '\\n', '\\nAlloys\\n', '\\n', '\\nAnalytica\\n', '\\n', '\\nAnalytics\\n', '\\n', '\\nAnatomia\\n', '\\n', '\\nAnimals\\n', '\\n', '\\nAntibiotics\\n', '\\n ', '\\nAntibodies\\n', '\\n', '\\nAntioxidants\\n', '\\n', '\\nApplied Biosciences\\n', '\\n', '\\nApplied Mechanics\\n', '\\n', '\\nApplied Microbiology\\n', '\\n', '\\nApplied Nano\\n', '\\n', '\\nApplied Sciences\\n', '\\n', '\\nApplied System Innovation (ASI)\\n', '\\n', '\\nAppliedChem\\n', '\\n', '\\nAppliedMath\\n', '\\n', '\\nAquaculture Journal\\n', '\\n', '\\nArchitecture\\n', '\\n', '\\nArts\\n', '\\n', '\\nAstronomy\\n', '\\n', '\\nAtmosphere\\n', '\\n', '\\nAtoms\\n', '\\n', '\\nAudiology Research\\n', '\\n', '\\nAutomation\\n', '\\n', '\\nAxioms\\n', '\\n', '\\nBacteria\\n', '\\n', '\\nBatteries\\n', '\\n', '\\nBehavioral Sciences\\n', '\\n', '\\nBeverages\\n', '\\n', '\\nBig Data and Cognitive Computing (BDCC)\\n', '\\n', '\\nBioChem\\n', '\\n', '\\nBioengineering\\n', '\\n', '\\nBiologics\\n', '\\n', '\\nBiology\\n', '\\n', '\\nBiology and Life Sciences Forum\\n', '\\n', '\\nBiomass\\n', '\\n', '\\nBiomechanics\\n', '\\n', '\\nBioMed\\n', '\\n', '\\nBiomedicines\\n', '\\n', '\\nBioMedInformatics\\n', '\\n', '\\nBiomimetics\\n', '\\n', '\\nBiomolecules\\n', '\\n', '\\nBiophysica\\n', '\\n', '\\nBiosensors\\n', '\\n', '\\nBioTech\\n', '\\n', '\\nBirds\\n', '\\n', '\\nBrain Sciences\\n', '\\n', '\\nBuildings\\n', '\\n', '\\nBusinesses\\n', '\\n', '\\nC\\n', '\\n', '\\nCancers\\n', '\\n', '\\nCardiogenetics\\n', '\\n', '\\nCatalysts\\n', '\\n', '\\nCells\\n', '\\n', '\\nCeramics\\n', '\\n', '\\nChallenges\\n', '\\n', '\\nChemEngineering\\n', '\\n', '\\nChemistry\\n', '\\n', '\\nChemistry Proceedings\\n', '\\n', '\\nChemosensors\\n', '\\n', '\\nChildren\\n', '\\n', '\\nChips\\n', '\\n', '\\nCivilEng\\n', '\\n', '\\nClean Technologies (Clean Technol.)\\n', '\\n', '\\nClimate\\n', '\\n', '\\nClinical and Translational Neuroscience (CTN)\\n', '\\n', '\\nClinics and Practice\\n', '\\n', '\\nClocks & Sleep\\n', '\\n', '\\nCoasts\\n', '\\n', '\\nCoatings\\n', '\\n', '\\nColloids and Interfaces\\n', '\\n', '\\nColorants\\n', '\\n', '\\nCommodities\\n', '\\n', '\\nCompounds\\n', '\\n', '\\nComputation\\n', '\\n', '\\nComputer Sciences & Mathematics Forum\\n', '\\n', '\\nComputers\\n', '\\n', '\\nCondensed Matter\\n', '\\n', '\\nConservation\\n', '\\n', '\\nConstruction Materials\\n', '\\n', '\\nCorrosion and Materials Degradation (CMD)\\n', '\\n', '\\nCosmetics\\n', '\\n', '\\nCOVID\\n', '\\n', '\\nCrops\\n', '\\n', '\\nCryptography\\n', '\\n', '\\nCrystals\\n', '\\n', '\\nCurrent Issues in Molecular Biology (CIMB)\\n', '\\n', '\\nCurrent Oncology\\n', '\\n', '\\nDairy\\n', '\\n', '\\nData\\n', '\\n', '\\nDentistry Journal\\n', '\\n', '\\nDermato\\n', '\\n', '\\nDermatopathology\\n', '\\n', '\\nDesigns\\n', '\\n', '\\nDiabetology\\n', '\\n', '\\nDiagnostics\\n', '\\n', '\\nDietetics\\n', '\\n', '\\nDigital\\n', '\\n', '\\nDisabilities\\n', '\\n', '\\nDiseases\\n', '\\n', '\\nDiversity\\n', '\\n', '\\nDNA\\n', '\\n', '\\nDrones\\n', '\\n', '\\nDynamics\\n', '\\n', '\\nEarth\\n', '\\n', '\\nEcologies\\n', '\\n', '\\nEconometrics\\n', '\\n', '\\nEconomies\\n', '\\n', '\\nEducation Sciences\\n', '\\n', '\\nElectricity\\n', '\\n', '\\nElectrochem\\n', '\\n', '\\nElectronic Materials\\n', '\\n', '\\nElectronics\\n', '\\n', '\\nEncyclopedia\\n', '\\n', '\\nEndocrines\\n', '\\n', '\\nEnergies\\n', '\\n', '\\nEng\\n', '\\n', '\\nEngineering Proceedings\\n', '\\n', '\\nEntomology\\n', '\\n', '\\nEntropy\\n', '\\n', '\\nEnvironmental Sciences Proceedings\\n', '\\n', '\\nEnvironments\\n', '\\n', '\\nEpidemiologia\\n', '\\n', '\\nEpigenomes\\n', '\\n', '\\nEuropean Burn Journal (EBJ)\\n', '\\n', '\\nEuropean Journal of Investigation in Health, Psychology and Education (EJIHPE)\\n', '\\n', '\\nFermentation\\n', '\\n', '\\nFibers\\n', '\\n', '\\nFinTech\\n', '\\n', '\\nFire\\n', '\\n', '\\nFishes\\n', '\\n', '\\nFluids\\n', '\\n', '\\nFoods\\n', '\\n', '\\nForecasting\\n', '\\n', '\\nForensic Sciences\\n', '\\n', '\\nForests\\n', '\\n', '\\nFoundations\\n', '\\n', '\\nFractal and Fractional (Fractal Fract)\\n', '\\n', '\\nFuels\\n', '\\n', '\\nFuture Internet\\n', '\\n', '\\nFuture Pharmacology\\n', '\\n', '\\nFuture Transportation\\n', '\\n', '\\nGalaxies\\n', '\\n', '\\nGames\\n', '\\n', '\\nGases\\n', '\\n\\n', '\\nGastroenterology Insights\\n', '\\n', '\\nGastrointestinal Disorders\\n', '\\n', '\\nGels\\n', '\\n', '\\nGenealogy\\n', '\\n', '\\nGenes\\n', '\\n', '\\nGeographies\\n', '\\n', '\\nGeoHazards\\n', '\\n', '\\nGeomatics\\n', '\\n', '\\nGeosciences\\n', '\\n', '\\nGeotechnics\\n', '\\n', '\\nGeriatrics\\n', '\\n', '\\nHealthcare\\n', '\\n', '\\nHearts\\n', '\\n', '\\nHemato\\n', '\\n', '\\nHematology Reports\\n', '\\n', '\\nHeritage\\n', '\\n', '\\nHistories\\n', '\\n', '\\nHorticulturae\\n', '\\n', '\\nHumanities\\n', '\\n', '\\nHumans\\n', '\\n', '\\nHydrobiology\\n', '\\n', '\\nHydrogen\\n', '\\n', '\\nHydrology\\n', '\\n', '\\nHygiene\\n', '\\n', '\\nImmuno\\n', '\\n', '\\nInfectious Disease Reports\\n', '\\n', '\\nInformatics\\n', '\\n', '\\nInformation\\n', '\\n', '\\nInfrastructures\\n', '\\n', '\\nInorganics\\n', '\\n', '\\nInsects\\n', '\\n', '\\nInstruments\\n', '\\n', '\\nInternational Journal of Environmental Research and Public Health (IJERPH)\\n', '\\n', '\\nInternational Journal of Financial Studies (IJFS)\\n', '\\n', '\\nInternational Journal of Molecular Sciences (IJMS)\\n', '\\n', '\\nInternational Journal of Neonatal Screening (IJNS)\\n', '\\n', '\\nInternational Journal of Plant Biology (IJPB)\\n', '\\n', '\\nInternational Journal of Translational Medicine (IJTM)\\n', '\\n', '\\nInternational Journal of Turbomachinery, Propulsion and Power (IJTPP)\\n', '\\n', '\\nInternational Medical Education (IME)\\n', '\\n', '\\nInventions\\n', '\\n', '\\nIoT\\n', '\\n', '\\nISPRS International Journal of Geo-Information (IJGI)\\n', '\\n', '\\nJ\\n', '\\n', '\\nJournal of Ageing and Longevity (JAL)\\n', '\\n', '\\nJournal of Cardiovascular Development and Disease (JCDD)\\n', '\\n', '\\nJournal of Clinical Medicine (JCM)\\n', '\\n', '\\nJournal of Composites Science (J. Compos. Sci.)\\n', '\\n', '\\nJournal of Cybersecurity and Privacy (JCP)\\n', '\\n', '\\nJournal of Developmental Biology (JDB)\\n', '\\n', '\\nJournal of Functional Biomaterials (JFB)\\n', '\\n', '\\nJournal of Functional Morphology and Kinesiology (JFMK)\\n', '\\n', '\\nJournal of Fungi (JoF)\\n', '\\n', '\\nJournal of Imaging (J. Imaging)\\n', '\\n', '\\nJournal of Intelligence (J. Intell.)\\n', '\\n', '\\nJournal of Low Power Electronics and Applications (JLPEA)\\n', '\\n', '\\nJournal of Manufacturing and Materials Processing (JMMP)\\n', '\\n', '\\nJournal of Marine Science and Engineering (JMSE)\\n', '\\n', '\\nJournal of Molecular Pathology (JMP)\\n', '\\n', '\\nJournal of Nanotheranostics (JNT)\\n', '\\n', '\\nJournal of Nuclear Engineering (JNE)\\n', '\\n', '\\nJournal of Open Innovation: Technology, Market, and Complexity (JOItmC)\\n', '\\n', '\\nJournal of Otorhinolaryngology, Hearing and Balance Medicine (OHBM)\\n', '\\n', '\\nJournal of Personalized Medicine (JPM)\\n', '\\n', '\\nJournal of Respiration (JoR)\\n', '\\n', '\\nJournal of Risk and Financial Management (JRFM)\\n', '\\n', '\\nJournal of Sensor and Actuator Networks (JSAN)\\n', '\\n', '\\nJournal of Theoretical and Applied Electronic Commerce Research (JTAER)\\n', '\\n', '\\nJournal of Vascular Diseases (JVD)\\n', '\\n', '\\nJournal of Xenobiotics (JoX)\\n', '\\n', '\\nJournal of Zoological and Botanical Gardens (JZBG)\\n', '\\n', '\\nJournalism and Media\\n', '\\n', '\\nKidney and Dialysis\\n', '\\n', '\\nKnowledge\\n', '\\n', '\\nLand\\n', '\\n', '\\nLanguages\\n', '\\n', '\\nLaws\\n', '\\n', '\\nLife\\n', '\\n', '\\nLiquids\\n', '\\n', '\\nLiterature\\n', '\\n', '\\nLivers\\n', '\\n', '\\nLogics\\n', '\\n', '\\nLogistics\\n', '\\n', '\\nLubricants\\n', '\\n', '\\nMachine Learning and Knowledge Extraction (MAKE)\\n', '\\n', '\\nMachines\\n', '\\n', '\\nMacromol\\n', '\\n', '\\nMagnetism\\n', '\\n', '\\nMagnetochemistry\\n', '\\n', '\\nMarine Drugs\\n', '\\n', '\\nMaterials\\n', '\\n', '\\nMaterials Proceedings\\n', '\\n', '\\nMathematical and Computational Applications (MCA)\\n', '\\n', '\\nMathematics\\n', '\\n', '\\nMedical Sciences\\n', '\\n', '\\nMedical Sciences Forum\\n', '\\n', '\\nMedicina\\n', '\\n', '\\nMedicines\\n', '\\n', '\\nMembranes\\n', '\\n', '\\nMerits\\n', '\\n', '\\nMetabolites\\n', '\\n', '\\nMetals\\n', '\\n', '\\nMeteorology\\n', '\\n', '\\nMethane\\n', '\\n', '\\nMethods and Protocols (MPs)\\n', '\\n', '\\nMetrology\\n', '\\n', '\\nMicro\\n', '\\n', '\\nMicrobiology Research\\n', '\\n', '\\nMicromachines\\n', '\\n', '\\nMicroorganisms\\n', '\\n', '\\nMicroplastics\\n', '\\n', '\\nMinerals\\n', '\\n', '\\nMining\\n', '\\n', '\\nModelling\\n', '\\n', '\\nMolbank\\n', '\\n', '\\nMolecules\\n', '\\n', '\\nMultimodal Technologies and Interaction (MTI)\\n', '\\n', '\\nMuscles\\n', '\\n', '\\nNanoenergy Advances\\n', '\\n', '\\nNanomanufacturing\\n', '\\n', '\\nNanomaterials\\n', '\\n', '\\nNetwork\\n', '\\n', '\\nNeuroglia\\n', '\\n', '\\nNeurology International\\n', '\\n', '\\nNeuroSci\\n', '\\n', '\\nNitrogen\\n', '\\n', '\\nNon-Coding RNA (ncRNA)\\n', '\\n', '\\nNursing Reports\\n', '\\n', '\\nNutraceuticals\\n', '\\n', '\\nNutrients\\n', '\\n', '\\nObesities\\n', '\\n', '\\nOceans\\n', '\\n', '\\nOnco\\n', '\\n', '\\nOptics\\n', '\\n', '\\nOral\\n', '\\n', '\\nOrganics\\n', '\\n', '\\nOrganoids\\n', '\\n', '\\nOsteology\\n', '\\n', '\\nOxygen\\n', '\\n', '\\nParasitologia\\n', '\\n', '\\nParticles\\n', '\\n', '\\nPathogens\\n', '\\n', '\\nPathophysiology\\n', '\\n', '\\nPediatric Reports\\n', '\\n', '\\nPharmaceuticals\\n', '\\n', '\\nPharmaceutics\\n', '\\n', '\\nPharmacoepidemiology\\n', '\\n', '\\nPharmacy\\n', '\\n', '\\nPhilosophies\\n', '\\n', '\\nPhotochem\\n', '\\n', '\\nPhotonics\\n', '\\n', '\\nPhycology\\n', '\\n', '\\nPhyschem\\n', '\\n', '\\nPhysical Sciences Forum\\n', '\\n', '\\nPhysics\\n', '\\n', '\\nPhysiologia\\n', '\\n', '\\nPlants\\n', '\\n', '\\nPlasma\\n', '\\n', '\\nPollutants\\n', '\\n', '\\nPolymers\\n', '\\n', '\\nPolysaccharides\\n', '\\n', '\\nPoultry\\n', '\\n', '\\nPowders\\n', '\\n', '\\nProceedings\\n', '\\n', '\\nProcesses\\n', '\\n', '\\nProsthesis\\n', '\\n', '\\nProteomes\\n', '\\n', '\\nPsych\\n', '\\n', '\\nPsychiatry International\\n', '\\n', '\\nPsychoactives\\n', '\\n', '\\nPublications\\n', '\\n', '\\nQuantum Beam Science (QuBS)\\n', '\\n', '\\nQuantum Reports\\n', '\\n', '\\nQuaternary\\n', '\\n', '\\nRadiation\\n', '\\n', '\\nReactions\\n', '\\n', '\\nReceptors\\n', '\\n', '\\nRecycling\\n', '\\n', '\\nReligions\\n', '\\n', '\\nRemote Sensing\\n', '\\n', '\\nReports\\n', '\\n', '\\nReproductive Medicine (Reprod. Med.)\\n', '\\n', '\\nResources\\n', '\\n', '\\nRheumato\\n', '\\n', '\\nRisks\\n', '\\n', '\\nRobotics\\n', '\\n', '\\nRuminants\\n', '\\n', '\\nSafety\\n', '\\n', '\\nSci\\n', '\\n', '\\nScientia Pharmaceutica (Sci. Pharm.)\\n', '\\n', '\\nSeeds\\n', '\\n', '\\nSensors\\n', '\\n', '\\nSeparations\\n', '\\n', '\\nSexes\\n', '\\n', '\\nSignals\\n', '\\n', '\\nSinusitis\\n', '\\n', '\\nSmart Cities\\n', '\\n', '\\nSocial Sciences\\n', '\\n', '\\nSocieties\\n', '\\n', '\\nSoftware\\n', '\\n', '\\nSoil Systems\\n', '\\n', '\\nSolar\\n', '\\n', '\\nSolids\\n', '\\n', '\\nSports\\n', '\\n', '\\nStandards\\n', '\\n', '\\nStats\\n', '\\n', '\\nStresses\\n', '\\n', '\\nSurfaces\\n', '\\n', '\\nSurgeries\\n', '\\n', '\\nSurgical Techniques Development\\n', '\\n', '\\nSustainability\\n', '\\n', '\\nSustainable Chemistry\\n', '\\n', '\\nSymmetry\\n', '\\n', '\\n SynBio\\n', '\\n', '\\nSystems\\n', '\\n', '\\nTaxonomy\\n', '\\n', '\\nTechnologies\\n', '\\n', '\\nTelecom\\n', '\\n', '\\nTextiles\\n', '\\n', '\\nThalassemia Reports\\n', '\\n', '\\nThermo\\n', '\\n', '\\nTomography\\n', '\\n', '\\nTourism and Hospitality\\n', '\\n', '\\nToxics\\n', '\\n', '\\nToxins\\n', '\\n', '\\nTransplantology\\n', '\\n', '\\nTrauma Care\\n', '\\n', '\\nTropical Medicine and Infectious Disease (TropicalMed)\\n', '\\n', '\\nUniverse\\n', '\\n', '\\nUrban Science\\n', '\\n', '\\nUro\\n', '\\n', '\\nVaccines\\n', '\\n', '\\nVehicles\\n', '\\n', '\\nVenereology\\n', '\\n', '\\nVeterinary Sciences\\n', '\\n', '\\nVibration\\n', '\\n', '\\nVirtual Worlds\\n', '\\n', '\\nViruses\\n', '\\n', '\\nVision\\n', '\\n', '\\nWater\\n', '\\n', '\\nWind\\n', '\\n', '\\nWomen\\n', '\\n', '\\nWorld\\n', '\\n', '\\nWorld Electric Vehicle Journal (WEVJ)\\n', '\\n', '\\nYouth\\n', '\\n', '\\nZoonotic Diseases\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Article Type', '\\n', '\\n', '\\n', 'All Article Types', '\\n', 'Article', '\\n', 'Review', '\\n', 'Communication', '\\n', 'Editorial', '\\n', 'Book Review', '\\n', 'Brief Report', '\\n', 'Case Report', '\\n', 'Comment', '\\n', 'Commentary', '\\n', 'Concept Paper', '\\n', 'Conference Report', '\\n', 'Correction', '\\n', 'Creative', '\\n', 'Data Descriptor', '\\n', 'Discussion', '\\n', 'Entry', '\\n', 'Essay', '\\n', 'Expression of Concern', '\\n', 'Extended Abstract', '\\n', 'Guidelines', '\\n', 'Hypothesis', '\\n', 'Interesting Images', '\\n', 'Letter', '\\n', 'New Book Received', '\\n', 'Obituary', '\\n', 'Opinion', '\\n', 'Perspective', '\\n', 'Proceeding Paper', '\\n', 'Project Report', '\\n', 'Protocol', '\\n', 'Registered Report', '\\n', 'Reply', '\\n', 'Retraction', '\\n', 'Short Note', '\\n', 'Study Protocol', '\\n', 'Systematic Review', '\\n', 'Technical Note', '\\n', 'Tutorial', '\\n', 'Viewpoint', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', 'Advanced', ' Search', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', '\\n', 'Section', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Special Issue', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Volume', '\\n', '\\n', '\\n', '\\n', 'Issue', '\\n', '\\n', '\\n', '\\n', 'Number', '\\n', '\\n', '\\n', '\\n', 'Page', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', 'Logical Operator', 'Operator', '\\n', '\\n', 'AND', '\\n', 'OR', '\\n', '\\n', '\\n', '\\n', 'Search Text', '\\n', '\\n', '\\n', '\\n', 'Search Type', '\\n', '\\n', 'All fields', '\\n', 'Title', '\\n', 'Abstract', '\\n', 'Keywords', '\\n', 'Authors', '\\n', 'Affiliations', '\\n', 'Doi', '\\n', 'Full Text', '\\n', 'References', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', '\\n', 'add_circle_outline', '\\n', '\\n', '\\n', '\\n', '\\n', 'remove_circle_outline', '\\n', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Journals', '\\n', '\\n', '\\n', 'Cancers', '\\n', '\\n', '\\n', 'Volume 13', '\\n', '\\n', '\\n', 'Issue 23', '\\n', '\\n', '\\n', '10.3390/cancers13236138', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nSubmit to this Journal\\n', '\\n', '\\nReview for this Journal\\n', '\\n', '\\nEdit a Special Issue\\n', '\\n', '\\n', '\\n', '\\n', '►', '\\n', '▼', '\\nArticle Menu\\n', '\\n', '\\n', '\\n', '\\n', 'Article Menu', '\\n', '\\n', '\\n', '\\n', 'Article Overview', '\\n', '\\n', '\\n', '\\n', 'Abstract', '\\n', '\\n', '\\n', 'Supplementary Material', '\\n', '\\n', '\\n', 'Open Access and Permissions', '\\n', '\\n', '\\n', 'Share and Cite', '\\n', '\\n', '\\n', 'Article Metrics', '\\n', '\\n', '\\n', 'Order Article Reprints', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Article Versions', '\\n', '\\n', '\\n', '\\n', 'Abstract', '\\n', '\\n', '\\n', 'Article Versions Notes', '\\n', '\\n', '\\n', 'Full-Text HTML', '\\n', '\\n', '\\n', 'Full-Text PDF', '\\n', '\\n', '\\n', 'Full-Text XML', '\\n', '\\n', '\\n', 'Full-Text Epub', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Related Info Links', '\\n', '\\n', '\\n', '\\n', 'PubMed/Medline', '\\n', '\\n', '\\n', 'Google Scholar', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'More by Authors Links', '\\n', '\\n', '\\n', '\\n', 'on DOAJ', '\\n', '\\n', '\\n', '\\n', '\\n', 'Mehta, P.', '\\n', '\\n', '\\n', '\\n', 'Antonelli, M.', '\\n', '\\n', '\\n', '\\n', 'Singh, S.', '\\n', '\\n', '\\n', '\\n', 'Grondecka, N.', '\\n', '\\n', '\\n', '\\n', 'Johnston, E. W.', '\\n', '\\n', '\\n', '\\n', 'Ahmed, H. U.', '\\n', '\\n', '\\n', '\\n', 'Emberton, M.', '\\n', '\\n', '\\n', '\\n', 'Punwani, S.', '\\n', '\\n', '\\n', '\\n', 'Ourselin, S.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'on Google Scholar', '\\n', '\\n', '\\n', '\\n', '\\n', 'Mehta, P.', '\\n', '\\n', '\\n', '\\n', 'Antonelli, M.', '\\n', '\\n', '\\n', '\\n', 'Singh, S.', '\\n', '\\n', '\\n', '\\n', 'Grondecka, N.', '\\n', '\\n', '\\n', '\\n', 'Johnston, E. W.', '\\n', '\\n', '\\n', '\\n', 'Ahmed, H. U.', '\\n', '\\n', '\\n', '\\n', 'Emberton, M.', '\\n', '\\n', '\\n', '\\n', 'Punwani, S.', '\\n', '\\n', '\\n', '\\n', 'Ourselin, S.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'on PubMed', '\\n', '\\n', '\\n', '\\n', '\\n', 'Mehta, P.', '\\n', '\\n', '\\n', '\\n', 'Antonelli, M.', '\\n', '\\n', '\\n', '\\n', 'Singh, S.', '\\n', '\\n', '\\n', '\\n', 'Grondecka, N.', '\\n', '\\n', '\\n', '\\n', 'Johnston, E. W.', '\\n', '\\n', '\\n', '\\n', 'Ahmed, H. U.', '\\n', '\\n', '\\n', '\\n', 'Emberton, M.', '\\n', '\\n', '\\n', '\\n', 'Punwani, S.', '\\n', '\\n', '\\n', '\\n', 'Ourselin, S.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Full Article Text', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n ', '/ajax/scifeed/subscribe', '\\n', '\\n', '\\n\\n', '\\n', '\\n', '.content__container {\\n        min-width: 300px;\\n    }', '\\n\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'share', '\\n', '\\n', '\\n', 'announcement', '\\n', '\\n', '\\n', 'question_answer', '\\n', '\\n', '\\n', 'thumb_up', '\\n', '\\n...\\n', '\\n', '\\n', '\\n', 'textsms', '\\n', '\\n...\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Need Help?', '\\n', '\\n', '\\n', 'Support', '\\n', '\\nFind support for a specific problem in the support section of our website.\\n', '\\n', '\\nGet Support\\n', '\\n', '\\n', '\\n', 'Feedback', '\\n', '\\nPlease let us know what you think of our products and services.\\n', '\\n', '\\nGive Feedback\\n', '\\n', '\\n', '\\n', 'Information', '\\n', '\\nVisit our dedicated information section to learn more about MDPI.\\n', '\\n', '\\nGet Information\\n', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Open Access', 'Article', '\\n', '\\nAutoProstate: Towards Automated Reporting of Prostate MRI for Prostate Cancer Assessment Using Deep Learning ', '\\n', '\\n\\nby\\n', 'Pritesh Mehta', ' 1,2,*', ', ', 'Michela Antonelli', ' 2', ', ', 'Saurabh Singh', ' 3', ', ', 'Natalia Grondecka', ' 4', ', ', 'Edward W. Johnston', ' 5', ', ', 'Hashim U. Ahmed', ' 6', ', ', 'Mark Emberton', ' 7', ', ', 'Shonit Punwani', ' 3', ' and ', 'Sébastien Ourselin', ' 2', ' \\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '1', '\\n', 'Department of Medical Physics and Biomedical Engineering, University College London, London WC1E 6BT, UK', '\\n', '\\n', '\\n', '2', '\\n', 'School of Biomedical Engineering & Imaging Sciences, King’s College London, London SE1 7EH, UK', '\\n', '\\n', '\\n', '3', '\\n', 'Centre for Medical Imaging, University College London, London WC1E 6BT, UK', '\\n', '\\n', '\\n', '4', '\\n', 'Department of Medical Radiology, Medical University of Lublin, 20-059 Lublin, Poland', '\\n', '\\n', '\\n', '5', '\\n', 'Interventional Radiology, Royal Marsden Hospital, London SW3 6JJ, UK', '\\n', '\\n', '\\n', '6', '\\n', 'Imperial Prostate, Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, London SW7 2AZ, UK', '\\n', '\\n', '\\n', '7', '\\n', 'Division of Surgery and Interventional Science, Faculty of Medical Sciences, University College London, London WC1E 6BT, UK', '\\n', '\\n', '\\n', '*', '\\n', 'Author to whom correspondence should be addressed. ', '\\n', '\\n', '\\n', '\\n', '\\nAcademic Editor: Fabio Zattoni\\n', '\\n', '\\n', 'Cancers', ' ', '2021', ', ', '13', '(23), 6138; ', 'https://doi.org/10.3390/cancers13236138', '\\n', '\\n', '\\n', 'Received: 12 November 2021', '\\n/\\n', 'Revised: 30 November 2021', '\\n/\\n', 'Accepted: 3 December 2021', '\\n/\\n', 'Published: 6 December 2021', '\\n', '\\n', '\\n(This article belongs to the Special Issue ', 'New Technologies in Prostate Cancer: From Diagnosis to Treatment', ')', '\\n', '\\n', '\\n', '\\n', 'Download PDF', '\\n\\n', '\\n', 'Browse Figures', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nCitation Export\\n', '\\n', '\\n\\n', '\\n', '\\n', '\\n', '\\n', '\\n\\n', '\\n', '\\n', '\\n', '\\n', '\\n\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'BibTeX', '\\n', '\\n', 'EndNote', '\\n', '\\n', 'RIS', '\\n', '\\n', 'Cite This Paper', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Simple Summary ', '\\n', '\\n', '\\nInternational guidelines recommend multiparametric magnetic resonance imaging (mpMRI) of the prostate for use by radiologists to identify lesions containing clinically significant prostate cancer, prior to confirmatory biopsy. Automatic assessment of prostate mpMRI using artificial intelligence algorithms holds a currently unrealized potential to improve the diagnostic accuracy achievable by radiologists alone, improve the reporting consistency between radiologists, and enhance reporting quality. In this work, we introduce AutoProstate: a deep learning-powered framework for automatic MRI-based prostate cancer assessment. In particular, AutoProstate utilizes patient data and biparametric MRI to populate an automatic web-based report which includes segmentations of the whole prostate, prostatic zones, and candidate clinically significant prostate cancer lesions, and in addition, several derived characteristics with clinical value are presented. Notably, AutoProstate performed well in external validation using the PICTURE study dataset, suggesting value in prospective multicentre validation, with a view towards future deployment into the prostate cancer diagnostic pathway.\\n', '\\n', '\\n', '\\n', '\\n', 'Abstract', '\\n', '\\n', '\\nMultiparametric magnetic resonance imaging (mpMRI) of the prostate is used by radiologists to identify, score, and stage abnormalities that may correspond to clinically significant prostate cancer (CSPCa). Automatic assessment of prostate mpMRI using artificial intelligence algorithms may facilitate a reduction in missed cancers and unnecessary biopsies, an increase in inter-observer agreement between radiologists, and an improvement in reporting quality. In this work, we introduce AutoProstate, a deep learning-powered framework for automatic MRI-based prostate cancer assessment. AutoProstate comprises of three modules: Zone-Segmenter, CSPCa-Segmenter, and Report-Generator. Zone-Segmenter segments the prostatic zones on T2-weighted imaging, CSPCa-Segmenter detects and segments CSPCa lesions using biparametric MRI, and Report-Generator generates an automatic web-based report containing four sections: ', 'Patient Details', ', ', 'Prostate Size and PSA Density', ', ', 'Clinically Significant Lesion Candidates', ', and ', 'Findings Summary', '. In our experiment, AutoProstate was trained using the publicly available PROSTATEx dataset, and externally validated using the PICTURE dataset. Moreover, the performance of AutoProstate was compared to the performance of an experienced radiologist who prospectively read PICTURE dataset cases. In comparison to the radiologist, AutoProstate showed statistically significant improvements in prostate volume and prostate-specific antigen density estimation. Furthermore, AutoProstate matched the CSPCa lesion detection sensitivity of the radiologist, which is paramount, but produced more false positive detections.\\n', '\\n', 'Keywords: ', '\\n', 'automatic report; computer-aided diagnosis; convolutional neural network; deep learning; lesion detection; lesion classification; magnetic resonance imaging; prostate cancer; segmentation', '\\n', ' ', 'automatic report', '; ', 'computer-aided diagnosis', '; ', 'convolutional neural network', '; ', 'deep learning', '; ', 'lesion detection', '; ', 'lesion classification', '; ', 'magnetic resonance imaging', '; ', 'prostate cancer', '; ', 'segmentation', '\\n', '\\n', '\\n', ' ', '\\n', '\\n', '\\n', '\\n', ' 1. Introduction', 'Radiologists use prostate multiparametric magnetic resonance imaging (mpMRI) to detect, score, and stage lesions that may correspond to clinically significant prostate cancer (CSPCa), whose status can later be confirmed using MR-guided targeted biopsy and histopathological grading [', '1', ']. However, the current diagnostic approach must be improved to reduce the small proportion of men with CSPCa who are missed by mpMRI, to reduce the large number of men who undergo unnecessary biopsies, and to increase the inter-observer agreement between readers [', '2', ']. In addition to lesion assessment, radiologists use prostate mpMRI to estimate prostate volume using the ellipsoid formula [', '3', ']. Primarily, prostate volume is required for calculating prostate-specific antigen density (PSAd), which has been shown to be a predictor of CSPCa [', '4', ']. However, the ellipsoid formula is an approximation which ignores exact prostate morphology [', '3', '], therefore more accurate volume estimation methods are sought. Computer-aided diagnosis (CAD) systems that use mpMRI for prostate volume estimation and CSPCa lesion detection and/or segmentation may provide the desired performance improvements over current clinical practice.', 'Automatic segmentation of the prostate may enable accurate prostate volume estimation. Several automatic methods for prostate segmentation have been published [', '5', ',', '6', ',', '7', ',', '8', ',', '9', ',', '10', ']. Foremost, the PROMISE12 Challenge has driven consistent improvements in the performance of prostate segmentation algorithms over the past decade [', '11', ']; an unpublished deep learning method named MSD-Net currently tops the leader board with a mean Dice coefficient of 0.92 for whole-prostate segmentation. To the best of our knowledge, only the work by Lee et al. [', '10', '] has compared prostate volume estimation using an automatic segmentation method to the clinically utilized ellipsoid formula. On a 70-patient test set, their 3D CNN for whole-prostate segmentation achieved a mean Dice coefficient of 0.87 and a mean absolute percentage error (Abs%Err) of 11.78% for volume estimation, while the mean Abs%Err for the ellipsoid formula was 11.92%. In the discussion section of their paper, Lee et al. mention the potential benefit of more accurate volume estimation methods on the calculation of PSAd, but their study stopped short of providing a quantitative comparison.', 'CAD systems for lesion detection and segmentation are actively being investigated, as demonstrated by a vast and growing literature [', '12', ',', '13', ',', '14', ',', '15', ',', '16', ',', '17', ',', '18', ']. The studies by Cao et al. [', '12', '] and Schelb et al. [', '14', '] directly compared CAD systems for CSPCa lesion detection against radiologist mpMRI assessment. Cao et al. showed that their proposed FocalNet convolutional neural network (CNN), trained using biparametric MRI (bpMRI), had a CSPCa lesion detection sensitivity of 87.9%, which was only 1.5% lower than PI-RADS v2 scoring by three experienced radiologists who read a subset of cases each. Their result was obtained from a fivefold cross-validation of 417 preoperative patients who later underwent radical prostatectomy. Similarly, the study by Schelb et al. showed that a U-Net CNN [', '19', '] produced similar CSPCa detection performance to PI-RADS v2 scoring by eight radiologists who each read a subset of cases. On the held-out test cohort of 62 men sampled from the same study cohort as the training data, their method achieved a patient-level sensitivity of 92% and specificity of 47%, while radiologist assessment yielded a sensitivity of 88% and a specificity of 50%; differences in sensitivity and specificity between the proposed CNN approach and radiologist scoring were not statistically significant. While the studies by Cao et al. and Schelb et al. evaluated CAD systems using test data sampled from the same study cohort as the training data, the study by Thon et al. [', '15', '] evaluated the commercially available Watson Elementary', 'TM', ' system using an external test cohort of 79 men. Their study concluded that Watson Elementary', 'TM', ' did not perform satisfactorily on external test data due to differences in the instrumentation and acquisition parameters used to collect training and test data. Moreover, they remarked that optimistic performances of CAD systems reported in other studies may be dataset-specific, and therefore advocated for the necessity of external validation of CAD systems.', 'This work has two aims. The first aim is to introduce AutoProstate: a deep learning-powered framework for automatic MRI-based prostate cancer detection and assessment that we have developed. In particular, AutoProstate segments the prostatic zones on T2-weighted imaging (T2WI), detects and segments CSPCa lesions using bpMRI, and generates a novel automatic web-based report containing four sections: ', 'Patient Details', ', ', 'Prostate Size and PSA Density', ', ', 'Clinically Significant Lesion Candidates', ', and ', 'Findings Summary', ', which posits it close to clinical deployment. Notably, AutoProstate uses up-to-date deep learning techniques for training and inference, such as hybrid losses [', '20', '], test-time dropout [', '21', '], test-time augmentation [', '22', '], and model ensembling, to enhance performance. The second aim of this work is to perform a high-quality single-centre external validation of AutoProstate, as a first step towards clinical deployment, ahead of multicentre external validation and prospective validation in a clinical setting. In our experiment, AutoProstate is trained using the publicly available PROSTATEx dataset [', '23', '], and externally validated using the Prostate Imaging Compared to Transperineal Ultrasound-guided biopsy for significant prostate cancer Risk Evaluation (PICTURE) trial dataset [', '24', ']. The external validation follows the key considerations for authors, reviewers, and readers of AI Manuscripts in radiology by Bluemke et al. [', '25', ']. In particular, the external test set contains MRIs acquired using scanners manufactured by a different vendor to the scanners used to acquire the training set and is confirmed using transperineal template prostate-mapping (TTPM) biopsy, which avoids the biases associated with MR-guided targeted biopsy and prostatectomy [', '24', ']. Furthermore, we compare the performance of AutoProstate to the performance of an experienced radiologist who, at the time of the PICTURE trial, had 10 years’ experience in reading prostate mpMRI.', ' 2. Methods', 'AutoProstate, visualized schematically in ', 'Figure 1', ', consists of three modules: Zone-Segmenter, CSPCa-Segmenter, and Report-Generator. Methodological aspects of each module are described in detail in the subsections to follow, while specific experimental parameters used to collect results are described in ', 'Section 3', '.', ' 2.1. Zone-Segmenter Module', 'The Zone-Segmenter module segments peripheral zone (PZ), central gland (CG), and background tissues on T2WI.', ' 2.1.1. Pre-Processing', 'T2W images are first resampled to a common in-plane resolution and cropped to a common in-plane shape, and then normalized by whitening of image voxel intensities.', ' 2.1.2. Zone-U-Net-E', 'After pre-processing, each T2WI slice is segmented by an ensemble of 2D nnU-Nets with task-specific hyperparameter modifications; we refer to each constituent 2D nnU-Net as Zone-U-Net and the ensemble of Zone-U-Nets as Zone-U-Net-E. A detailed description of the Zone-U-Net architecture is given in ', 'Supplementary Section S1', '. The output of each Zone-U-Net is slice-wise PZ, CG, and background probability maps. Per-voxel averaging is used to combine the probability map outputs of each Zone-U-Net ∈ Zone-U-Net-E, followed by restacking of slices to form PZ, CG, and background probability map volumes.', ' 2.1.3. Post-Processing', 'The PZ, CG, and background probability maps output by Zone-U-Net-E are transformed to the original T2WI shape and voxel resolution using padding and resampling operations. As a final step, a zonal segmentation map is obtained from the PZ, CG, and background probability maps using a per-voxel argmax operation.', ' 2.2. CSPCa-Segmenter Module', 'The CSPCa-Segmenter module detects and segments CSPCa lesions using each patient’s T2WI, apparent diffusion coefficient (ADC) map, low b-value diffusion-weighted imaging (DWI), and PZ and CG probability maps output by Zone-Segmenter.', ' 2.2.1. Pre-Processing I: Computed High b-Value DWI', 'AutoProstate generates computed high b-value DWI from available DWI corresponding to low b-values (typically ', '\\n', '\\n', '\\n', 'b', '\\n', '\\xa0', '\\n', '\\n', '∈', '\\n', '\\n', '[', '\\n', '\\n', '0', '\\n', ',', '\\n', '\\xa0', '\\n', '1000', '\\n', '\\n', ']', '\\n', '\\n', '\\n', ' s/mm', '2', ' [', '26', ']) using a monoexponential model for the per-voxel observed signal [', '27', ']:', '\\n', '\\n', '\\n', '\\n', 's', '\\n', '\\n', '(', '\\n', 'b', '\\n', ')', '\\n', '\\n', '=', '\\n', 's', '\\n', '\\n', '(', '\\n', '0', '\\n', ')', '\\n', '\\n', '·', '\\n', 'exp', '\\n', '\\n', '(', '\\n', '\\n', '−', '\\n', 'b', '\\n', '\\xa0', '\\n', '·', '\\n', 'ADC', '\\n', '\\n', ')', '\\n', '\\n', '.', '\\n', '\\n', '\\n', '\\n', '\\n', '(1)', '\\n', '\\n', 'Using non-linear least squares to fit Equation (1) to voxel intensities belonging to low b-value images, estimates ', '\\n', '\\n', '\\n', 's', '\\n', '*', '\\n', '\\n', '\\n', '(', '\\n', '0', '\\n', ')', '\\n', '\\n', '\\n', ' of ', '\\n', '\\n', 's', '\\n', '\\n', '(', '\\n', '0', '\\n', ')', '\\n', '\\n', '\\n', ' and ', '\\n', '\\n', '\\n', '\\n', 'ADC', '\\n', '\\n', '*', '\\n', '\\n', '\\n', ' of ', '\\n', '\\n', 'ADC', '\\n', '\\n', ', are obtained. Subsequently, a computed high b-value image is generated using the equation:', '\\n', '\\n', '\\n', '\\n', 's', '\\n', '\\n', '(', '\\n', '\\n', '\\n', 'b', '\\n', 'c', '\\n', '\\n', '\\n', ')', '\\n', '\\n', '=', '\\n', '\\n', '\\n', '\\n', '\\xa0', '\\n', 's', '\\n', '\\n', '\\n', '*', '\\n', '\\n', '\\n', '(', '\\n', '0', '\\n', ')', '\\n', '\\n', '·', '\\n', 'exp', '\\n', '\\n', '(', '\\n', '\\n', '−', '\\n', 'b', '\\n', '\\xa0', '\\n', '·', '\\n', '\\n', '\\n', 'ADC', '\\n', '\\n', '*', '\\n', '\\n', '\\n', ')', '\\n', '\\n', ',', '\\n', '\\n', '\\n', '\\n', '\\n', '(2)', '\\n', '\\n', '\\nwhere ', '\\n', '\\n', '\\n', 'b', '\\n', 'c', '\\n', '\\n', '\\n', ' is the high b-value being extrapolated.', ' 2.2.2. Pre-Processing II: Registration', 'Image registration is used to align ADC maps and computed high b-value DWI to T2WI to account for voluntary/involuntary patient movement between T2WI and DWI acquisitions and differences in resolution. First, ADC maps are affinely registered to T2WI using the symmetric block matching algorithm [', '28', ']. Next, a non-rigid registration is applied to the transformed ADC map using the free-form deformation (FFD) algorithm [', '29', '], with the convolution-based fast local normalized correlation coefficient (LNCC) similarity measure to enable robustness to bias field inhomogeneity [', '30', ']. Finally, the transformation obtained from the composition of both types of registration is used to register computed high b-value DWI to T2WI.', ' 2.2.3. Pre-Processing III: Resampling, Cropping, and Normalization', 'T2WI, registered ADC map and computed high b-value DWI, and PZ and CG probability maps are resampled to a common in-plane resolution and cropped to a common in-plane shape, centred on the prostate; image cropping is used for memory efficiency. Then, T2WI and computed high b-value DWI are normalized by dividing voxel intensities by the interquartile mean of CG voxel intensities. Our approach is a modification of the normalization approach suggested by Bonekamp et al. [', '31', '], where voxel intensities were divided by the mean of PZ voxel intensities. We opt for normalization using CG voxel intensities since CG segmentations are typically more reliable than PZ segmentations [', '32', '], and we opt for the interquartile mean of CG voxel intensities as opposed to the mean of all CG voxel intensities, to remove extremes that may correspond to abnormalities unique to a patient. ADC maps were not normalized as they contain a quantitative measurement.', ' 2.2.4. CSPCa-U-Net-E', 'After pre-processing, each slice of a patient’s T2WI, ADC map, computed high b-value DWI, and PZ and CG probability maps are input channel-wise to an ensemble of 2D nnU-Nets for CSPCa lesion segmentation; the addition of PZ and CG guidance as input has been shown to increase CSPCa lesion detection performance as the occurrence and appearance of prostate cancer is dependent on its zonal location [', '33', ']. We refer to each constituent 2D nnU-Net as CSPCa-U-Net and the ensemble of CSPCa-U-Nets as CSPCa-U-Net-E. A detailed description of the CSPCa-U-Net architecture is given in ', 'Supplementary Section S2', '. In each CSPCa-U-Net, we model epistemic uncertainty using test-time dropout, following the approach in Kendall et al. [', '34', '], i.e., dropout layers are inserted after the central three encoder units and two decoder units, with dropout probability equal to P. We model aleatoric uncertainty using test-time augmentation as in Wang et al. [', '22', '].', 'The output of each CSPCa-U-Net is slice-wise CSPCa probability maps. Per-voxel averaging is used to combine the probability map outputs of each CSPCa-U-Net ∈ CSPCa-U-Net-E, followed by restacking of slices to form a probability map volume.', ' 2.2.5. Post-Processing', 'The CSPCa probability map output by CSPCa-U-Net-E is transformed to the original T2WI shape and voxel resolution using padding and resampling operations. Next, probabilities are calibrated using an isotonic regression calibration module [', '35', '], to allow more interpretable CSPCa likelihoods. CSPCa lesion segmentations are obtained by thresholding CSPCa probability maps using a cut-off value C; C is chosen during experimentation using training data to match AutoProstate’s detection sensitivity and specificity to that of an experienced radiologist. Finally, a false-positive reduction step is applied to remove connected components smaller than MinSize mm', '2', '.', ' 2.3. Report-Generator Module', 'The Report-Generator module generates an automatic report using input bpMRI and clinical data, and the outputs of the Zone-Segmenter and CSPCa-Segmenter modules; the report template is shown in ', 'Figure 2', '.', 'The left-hand pane contains interactive report elements including a patient selector and transverse, frontal, and sagittal views of zone and CSPCa lesion segmentation outputs overlaid on T2WI, with associated widgets for slice selection.', 'The topmost section of the main report interface is named ', 'Patient Details', '. This section includes ', 'Patient Name', ', ', 'Hospital Number', ', ', 'Date of Birth', ', ', 'Scan Date', ', ', 'Age', ' (years), and ', 'PSA', ' (ng/mL).', 'The second report section is named ', 'Prostate Size and PSA Density', '. This section presents calculated prostate lengths and volumes, and the PSAd. The ', 'Transverse', ', ', 'Anterior–Posterior', ', and ', 'Cranio–Caudal', ' lengths of the prostate, in cm, are calculated using the maximum extents of the prostate on the whole-prostate segmentation, where the whole-prostate segmentation is the union of the PZ and CG segmentations. ', 'Prostate Volume', ', ', 'Peripheral Zone Volume', ', and ', 'Central Gland Volume', ', in cm', '3', ', are calculated by multiplying voxel counts by voxel volume. The ', 'PSA Density', ' (ng/mL', '2', ') is calculated by dividing PSA by the calculated whole-prostate volume.', 'The third report section is named ', 'Clinically Significant Lesion Candidates', '. This section presents a listing of all detected CSPCa lesions, sorted in descending order of ', 'Probability of CSPCa', '. The ', 'Centroid Slice', ', ', 'Centroid Zone', ' (PZ or CG), and ', 'Centroid Region', ' (base, midgland, or apex) are determined based on the location of the lesion centroid; our region determination follows the methodology outlined by Litjens et al. [', '11', '] for evaluating the PROMISE12 Challenge, where the apex is defined as the caudal-most third of the prostate, the base is the cranio-most third of the prostate, and the midgland is the remaining portion. The ', 'Min ADC', ' (mm', '2', '/s) is calculated as the minimum ADC value inside the predicted CSPCa lesion contour. As in the ', 'Prostate Size and PSA Density', ' report section, ', 'Volume', ' (cm', '3', ') is calculated by multiplying voxel counts by voxel volume. Finally, the flag ', 'Extra-Capsular?', ' is set to true if the lesion contour protrudes beyond the whole-prostate contour, otherwise it is set to false.', 'The last section of the report is named ', 'Findings Summary', ', where key information (denoted xx in ', 'Figure 2', ') from other report sections is used to populate a template paragraph.', 'Following patient selection, the report is built using Streamlit (version 0.75.0; Available online: ', 'https://streamlit.io', ' (accessed on 21 January 2021). Streamlit is an open-source Python library for creating shareable interactive web applications.', ' 3. Experimental Setup', 'In this section, we describe the datasets used for training and testing AutoProstate, the methodological settings employed, and the evaluation measures used to assess performance.', ' 3.1. Patient Datasets', 'AutoProstate was trained using the publicly available PROSTATEx dataset [', '23', '], and externally validated using the Prostate Imaging Compared to Transperineal Ultrasound-guided biopsy for significant prostate cancer Risk Evaluation (PICTURE) study dataset [', '24', '].', ' 3.1.1. PROSTATEx Dataset', 'Details of the PROSTATEx dataset have previously been reported [', '36', ']. A total of 346 consecutive patient studies were downloaded from the PROSTATEx Challenges database [', '23', ']. The database features mpMRI for men examined at Radboud University Medical Center between 2011 and 2012.', 'MpMRI was acquired using two 3-Tesla magnetic field scanners (Magnetom Trio and Skyra, Siemens) and a pelvic-phased array coil. Sequences collected included T2WI, ADC map computed from DWI acquired at multiple b-values (50, 400, 800), and DCEI with a temporal resolution of 3.5 s. All mpMRI studies were reported by an experienced radiologist with over 20 years’ experience in reading prostate mpMRI, who highlighted areas of suspicion per modality with a point marker and scored them using PI-RADS v1. MR-guided targeted biopsies of marked points with PI-RADS v1 score ≥ 3 were performed, while marked points with PI-RADS v1 score 3 (unlikely for CSPCa) were not biopsied and assumed to be clinically insignificant (5% incidence of CSPCa in PI-RADS v1 3 lesions at Radboud University Medical Center). Subsequently, biopsy specimens were graded by a histopathologist. The marked point coordinate and a ground-truth label (clinically significant equal to true or false) for each marked lesion was released publicly for 204 of the 346 patients, hence only these 204 patients feature in our work; clinical and histopathological characteristics are shown in ', 'Table S1', '.', 'Whole-prostate, zonal, and lesion contours for the 204 patients were performed by an external group [', '37', ']. In summary, contours were produced in consensus by radiology residents (2 years’ experience in reading prostate mpMRI) and board-certified radiologists (5 years’ experience in reading prostate mpMRI) at the University of Naples. Radiology residents and board-certified radiologists worked in pairs for quality control and annotation. Whole-prostate and zonal contours (PZ and CG) were drawn for each patient. In addition, 299 lesions were delineated, including 76 CSPCa lesions and 223 low-grade or benign lesions (nCSPCa).', ' 3.1.2. PICTURE Dataset', 'Full details of the PICTURE study have previously been reported [', '24', ',', '38', ']. Men were examined at University College London Hospital between 2012 and 2014. Inclusion criteria for the PICTURE study were: (i) men who had undergone an initial standard transrectal ultrasound-guided (TRUS) biopsy, but concern remained over the accuracy of the subsequent diagnosis; and (ii) men suitable for further characterization using transperineal template prostate-mapping (TTPM) biopsy. Exclusion criteria were: (i) previous history of prostate cancer treatment; and (ii) lack of complete gland sampling or inadequate sampling density at TTPM.', 'MpMRI was acquired using a 3-Tesla magnetic field scanner (Achieva, Philips Healthcare) and a pelvic-phased array coil. Sequences collected included T2WI, DWI with high b-value (2000), ADC map computed from DWI acquired at multiple b-values (0, 150, 500, 1000), and DCEI with a temporal resolution of 13 s.', 'All mpMRI studies were reported by an experienced radiologist with 10 years’ experience in reading prostate mpMRI, using a five-point Likert impression scale for the likelihood of CSPCa [', '39', ']; CSPCa was defined as Gleason score ≥ 3 + 4. Scoring was completed at the lesion, sector, and patient-levels. Clinical information, including the referral PSA (ng/mL), was available to the radiologist during scoring to reflect clinical practice. Men underwent MR-guided targeted biopsy of focal index lesions and TTPM biopsy with 5 mm sampling as the reference standard. TTPM biopsy was used to overcome the inaccuracies of TRUS biopsy [', '1', '] and the selection bias towards men with aggressive disease associated to radical prostatectomy [', '40', ']. Altogether, 249 men completed mpMRI and TTPM biopsy.', 'In this work, two patients were removed due to missing MRI data. Clinical and histopathological characteristics for the 247 included patients are shown in ', 'Table S2', '.', 'Whole-prostate and zonal contours were drawn by a board-certified radiologist (E.W.J., 3 years’ experience in the quantitative analysis of prostate mpMRI), for 80 patients. Lesions were delineated by two board-certified radiologists (S.S. and N.G., 5 and 4-years’ experience in scoring prostate mpMRI using Likert assessment and PI-RADS v2, respectively), who drew contours on a subset of cases each. The protocol for lesion contouring was agreed between the radiologists beforehand. First, histopathology reports from MR-guided targeted and TTPM biopsies were reviewed alongside mpMRI to locate the highest Gleason grade focal lesion; if there were multiple focal lesions with the maximum Gleason grade, the highest scoring focal lesion according to Likert or PI-RADS v2 was identified. Next, a single axial T2WI slice was selected corresponding to the centre of the identified lesion. Then, all focal lesions on the selected slice were contoured. Additionally, focal benign lesions that were scored Likert or PI-RADS v2 ≥ 4 were contoured in patients that were biopsy-negative for cancer. A total of 210 lesions were delineated, including 147 CSPCa lesions and 63 nCSPCa lesions.', ' 3.2. Methodological Settings', 'In this section, we describe the training and inference settings used for conducting experiments with AutoProstate.', ' 3.2.1. Zone-Segmenter Module', 'T2WI were resampled to a common in-plane resolution of 0.4018 mm × 0.4018 mm and cropped to a common in-plane shape of 320 × 320.', 'A tenfold cross-validation analysis of Zone-U-Net was conducted using the PROSTATEx dataset to optimize training hyperparameters, loss function, and augmentations. Fold splits are shown in ', 'Table S3', '. Zone-U-Net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to eight, Adam optimization [', '41', '], an equally-weighted hybrid loss composed of Dice loss [', '8', '] and Focal loss [', '20', '], and horizontal flip (probability = 0.5), rotation (−20°, 20°), and scaling (−10%, 20%) augmentations.', 'Following the tenfold cross-validation, the ten trained Zone-U-Nets were used to construct Zone-U-Net-E; cross-validation ensembles have been shown to be an effective ensembling strategy [', '32', '].', ' 3.2.2. CSPCa-Segmenter Module', 'A high b-value, ', '\\n', '\\n', '\\n', 'b', '\\n', '\\n', '\\n', 'c', '\\n', '\\xa0', '\\n', '\\n', '\\n', '\\n', '=', '\\n', '2000', '\\n', '\\n', ', was selected for computing high b-value DWI as in Verma et al. [', '26', '].', 'The registration of ADC maps to T2WI employed default parameters for affine registration via symmetric block-matching. The subsequent non-rigid FFD registration used a Gaussian kernel with standard deviation equal to 5 mm for LNCC calculation, control point spacing equal to 10 mm, and bending energy constraint equal to 0.1. Registrations were run using NiftyReg (version 1.3; Available online: ', 'https://github.com/KCL-BMEIS/niftyreg', ' (accessed on 1 October 2018). Through visual inspection, satisfactory registration was observed for the majority of PROSTATEx and PICTURE dataset cases. No manual steps were taken to correct any instances of misregistration, and cases with misregistration were not excluded from our analysis.', 'T2WI, registered ADC maps and computed b2000 (Cb2000) DWI, and PZ and CG probability maps, were resampled to a common in-plane resolution of 0.4018 mm × 0.4018 mm and cropped to a common in-plane shape of 256 × 256, centred on the prostate.', 'Like Zone-U-Net, the training settings for CSPCa-U-Net were determined through tenfold cross-validation using the PROSTATEx dataset with the fold splits shown in ', 'Table S3', '. CSPCa-U-Net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to 12, Adam optimization, a dropout probability of ', '\\n', '\\n', '\\n', 'P', '\\n', '\\xa0', '\\n', '\\n', '=', '\\n', '0.2', '\\n', '\\n', ' for central dropout, a hybrid loss composed of the sum of Dice loss multiplied by 0.5 and Focal loss multiplied by 1.0, and horizontal flip (probability = 0.5), rotation (−20°, 20°), and scaling (−10%, +20%) augmentations. The same dropout probability and augmentation settings were used for test-time dropout and test-time augmentation.', 'CSPCa probability maps output by CSPCa-U-Net for each fold were calibrated using separate isotonic calibration modules for each fold. Following calibration, CSPCa probability maps were thresholded using cut-off values determined for each fold, corresponding to a lesion-level sensitivity of 93% and specificity of 37%, in the fold’s training set. The aforementioned sensitivity and specificity correspond to reference radiologist performance at PI-RADS v1 cut-off ≥ 4 on a separate patient cohort from Radboud Medical Center, reported on in Litjens et al. [', '42', '], which was used since prospective radiologist performance was not available for the PROSTATEx dataset. As a final post-processing step, connected components smaller than 40 mm', '3', ' were removed. UK National Institute for Health and Care Excellence (NICE) guidelines recommend a minimum size of 200 mm', '3', ' for CSPCa lesions [', '43', ']; we picked a minimum size of 40 mm', '3', ' (20% of 200 mm', '3', ') considering some CSPCa lesions may only be partially segmented.', 'Following the tenfold cross-validation, the ten trained CSPCa-U-Nets were used to construct CSPCa-U-Net-E. CSPCa-U-Net-E was calibrated using isotonic calibration. For thresholding, a cut-off value C = 4.5% was determined to match radiologist performance in the training set for CSPCa-U-Net-E i.e., the entire PROSTATEx dataset. For false-positive reduction, connected components smaller than 40 mm', '3', ' were removed, as in the cross-validation analysis.', ' 3.3. AutoProstate External Validation Evaluation Measures', 'Whole-prostate and zonal segmentations were evaluated using the Dice coefficient. Prostate size measurements (transverse, anterior–posterior, and cranio–caudal lengths), as well as whole-prostate and zonal volumes, were evaluated using the Abs%Err; the ground-truth lengths and volumes used in the calculation of Abs%Err were derived from the manually-drawn whole-prostate and zonal contours. The PSAd estimated by AutoProstate was evaluated using absolute error (AbsErr), since the absolute value of PSAd has a meaning relative to risk definitions [', '43', ']; the ground-truth PSAd value used in the calculation of AbsErr was obtained by dividing PSA by the whole-prostate volume calculated using the manually-drawn whole-prostate contour. The aforementioned evaluation metrics were calculated over the 80 patients from the PICTURE dataset for which manually drawn whole-prostate and zonal segmentations were available.', 'Receiver operating characteristic (ROC) area under the curve (AUC) and precision-recall (PR) AUC were calculated to quantify AutoProstate’s ability to differentiate between CSPCa lesions and nCSPCa lesions. After thresholding and false-positive reduction, sensitivity, specificity, and precision were calculated at lesion-level and average false positives were calculated at patient-level. For the PICTURE dataset, the calculation of average false positives was made using 93 patients who were biopsy-negative for CSPCa, due to limitations in the ground-truth prohibiting false-positive determination in biopsy positive patients. In addition, CSPCa lesion Dice and Abs%Err of lesion area were calculated on slices containing a contour.', 'Prostate volume, PSAd, and lesion detection metrics computed for AutoProstate were compared to the same metrics calculated for an experienced radiologist (S.P., 10 years’ experience in scoring prostate mpMRI) who prospectively filled out a case report for each patient. Prostate volume was estimated using the ellipsoid formula and lesions were scored using a five-point Likert scale [', '39', ']. Statistical tests were used to compare the performances of AutoProstate and the experienced radiologist. The Wilcoxon’s signed-rank test [', '44', '] was used to statistically compare prostate volume and PSAd estimates, DeLong’s test [', '45', '] was used to statistically compare lesion ROC AUC, McNemar’s test [', '46', '] was used to statistically compare sensitivity and specificity, the weighted generalized score (WGS) test statistic [', '47', '] was used to statistically compare precision, and Wilcoxon’s signed-rank test was used to statistically compare average false positives.', ' 4. Results', 'AutoProstate, trained using the PROSTATEx dataset, was externally validated using the PICTURE dataset. This section presents the results of the cross-validation of Zone-U-Net and CSPCa-U-Net (the building blocks of AutoProstate) and a detailed analysis of the external validation of AutoProstate using the PICTURE dataset, with comparisons made to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpMRI, where possible.', ' 4.1. Zone-U-Net and CSPCa-U-Net Tenfold Cross-Validation', 'Using the settings described in ', 'Section 3.2.1', '., Zone-U-Net achieved mean Dice coefficients of 0.78, 0.86, and 0.91 for PZ, CG, and whole-prostate segmentation, respectively.', 'Using the settings described in ', 'Section 3.2.2', '., CSPCa-U-Net achieved a mean ROC AUC of 0.85 and a mean PR AUC of 0.70. After thresholding, CSPCa-U-Net achieved a mean sensitivity of 93%, a mean specificity of 37%, a mean precision of 34%, and a mean false-positive count per patient of 6.9. Following false-positive reduction, mean sensitivity dropped marginally to 92%, mean specificity increased to 46%, mean precision increased to 37%, and mean false positives per patient dropped significantly to 3.3 (', 'p', ' 0.01). Furthermore, CSPCa-U-Net achieved a mean Dice coefficient of 0.39 for CSPCa lesion segmentation.', ' 4.2. AutoProstate External Validation Analysis: Whole-Prostate and Zonal Segmentations, Prostate Size Measurements, and PSA Density', 'Table 1', ' and ', 'Figure 3', ' present summaries of the distribution of Dice coefficients for whole-prostate and zonal segmentations, the distribution of Abs%Err for prostate size measurements, and the distribution of AbsErr for PSAd calculation, for 80 patients from the PICTURE dataset for which ground-truth segmentations were available.', 'Mean Dice coefficients of 0.75, 0.80, and 0.89 were obtained for the PZ, CG, and whole-prostate, respectively. AutoProstate’s Zone-Segmenter module found PZ segmentation a more difficult task than CG segmentation, while whole-prostate segmentation had a higher mean Dice coefficient than both zonal segmentations, suggesting an ease of distinguishing prostate tissue from background tissues, but a difficulty in distinguishing between PZ and CG tissue. As expected, the mean Dice coefficients for the PZ, CG, and whole-prostate segmentations were lower than those obtained on the PROSTATEx dataset during the tenfold cross-validation of Zone-U-Net (0.78, 0.86, and 0.91 for PZ, CG, and whole-prostate segmentation, respectively) which may be indicative of a generalization gap due to acquisition/population differences.', 'The transverse, anterior–posterior, and cranio–caudal lengths of the prostate were estimated using the whole-prostate segmentation output by Zone-Segmenter. Mean Abs%Err of 3%, 5%, and 20% were obtained for transverse, anterior–posterior, and cranio–caudal lengths, respectively. In addition to the lowest mean Abs%Err, the transverse length had a smaller standard deviation than anterior–posterior and cranio–caudal lengths. Through visual inspection of segmentation outputs, we attribute the variability in the accuracy of the anterior–posterior measurement to the difficulty of determining prostate extent in the anterior fibromuscular stroma, and similarly, we attribute the variability in the accuracy of the cranio–caudal measurement to the difficulty of determining prostate extent at the base and apex regions of the prostate. Strikingly, a large maximum Abs%Err of 100% was observed for the cranio–caudal measurement, due to under-segmentation of the base region in the ground-truth.', 'PZ, CG, and whole-prostate volumes were calculated using the PZ, CG, and whole-prostate segmentations output by Zone-Segmenter. Mean Abs%Errs of 12%, 18%, and 9% were obtained for PZ, CG, and whole-prostate volumes, respectively. Strikingly, a large maximum Abs%Err of 112% was observed for the CG, which was found to be due to over-segmentation of the CG in the base region.', 'We compare the Abs%Err of the whole-prostate volume calculated by AutoProstate to the same calculated by the experienced radiologist who used the ellipsoid formula, which is clinically advocated. AutoProstate had a mean Abs%Err of 9%, while the experienced radiologist’s mean Abs%Err was 13%; the difference was statistically significant (', 'p', ' 0.05). Using the whole-prostate volumes computed by AutoProstate and the experienced radiologist, PSAd was calculated. AutoProstate achieved a mean AbsErr of 0.019, while the experienced radiologist’s mean AbsErr was 0.031; again, the difference was statistically significant (', 'p', ' 0.05).', ' 4.3. AutoProstate External Validation Analysis: Clinically Significant Prostate Cancer Lesion Detection and Segmentation', 'CSPCa lesion detection performance for AutoProstate and the experienced radiologist are shown in ', 'Table 2', ', while ', 'Figure 4', ' shows the ROC and PR curves for AutoProstate and the radiologist.', 'AutoProstate achieved a mean ROC AUC of 0.70 and a mean PR AUC of 0.84, calculated using output CSPCa probability maps prior to thresholding. After thresholding the CSPCa probability maps using a cut-off value equal to 4.5%, the following were obtained: a sensitivity of 78%, a specificity of 49%, a precision of 78%, and a mean false-positive count of 6.1. Following false-positive reduction, mean sensitivity dropped marginally to 76%, mean specificity increased to 57%, mean precision increased marginally to 80%, and the mean false-positive count per patient dropped to 2.5.', 'Likert scores assigned to suspicious lesions by the experienced radiologist were used to calculate ROC and PR curves; radiologist Likert scoring gave a ROC AUC of 0.64 and PR AUC of 0.78. After thresholding at cut-off score Likert ≥ 4, the following were obtained: a sensitivity of 78%, a specificity of 48%, a precision of 78%, and a mean false-positive count of 0.3. Differences between the ROC AUC, PR AUC, sensitivity, specificity, and precision of AutoProstate and the experienced radiologist were not statistically significant. However, the difference between mean false positives was statistically significant (', 'p', ' 0.001).', 'A further analysis was completed to assess the level of agreement between AutoProstate and the experienced radiologist’s Likert scores, on annotated lesions, as shown in ', 'Table S4', '. For CSPCa lesions, there was a 78% (114/147) concordance between AutoProstate and the experienced radiologist, while for nCSPCa lesions, there was a 62% (39/63) concordance.', 'AutoProstate’s lesion segmentations enable the calculation of lesion volume and lesion minimum ADC. Lesion segmentation accuracy, evaluated using the Dice coefficient, was calculated using slices containing a corresponding ground-truth CSPCa lesion contour. The following Dice coefficient metrics were obtained: a mean of 0.46 (SD: 0.32), a median of 0.58 (IQR: 0.10–0.72), and a min–max range of 0.00–0.90. Several example CSPCa lesion segmentations are presented in ', 'Figure 5', '. Examples are shown in the PZ and CG, and in the base, midgland, and apex regions of the prostate. In addition, examples have been included to demonstrate AutoProstate’s robustness to magnetic susceptibility artifacts. Furthermore, an example automatic report generated by AutoProstate is shown in ', 'Figure 6', '.', ' 5. Discussion', 'In this work, we introduced AutoProstate, a deep learning-powered framework for automatic MRI-based prostate cancer assessment. AutoProstate consists of three modules: Zone-Segmenter, CSPCa-Segmenter, and Report-Generator. The output of AutoProstate is an automatic web-based report that presents patient details, prostate size measurements and PSAd, a listing of candidate CSPCa lesions with derived characteristics, and a findings summary. AutoProstate, trained using the publicly available PROSTATEx dataset, was externally validated using the PICTURE dataset. During the external validation, the performance of AutoProstate was compared to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpMRI, who prospectively estimated prostate volume and PSAd using the ellipsoid formula, and scored lesions using a five-point Likert scale.', 'PZ, CG, and whole-prostate segmentations are output by AutoProstate’s Zone-Segmenter module. During the experimental setup phase, we tested Zone-U-Net, prior to ensembling of Zone-U-Nets to form Zone-U-Net-E. Zone-U-Net achieved mean Dice coefficients of 0.78, 0.86, and 0.91 for PZ, CG, and whole-prostate segmentation, respectively, in tenfold cross-validation using the PROSTATEx dataset. Our result compares well to recent works by Aldoj et al. [', '6', '], where their proposed Dense-2 U-Net CNN was evaluated using fourfold cross-validation of a 188-patient subset from the PROSTATEx dataset, and to a recent work by Cuocolo et al. [', '7', '], where the previously proposed ENet CNN [', '48', '] was evaluated using a 105-patient test set from the PROSTATEx dataset. Aldoj et al. obtained mean Dice coefficients of 0.78, 0.91, and 0.92, and Cuocolo et al. obtained mean Dice coefficients of 0.71, 0.87, and 0.91, for PZ, CG, and whole-prostate segmentation, respectively. However, direct comparison between our work and the works of Aldoj et al. and Cuocolo et al. is not possible due to the use of different subsets of data for testing. During the external validation of AutoProstate using the PICTURE dataset, where Zone-U-Net-E was used for PZ, CG, and whole-prostate segmentation, AutoProstate achieved mean Dice coefficients of 0.75, 0.80, and 0.89, respectively, on 80 patients for which ground-truth segmentations were available. Antonelli et al. [', '49', '] previously reported segmentation results for the PICTURE dataset. A multi-atlas segmentation approach featuring a novel genetic atlas selection strategy was proposed; mean Dice coefficients of 0.72 and 0.83 were reported for PZ and CG segmentation, using leave-one-out cross-validation, and a mean Dice coefficient of 0.83 was reported for whole-prostate segmentation, using atlases from the PROMISE12 dataset [', '11', '].', 'An accurate whole-prostate segmentation is crucial for downstream calculations of prostate volume and PSAd [', '50', ']. AutoProstate’s estimate of prostate volume was compared to an estimate obtained using the ellipsoid formula, which is clinically advocated [', '51', ']. AutoProstate achieved a mean Abs%Err of 9%, while the radiologist computed ellipsoid formula estimate had a mean Abs%Err of 13%. Notably, the difference in mean Abs%Err was statistically significant (', '\\n', '\\n', 'p', '\\n', '=', '\\n', '0.0051', '\\n', '<', '\\n', '0.05', '\\n', ')', '\\n', '\\n', '. Furthermore, we compared PSAd estimates obtained using the volume estimates; we found a mean AbsErr of 0.019 for AutoProstate and a mean AbsErr of 0.031 for the radiologist; again, the difference was statistically significant (', '\\n', '\\n', 'p', '\\n', '=', '\\n', '0.0018', '\\n', '<', '\\n', '0.05', '\\n', ')', '\\n', '\\n', '. Since PSAd is used clinically to inform the decision to biopsy or to discharge patients [', '52', '] and furthermore, to monitor patients on active surveillance, as recommended by NICE guidelines in the UK [', '43', '], we believe a case exists for replacement of the ellipsoid formula with automated methods such as ours.', 'AutoProstate’s foremost purpose is to detect and segment CSPCa lesions. During the experimental setup phase, we tested CSPCa-U-Net, prior to ensembling of CSPCa-U-Nets to form CSPCa-U-Net-E. Markedly, CSPCa-U-Net achieved a lesion-level mean ROC AUC of 0.85 in tenfold cross-validation using the PROSTATEx dataset, while previous studies have reported a lesion-level mean ROC AUC of 0.81 on the same subset of PROSTATEx data used in this study, using the same input modalities. During the external validation of AutoProstate using the PICTURE dataset, where CSPCa-U-Net-E was used to segment CSPCa lesions, AutoProstate achieved a lesion-level ROC AUC of 0.70. Notably, we observed a large reduction in ROC AUC on the PICTURE dataset from that seen during the PROSTATEx dataset tenfold cross-validation. We believe that the main reason for the reduction in ROC AUC is the use of TTPM biopsy in the PICTURE study, which allowed lesions that were not prospectively identified by the radiologist, to be retrospectively contoured using TTPM biopsy findings. Other reasons may include a high occurrence of magnetic susceptibility artifacts on DWI in the PICTURE dataset and a possible generalization gap between training data and external testing data due to population/acquisition differences. On the PICTURE dataset, radiologist Likert assessment achieved a lesion-level ROC AUC of 0.64; the difference in ROC AUC between AutoProstate and the experienced radiologist was not statistically significant. Following thresholding and false-positive reduction, AutoProstate achieved a lesion-level sensitivity of 76%, a lesion-level specificity of 57%, and 2.5 false positives per patient (calculated over patients without CSPCa, only). In comparison, radiologist Likert assessment thresholded at Likert ≥ 4, achieved a lesion-level sensitivity of 78%, a lesion-level specificity of 48%, and 0.3 false positives per patient (calculated over patients without CSPCa, only); only the difference between the number of false positive detections by AutoProstate and the experienced radiologist was statistically significant (', '\\n', '\\n', 'p', '\\n', '\\n', '0.001', '\\n', '\\n', '). While AutoProstate has demonstrated an ability to differentiate between CSPCa lesions and low-grade/benign lesions at the level of an experienced radiologist, further work is needed to reduce the number of false positives produced. Interestingly, AutoProstate achieved a similar sensitivity and improved specificity compared to the radiologist on annotated CSPCa and nCSPCa lesions but had a higher overall false-positive count. Therefore, it’s possible that the additional false positives produced by AutoProstate, that were not prospectively scored by the radiologist, may be easy for radiologists to rule-out.', 'Several aspects of this study have been guided by the set of nine key considerations for authors, reviewers, and readers of artificial intelligence studies in radiology by Bluemke et al. [', '25', ']. As recommended, we maintained a clear separation between training data and testing data. In particular, we avoided a common pitfall observed in previous studies [', '12', ',', '15', '], by determining the probability cut-off value using training data, rather than a biased approach involving the test data itself. In line with further recommendations by Bluemke et al., we were able to externally validate AutoProstate using the PICTURE dataset. Furthermore, the PICTURE dataset was acquired using Phillips’ scanners, while the PROSTATEx dataset, used to train AutoProstate, was acquired using Siemens’ scanners, meaning a further recommendation on using multivendor data for evaluation was met. Moreover, we compared AutoProstate to an expert radiologist who prospectively reported PICTURE dataset patients, and both AutoProstate and the radiologist were compared to an accepted reference standard which combined TTPM and MR-guided targeted biopsies; TTPM biopsy is highly accurate and avoids biases associated to MR-guided targeted biopsy, transrectal ultrasound-guided (TRUS) biopsy, and prostatectomy [', '24', '].', 'CAD system studies should describe how the CAD system will be deployed clinically, so future prospective trials can be planned accordingly. Our goal in this study was to understand the strengths, weaknesses, and idiosyncrasies of AutoProstate through a comparison against an experienced radiologist. In the clinical workflow, we envision AutoProstate as a radiologist companion system during clinical reads to allow enhanced clinical reporting. It should be acknowledged that current CAD systems for MRI-based prostate cancer diagnosis contain varying degrees of error in terms of producing too many false positives, false negatives, or both. Since the automatic report produced by AutoProstate presents visual segmentation outputs, as well as derived measurements, all outputs produced by AutoProstate can be rapidly verified by the radiologist. In particular, automatic report information deemed to be accurate can be used to prepare the patient’s clinical report, while erroneous information can be recalculated using current clinical methods or ignored if not required.', 'There were three limitations in our study. Firstly, our training data was limited to 76 CSPCa lesions and 223 nCSPCa lesions; we may expect improved detection sensitivity and reduced false positives if a bigger training dataset with more lesions is available. Secondly, our external validation was limited to a single external site. Thirdly, lesion contours for each PICTURE dataset patient were drawn by a single radiologist only. While the location and Gleason score of lesions was confirmed by a combination of TTPM and MR-guided targeted biopsies, we were not able to overcome the inter-reader variation known to exist in lesion boundary determination [', '53', '].', 'Our future work will be to perform a prospective validation of Autoprostate. In particular, we will plan a clinical trial that investigates the impact of the automatic report on the prospective clinical read of radiologists of varying levels of experience. In preparation for the prospective validation, we will seek a larger multi-centre and multi-vendor training dataset.', ' 6. Conclusions', 'In this work, we presented AutoProstate for automatic MRI-based prostate cancer assessment. External validation using the PICTURE dataset demonstrated statistically significant improvements in prostate volume and PSA density estimation and no statistically significant differences in CSPCa lesion detection performance, when compared to an experienced radiologist with over 10 years’ experience in reading prostate mpMRI. However, further work is needed to reduce the number of false positives produced by AutoProstate, prior to prospective validation.', '\\n', '\\n', '\\n', ' Supplementary Materials', 'The following are available online at ', 'https://www.mdpi.com/article/10.3390/cancers13236138/s1', ', Section S1: Zone-U-Net Architecture, Section S2: CSPCa-U-Net Architecture, Table S1: PROSTATEx dataset characteristics, Table S2: PICTURE dataset characteristics, Table S3: Ten-fold cross-validation fold split of the PROSTATEx dataset. Lesion significance, size, and zone were used for fold stratification.', 'Author Contributions', 'Conceptualization, P.M., M.A. and S.O.; methodology, P.M. and M.A.; software, P.M.; formal analysis, P.M. and M.A.; data curation, P.M., M.A., S.S., N.G., E.W.J., H.U.A., M.E. and S.P.; writing—original draft preparation, P.M.; writing—review and editing, P.M., M.A., S.S., N.G., E.W.J., H.U.A., M.E., S.P. and S.O.; supervision, M.A., S.P. and S.O. All authors have read and agreed to the published version of the manuscript.', 'Funding', 'This research received no external funding.', 'Institutional Review Board Statement', 'Our Institutional Review Board approved the study and waived the requirement for individual consent for retrospective analysis of prospectively acquired patient data collected as part of clinical trials/routine care (RD No: 12/0195, 16 July 2012).', 'Informed Consent Statement', 'Not applicable.', 'Data Availability Statement', 'PROSTATEx dataset data citation: Geert Litjens, Oscar Debats, Jelle Barentsz, Nico Karssemeijer, and Henkjan Huisman. “ProstateX Challenge data”, The Cancer Imaging Archive (2017). DOI: 10.7937/K9TCIA.2017.MURS5CL. PROSTATEx dataset masks citation: R. Cuocolo, A. Stanzione, A. Castaldo, D.R. De Lucia, M. Imbriaco, Quality control and whole-gland, zonal and lesion annotations for the PROSTATEx challenge public dataset, Eur. J. Radiol. (2021).', 'Acknowledgments', 'P.M.’s research is supported by the Engineering and Physical Sciences Research Council (EPSRC) [EP/R512400/1]. P.M.’s work was additionally supported by the EPSRC-funded UCL Centre for Doctoral Training in Intelligent, Integrated Imaging in Healthcare (i4health) [EP/S021930/1]. M.A.’s research is supported by the Wellcome/EPSRC Centre for Medical Engineering King’s College London and by the London Medical Imaging and AI Centre for Value-Based Healthcare. H.U.A.’s research is supported by core funding from the UK’s National Institute of Health Research (NIHR) Imperial Biomedical Research Centre. HUA currently also receives funding from the Wellcome Trust, Medical Research Council (UK), Cancer Research UK, Prostate Cancer UK, The Urology Foundation, BMA Foundation, Imperial Health Charity, Sonacare Inc., Trod Medical and Sophiris Biocorp for trials in prostate cancer. M.E. and S.P. receive research support from the University College London/University College London Hospital (UCL/UCLH) Biomedical Research Centre.', 'Conflicts of Interest', 'H.U.A. is a paid consultant to Boston Scientific for teaching and training on Rezum for benign prostate hyperplasia treatment and cryotherapy for prostate cancer treatment and is paid for teaching and proctoring HIFU for treating prostate cancer. M.E. receives honoraria from consulting, educational activities, and training from: Sonacare Inc.; NINA Medical; and Angiodynamics Inc. All other authors declare no conflicts of interest.', 'References', 'Ahmed, H.U.; El-Shater Bosaily, A.; Brown, L.C.; Gabe, R.; Kaplan, R.; Parmar, M.K.; Collaco-Moraes, Y.; Ward, K.; Hindley, R.G.; Freeman, A.; et al. Diagnostic accuracy of multi-parametric MRI and TRUS biopsy in prostate cancer (PROMIS): A paired validating confirmatory study. ', 'Lancet', ' ', '2017', ', ', '389', ', 815–822. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Brembilla, G.; Dell’Oglio, P.; Stabile, A.; Damascelli, A.; Brunetti, L.; Ravelli, S.; Cristel, G.; Schiani, E.; Venturini, E.; Grippaldi, D.; et al. Interreader variability in prostate MRI reporting using Prostate Imaging Reporting and Data System version 2.1. ', 'Eur. Radiol.', ' ', '2020', ', ', '30', ', 3383–3392. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Stanzione, A.; Ponsiglione, A.; Di Fiore, G.A.; Picchi, S.G.; Di Stasi, M.; Verde, F.; Petretta, M.; Imbriaco, M.; Cuocolo, R. Prostate Volume Estimation on MRI: Accuracy and Effects of Ellipsoid and Bullet-Shaped Measurements on PSA Density. ', 'Acad. Radiol.', ' ', '2021', ', ', '28', ', e219–e226. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Distler, F.A.; Radtke, J.P.; Bonekamp, D.; Kesch, C.; Schlemmer, H.-P.; Wieczorek, K.; Kirchner, M.; Pahernik, S.; Hohenfellner, M.; Hadaschik, B.A. The Value of PSA Density in Combination with PI-RADS', 'TM', ' for the Accuracy of Prostate Cancer Prediction. ', 'J. Urol.', ' ', '2017', ', ', '198', ', 575–582. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Yang, X.; Lei, Y.; Wang, T.; Jiang, X.; Jani, A.; Mao, H.; Curran, W.; Patel, P.; Liu, T.; Wang, B. 3D prostate segmentation in MR image using 3D deeply supervised convolutional neural networks. ', 'Med. Phys.', ' ', '2018', ', ', '45', ', e582–e583. [', 'Google Scholar', ']', 'Aldoj, N.; Biavati, F.; Michallek, F.; Stober, S.; Dewey, M. Automatic prostate and prostate zones segmentation of magnetic resonance images using DenseNet-like U-net. ', 'Sci. Rep.', ' ', '2020', ', ', '10', ', 1–17. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Cuocolo, R.; Comelli, A.; Stefano, A.; Benfante, V.; Dahiya, N.; Stanzione, A.; Castaldo, A.; De Lucia, D.R.; Yezzi, A.; Imbriaco, M. Deep Learning Whole-Gland and Zonal Prostate Segmentation on a Public MRI Dataset. ', 'J. Magn. Reson. Imaging', ' ', '2021', ', 1–8. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Milletari, F.; Navab, N.; Ahmadi, S. V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation. In Proceedings of the Fourth International Conference on 3D Vision (3DV), Stanford, CA, USA, 25–28 October 2016. [', 'Google Scholar', ']', 'Comelli, A.; Dahiya, N.; Stefano, A.; Vernuccio, F.; Portoghese, M.; Cutaia, G.; Bruno, A.; Salvaggio, G.; Yezzi, A. Deep Learning-Based Methods for Prostate Segmentation in Magnetic Resonance Imaging. ', 'Appl. Sci.', ' ', '2021', ', ', '11', ', 782. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Lee, D.K.; Sung, D.J.; Kim, C.-S.; Heo, Y.; Lee, J.Y.; Park, B.J.; Kim, M.J. Three-Dimensional Convolutional Neural Network for Prostate MRI Segmentation and Comparison of Prostate Volume Measurements by Use of Artificial Neural Network and Ellipsoid Formula. ', 'Am. J. Roentgenol.', ' ', '2020', ', ', '214', ', 1229–1238. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Litjens, G.; Toth, R.; van de Ven, W.; Hoeks, C.; Kerkstra, S.; van Ginneken, B.; Vincent, G.; Guillard, G.; Birbeck, N.; Zhang, J.; et al. Evaluation of prostate segmentation algorithms for MRI: The PROMISE12 challenge. ', 'Med. Image Anal.', ' ', '2014', ', ', '18', ', 359–373. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Cao, R.; Mohammadian Bajgiran, A.; Afshari Mirak, S.; Shakeri, S.; Zhong, X.; Enzmann, D.; Raman, S.; Sung, K. Joint Prostate Cancer Detection and Gleason Score Prediction in mp-MRI via FocalNet. ', 'IEEE Trans. Med. Imaging', ' ', '2019', ', ', '38', ', 2496–2506. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Giannini, V.; Mazzetti, S.; Armando, E.; Carabalona, S.; Russo, F.; Giacobbe, A.; Muto, G.; Regge, D. Multiparametric magnetic resonance imaging of the prostate with computer-aided detection: Experienced observer performance study. ', 'Eur. Radiol.', ' ', '2017', ', ', '27', ', 4200–4208. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Schelb, P.; Kohl, S.; Radtke, J.P.; Wiesenfarth, M.; Kickingereder, P.; Bickelhaupt, S.; Kuder, T.A.; Stenzinger, A.; Hohenfellner, M.; Schlemmer, H.-P.; et al. Classification of Cancer at Prostate MRI: Deep Learning versus Clinical PI-RADS Assessment. ', 'Radiology', ' ', '2019', ', ', '293', ', 607–617. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Thon, A.; Teichgraber, U.; Tennstedt-Schenk, C.; Hadjidemetriou, S.; Winzler, S.; Malich, A.; Papageorgiou, I. Computer aided detection in prostate cancer diagnostics: A promising alternative to biopsy? A retrospective study from 104 lesions with histological ground truth. ', 'PLoS ONE', ' ', '2017', ', ', '12', ', e0185995. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Greer, M.D.; Lay, N.; Shih, J.H.; Barrett, T.; Bittencourt, L.K.; Borofsky, S.; Kabakus, I.; Law, Y.M.; Marko, J.; Shebel, H.; et al. Computer-aided diagnosis prior to conventional interpretation of prostate mpMRI: An international multi-reader study. ', 'Eur. Radiol.', ' ', '2018', ', ', '28', ', 4407–4417. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Gaur, S.; Lay, N.; Harmon, S.A.; Doddakashi, S.; Mehralivand, S.; Argun, B.; Barrett, T.; Bednarova, S.; Girometti, R.; Karaarslan, E.; et al. Can computer-aided diagnosis assist in the identification of prostate cancer on prostate MRI? A multi-center, multi-reader investigation. ', 'Oncotarget', ' ', '2018', ', ', '9', ', 33804–33817. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Zhu, L.; Gao, G.; Liu, Y.; Han, C.; Liu, J.; Zhang, X.; Wang, X. Feasibility of integrating computer-aided diagnosis with structured reports of prostate multiparametric MRI. ', 'Clin. Imaging', ' ', '2020', ', ', '60', ', 123–130. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Ronneberger, O.; Fischer, P.; Brox, T. U-Net: Convolutional Networks for Biomedical Image Segmentation. In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Munich, Germany, 5–9 October 2015; Springer: Cham, Switzerland, 2015; pp. 234–241. [', 'Google Scholar', ']', 'Zhu, W.; Huang, Y.; Zeng, L.; Chen, X.; Liu, Y.; Qian, Z.; Du, N.; Fan, W.; Xie, X. AnatomyNet: Deep learning for fast and fully automated whole-volume segmentation of head and neck anatomy. ', 'Med. Phys.', ' ', '2019', ', ', '46', ', 576–589. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Gal, Y.; Ghahramani, Z. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In Proceedings of the 33rd International Conference on Machine Learning, ICML 2016, New York, NY, USA, 20–22 June 2016; Volume 48, pp. 1651–1660. [', 'Google Scholar', ']', 'Wang, G.; Li, W.; Aertsen, M.; Deprest, J.; Ourselin, S.; Vercauteren, T. Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks. ', 'Neurocomputing', ' ', '2019', ', ', '338', ', 34–45. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Litjens, G.; Debats, O.; Barentsz, J.; Karssemeijer, N.; Huisman, H. ProstateX Challenge data. ', 'Cancer Imaging Arch.', ' ', '2017', '. [', 'Google Scholar', ']', 'Simmons, L.A.M.; Kanthabalan, A.; Arya, M.; Briggs, T.; Barratt, D.; Charman, S.C.; Freeman, A.; Gelister, J.; Hawkes, D.; Hu, Y.; et al. The PICTURE study: Diagnostic accuracy of multiparametric MRI in men requiring a repeat prostate biopsy. ', 'Br. J. Cancer', ' ', '2017', ', ', '116', ', 1159–1165. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Bluemke, D.A.; Moy, L.; Bredella, M.A.; Ertl-Wagner, B.B.; Fowler, K.J.; Goh, V.J.; Halpern, E.F.; Hess, C.P.; Schiebler, M.L.; Weiss, C.R. Assessing radiology research on artificial intelligence: A brief guide for authors, reviewers, and readers-From the Radiology Editorial Board. ', 'Radiology', ' ', '2020', ', ', '294', ', 487–489. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Verma, S.; Sarkar, S.; Young, J.; Venkataraman, R.; Yang, X.; Bhavsar, A.; Patil, N.; Donovan, J.; Gaitonde, K. Evaluation of the impact of computed high b-value diffusion-weighted imaging on prostate cancer detection. ', 'Abdom. Radiol.', ' ', '2016', ', ', '41', ', 934–945. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Blackledge, M.D.; Leach, M.O.; Collins, D.J.; Koh, D.-M.; May, I.; Tumor, I.; Blackledge, M.D.; Leach, M.O.; Collins, D.J. Computed Diffusion-weighted MR Imaging May Improve Tumor Detection. ', 'Radiology', ' ', '2011', ', ', '261', ', 573–581. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Ourselin, S.; Roche, A.; Subsol, G.; Pennec, X.; Ayache, N. Reconstructing a 3D structure from serial histological sections. ', 'Image Vis. Comput.', ' ', '2001', ', ', '19', ', 25–31. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Modat, M.; Ridgway, G.R.; Taylor, Z.A.; Lehmann, M.; Barnes, J.; Hawkes, D.J.; Fox, N.C.; Ourselin, S. Fast free-form deformation using graphics processing units. ', 'Comput. Methods Programs Biomed.', ' ', '2010', ', ', '98', ', 278–284. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Cachier, P.; Bardinet, E.; Dormont, D.; Pennec, X.; Ayache, N. Iconic feature based nonrigid registration: The PASHA algorithm. ', 'Comput. Vis. Image Underst.', ' ', '2003', ', ', '89', ', 272–298. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Bonekamp, D.; Kohl, S.; Wiesenfarth, M.; Schelb, P.; Radtke, J.P.; Gotz, M.; Kickingereder, P.; Yaqubi, K.; Hitthaler, B.; Gahlert, N.; et al. Radiomic Machine Learning for Characterization of Prostate Lesions with MRI: Comparison to ADC Values. ', 'Radiology', ' ', '2018', ', ', '289', ', 128–137. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Isensee, F.; Petersen, J.; Klein, A.; Zimmerer, D.; Jaeger, P.F.; Kohl, S.; Wasserthal, J.; Koehler, G.; Norajitra, T.; Wirkert, S.; et al. nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation. ', 'arXiv', ' ', '2018', ', arXiv:1809.10486. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Hosseinzadeh, M.; Brand, P.; Huisman, H. Effect of Adding Probabilistic Zonal Prior in Deep Learning-based Prostate Cancer Detection. In Proceedings of the Medical Imaging with Deep Learning (MIDL), London, UK, 8–10 July 2019. [', 'Google Scholar', ']', 'Kendall, A.; Badrinarayanan, V.; Cipolla, R. Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding. In Proceedings of the Proceedings of the British Machine Vision Conference (BMVC), London, UK, 4–7 September 2017. [', 'Google Scholar', ']', 'Zadrozny, B.; Elkan, C. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Edmonton, AB, Canada, 23–26 July 2002; pp. 694–699. [', 'Google Scholar', ']', 'Litjens, G.; Debats, O.; Barentsz, J.; Karssemeijer, N.; Huisman, H. Computer-aided detection of prostate cancer in MRI. ', 'IEEE Trans Med Imaging.', ' ', '2014', ', ', '33', ', 1083–1092. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Cuocolo, R.; Stanzione, A.; Castaldo, A.; De Lucia, D.R.; Imbriaco, M. Quality control and whole-gland, zonal and lesion annotations for the PROSTATEx challenge public dataset. ', 'Eur. J. Radiol.', ' ', '2021', ', ', '138', ', 120. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Emberton, M.; Simmons, L.A.M.; Ahmed, H.U.; Moore, C.M. ', 'PICTURE: Prostate Imaging (Multi-Sequence MRI and Prostate HistoScanning TM ) Compared to Transperineal Ultrasound Guided Biopsy for Significant Prostate Cancer Risk Evaluation CASE REPORT FORM', '; University College London Hospitals: London, UK, 2013. [', 'Google Scholar', ']', 'Dickinson, L.; Ahmed, H.U.; Allen, C.; Barentsz, J.O.; Carey, B.; Futterer, J.J.; Heijmink, S.W.; Hoskin, P.J.; Kirkham, A.; Padhani, A.R.; et al. Magnetic Resonance Imaging for the Detection, Localisation, and Characterisation of Prostate Cancer: Recommendations from a European Consensus Meeting. ', 'Eur. Urol.', ' ', '2011', ', ', '59', ', 477–494. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Wang, N.N.; Fan, R.E.; Leppert, J.T.; Ghanouni, P.; Kunder, C.A.; Brooks, J.D.; Chung, B.I.; Sonn, G.A. Performance of multiparametric MRI appears better when measured in patients who undergo radical prostatectomy. ', 'Res. Rep. Urol.', ' ', '2018', ', ', '10', ', 233–235. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Kingma, D.P.; Ba, J. Adam: A Method for Stochastic Optimization. In Proceedings of the International Conference on Learning Representations, San Diego, CA, USA, 7–9 May 2015. [', 'Google Scholar', ']', 'Litjens, G.J.; Barentsz, J.O.; Karssemeijer, N.; Huisman, H.J. Clinical evaluation of a computer-aided diagnosis system for determining cancer aggressiveness in prostate MRI. ', 'Eur. Radiol.', ' ', '2015', ', ', '25', ', 3187–3199. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'NICE Prostate cancer: Diagnosis and management. National Institute of Health and Care Excellence: Guidelines. 2019. Available online: ', 'https://www.nice.org.uk/guidance/ng131', ' (accessed on 5 September 2019).', 'Wilcoxon, F. Individual Comparisons by Ranking Methods. ', 'Biom. Bull.', ' ', '1945', ', ', '1', ', 80–83. [', 'Google Scholar', '] [', 'CrossRef', ']', 'DeLong, E.R.; DeLong, D.M.; Clarke-Pearson, D.L. Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves : A Nonparametric Approach. ', 'Biometrics', ' ', '1988', ', ', '44', ', 837–845. [', 'Google Scholar', '] [', 'CrossRef', ']', 'McNemar, Q. Note on the sampling error of the difference between correlated proportions or percentages. ', 'Psychometrika', ' ', '1947', ', ', '12', ', 153–157. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Kosinski, A.S. A weighted generalized score statistic for comparison of predictive values of diagnostic tests. ', 'Stat. Med.', ' ', '2013', ', ', '32', ', 1–20. [', 'Google Scholar', '] [', 'CrossRef', ']', 'Paszke, A.; Chaurasia, A.; Kim, S.; Culurciello, E. ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation. ', 'arXiv', ' ', '2016', ', arXiv:1606.02147. [', 'Google Scholar', ']', 'Antonelli, M.; Cardoso, M.J.; Johnston, E.W.; Appayya, M.B.; Presles, B.; Modat, M.; Punwani, S.; Ourselin, S. GAS: A genetic atlas selection strategy in multi-atlas segmentation framework. ', 'Med. Image Anal.', ' ', '2019', ', ', '52', ', 97–108. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Borofsky, S.; George, A.K.; Gaur, S.; Bernardo, M.; Greer, M.D.; Mertan, F.V.; Taffel, M.; Moreno, V.; Merino, M.J.; Wood, B.J.; et al. What Are We Missing? False-negative Cancers at Multiparametric MR Imaging of the Prostate. ', 'Radiology', ' ', '2017', ', ', '286', ', 186–195. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Littrup, P.J.; Williams, C.R.; Egglin, T.K.; Kane, R.A. Determination of prostate volume with transrectal US for cancer screening: Part II. Accuracy of in vitro and in vivo techniques. ', 'Radiology', ' ', '1991', ', ', '179', ', 49–53. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Brizmohun Appayya, M.; Adshead, J.; Ahmed, H.U.; Allen, C.; Bainbridge, A.; Barrett, T.; Giganti, F.; Graham, J.; Haslam, P.; Johnston, E.W.; et al. National implementation of multi-parametric magnetic resonance imaging for prostate cancer detection – recommendations from a UK consensus meeting. ', 'BJU Int.', ' ', '2018', ', ', '122', ', 13–25. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', 'Steenbergen, P.; Haustermans, K.; Lerut, E.; Oyen, R.; De Wever, L.; Van Den Bergh, L.; Kerkmeijer, L.G.W.; Pameijer, F.A.; Veldhuis, W.B.; Van Der Voort Van Zyp, J.R.N.; et al. Prostate tumor delineation using multiparametric magnetic resonance imaging: Inter-observer variability and pathology validation. ', 'Radiother. Oncol.', ' ', '2015', ', ', '115', ', 186–190. [', 'Google Scholar', '] [', 'CrossRef', '] [', 'PubMed', ']', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 1.', '\\nAutoProstate framework diagram. AutoProstate consists of three modules: Zone-Segmenter (green), CSPCa-Segmenter (blue), and Report-Generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. Yellow boxes indicate AutoProstate inputs from external sources.\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 1.', '\\nAutoProstate framework diagram. AutoProstate consists of three modules: Zone-Segmenter (green), CSPCa-Segmenter (blue), and Report-Generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. Yellow boxes indicate AutoProstate inputs from external sources.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 2.', '\\nAutoProstate Report template, where xx denotes an automatically populated field.\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 2.', '\\nAutoProstate Report template, where xx denotes an automatically populated field.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 3.', '\\nAutoProstate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and PSAd, using 80 patients from the PICTURE dataset for which ground-truth segmentations were available: (', 'a', ') Distribution of Dice coefficients for PZ, CG, and whole-prostate segmentation; (', 'b', ') Distribution of Abs%Err for transverse, anterior–posterior, and cranio–caudal lengths; (', 'c', ') Distribution of Abs%Err for PZ and CG volumes; (', 'd', ') Distribution of Abs%Err for whole-prostate volume estimations by AutoProstate and the experienced radiologist; and (', 'e', ') Distribution of AbsErr for PSAd calculated by AutoProstate and the experienced radiologist; the ground-truth PSAd value used to compute the AbsErr for AutoProstate and the experienced radiologist was calculated by dividing PSA by the whole-prostate volume derived from the ground-truth whole-prostate segmentation.\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 3.', '\\nAutoProstate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and PSAd, using 80 patients from the PICTURE dataset for which ground-truth segmentations were available: (', 'a', ') Distribution of Dice coefficients for PZ, CG, and whole-prostate segmentation; (', 'b', ') Distribution of Abs%Err for transverse, anterior–posterior, and cranio–caudal lengths; (', 'c', ') Distribution of Abs%Err for PZ and CG volumes; (', 'd', ') Distribution of Abs%Err for whole-prostate volume estimations by AutoProstate and the experienced radiologist; and (', 'e', ') Distribution of AbsErr for PSAd calculated by AutoProstate and the experienced radiologist; the ground-truth PSAd value used to compute the AbsErr for AutoProstate and the experienced radiologist was calculated by dividing PSA by the whole-prostate volume derived from the ground-truth whole-prostate segmentation.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 4.', '\\nPICTURE dataset CSPCa lesion detection (', 'a', ') ROC curves and (', 'b', ') PR curves, corresponding to the experienced radiologist (gold) and AutoProstate (blue).\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 4.', '\\nPICTURE dataset CSPCa lesion detection (', 'a', ') ROC curves and (', 'b', ') PR curves, corresponding to the experienced radiologist (gold) and AutoProstate (blue).', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 5.', '\\nPICTURE dataset axial T2WI, ADC map, Cb2000 DWI, ground-truth lesion contour overlaid on T2WI, probability map overlaid on T2WI, and segmentation overlaid on T2WI: (a) 79-year-old man, PSA 12.57 ng/mL, midgland PZ GS 4 + 3 lesion, Likert 5, AutoProstate probability of CSPCa 100%; (b) 66-year-old man, PSA 7.50 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 3, AutoProstate probability of CSPCa 65%; (c) 64-year-old man, PSA 10.53 ng/mL, apex CG GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 95%; (d) 56-year-old man, PSA 7.91 ng/mL, base CG GS 3 + 4 lesion, Likert 4, AutoProstate probability of CSPCa 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on DWI, PSA 6.15 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, PSA 4.09 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 49%.\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 5.', '\\nPICTURE dataset axial T2WI, ADC map, Cb2000 DWI, ground-truth lesion contour overlaid on T2WI, probability map overlaid on T2WI, and segmentation overlaid on T2WI: (a) 79-year-old man, PSA 12.57 ng/mL, midgland PZ GS 4 + 3 lesion, Likert 5, AutoProstate probability of CSPCa 100%; (b) 66-year-old man, PSA 7.50 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 3, AutoProstate probability of CSPCa 65%; (c) 64-year-old man, PSA 10.53 ng/mL, apex CG GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 95%; (d) 56-year-old man, PSA 7.91 ng/mL, base CG GS 3 + 4 lesion, Likert 4, AutoProstate probability of CSPCa 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on DWI, PSA 6.15 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, PSA 4.09 ng/mL, midgland PZ GS 3 + 4 lesion, Likert 5, AutoProstate probability of CSPCa 49%.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Figure 6.', '\\nAutoProstate Report for a 64-year-old man with PSA equal to 10.53 ng/mL who participated in the PICTURE study. LESION 1 (probability of CSPCa equal to 95%) corresponds to a biopsy-proven GS 3+4 lesion, while LESION 2 and LESION 3 (probabilities of CSPCa equal to 46% and 7%, respectively) are false positives.\\n\\n', '\\n', '\\n', '\\n', ' ', 'Figure 6.', '\\nAutoProstate Report for a 64-year-old man with PSA equal to 10.53 ng/mL who participated in the PICTURE study. LESION 1 (probability of CSPCa equal to 95%) corresponds to a biopsy-proven GS 3+4 lesion, while LESION 2 and LESION 3 (probabilities of CSPCa equal to 46% and 7%, respectively) are false positives.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Table 1.', '\\nAutoProstate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and PSAd, using 80 patients from the PICTURE dataset for which ground-truth segmentations were available.\\n', '\\n', '\\n', '\\n', 'Table 1.', '\\nAutoProstate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and PSAd, using 80 patients from the PICTURE dataset for which ground-truth segmentations were available.', '\\n', '\\n', 'Evaluation Measure', 'Mean (SD)', 'Median (IQR)', 'Min–Max', 'Experienced Radiologist ', '†', 'Whole-prostate volume Abs%Err', '13 (11)', '11 (5–20)', '0–66', 'PSA density AbsErr', '0.031 (0.032)', '0.022 (0.008–0.043)', '0.000–0.158', 'AutoProstate', 'Segmentation', 'Peripheral zone Dice coefficient', '0.75 (0.06)', '0.75 (0.70–0.79)', '0.55–0.88', 'Central gland Dice coefficient', '0.80 (0.07)', '0.81 (0.77–0.85)', '0.56–0.90', 'Whole-prostate Dice coefficient', '0.89 (0.03)', '0.90 (0.88–0.92)', '0.75–0.93', 'Lengths', 'Transverse length Abs%Err', '3 (2)', '2 (1–4)', '0–12', 'Anterior–posterior length Abs%Err', '5 (4)', '4 (2–7)', '0–22', 'Cranio–caudal length Abs%Err', '20 (15)', '16 (10–31)', '0–100', 'Volumes and PSA density', 'Peripheral zone volume Abs%Err', '12 (10)', '10 (4–18)', '0–49', 'Central gland volume Abs%Err', '18 (15)', '14 (10–25)', '0–112', 'Whole-prostate volume Abs%Err *', '9 (7)', '8 (5–12)', '0–37', 'PSA density AbsErr *', '0.019 (0.020)', '0.014 (0.006–0.025)', '0.000–0.129', '\\n', '\\n', 'AbsErr: absolute error; Abs%Err: absolute percentage error; IQR: interquartile range; Max: maximum; Min: minimum; PSA: prostate-specific antigen; SD: standard deviation. ', '†', ' the experienced radiologist used the ellipsoid formula to estimate whole-prostate volume. * indicates a ', 'p', '-value 0.05 for AutoProstate compared to the experienced radiologist.', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Table 2.', '\\nPICTURE dataset CSPCa lesion detection metrics for the experienced radiologist and AutoProstate. Mean and standard deviation of false positives per patient were calculated using the 93 PICTURE dataset patients who were biopsy-negative for CSPCa, rather than over all patients, due to limitations in the ground-truth. All other metrics shown are calculated at the lesion level for the 147 CSPCa lesions and 63 nCSPCa lesions.\\n', '\\n', '\\n', '\\n', 'Table 2.', '\\nPICTURE dataset CSPCa lesion detection metrics for the experienced radiologist and AutoProstate. Mean and standard deviation of false positives per patient were calculated using the 93 PICTURE dataset patients who were biopsy-negative for CSPCa, rather than over all patients, due to limitations in the ground-truth. All other metrics shown are calculated at the lesion level for the 147 CSPCa lesions and 63 nCSPCa lesions.', '\\n', '\\n', 'Experienced Radiologist (Likert Scoring)', 'ROC AUC', '0.64 (0.56–0.72)', 'PR AUC', '0.78 (0.71–0.84)', 'Post-thresholding (cut-off: Likert ≥4)', 'Sensitivity/recall (%)', '78 (71–84)', 'Specificity (%)', '48 (35–60)', 'Precision (%)', '78 (71–84)', 'Mean false positives per patient', '0.3 (0.2–0.4)', 'AutoProstate', 'ROC AUC', '0.70 (0.62–0.78)', 'PR AUC', '0.84 (0.77–0.90)', 'Post-thresholding (cut-off: ≥4.5%)', 'Sensitivity/recall (%)', '78 (71–85)', 'Specificity (%)', '49 (37–62)', 'Precision (%)', '78 (71–85)', 'Mean false positives per patient *', '6.1 (5.5–6.8)', 'Post-thresholding (cut-off: ≥4.5%) and false-positive reduction (40 mm', '3', ')', 'Sensitivity/recall (%)', '76 (68–82)', 'Specificity (%)', '57 (45–69)', 'Precision (%)', '80 (74–87)', 'Mean false positives per patient *', '2.5 (2.2–2.8)', '\\n', '\\n', 'AUC: area under curve; PR: precision-recall; ROC: receiver operating characteristic. * indicates a ', 'p', '-value 0.001 for AutoProstate compared to the radiologist.', '\\n', 'Publisher’s Note:', ' MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.', '\\n', '© 2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (', 'https://creativecommons.org/licenses/by/4.0/', ').', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Cancers', ',\\nEISSN 2072-6694,\\nPublished by MDPI\\n', '\\n', '\\n', '\\nDisclaimer\\n', '\\n', '\\nThe statements, opinions and data contained in the journal ', 'Cancers', ' are solely\\nthose of the individual authors and contributors and not of the publisher and the editor(s).\\nMDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n', '\\n', '\\n', '\\n', '\\n', 'RSS', '\\n', '\\n', '\\n', 'Content Alert', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nFurther Information\\n', '\\n', '\\nArticle Processing Charges\\n', '\\n', '\\nPay an Invoice\\n', '\\n', '\\nOpen Access Policy\\n', '\\n', '\\nContact MDPI\\n', '\\n', '\\nJobs at MDPI\\n', '\\n', '\\n', '\\n', '\\nGuidelines\\n', '\\n', '\\nFor Authors\\n', '\\n', '\\nFor Reviewers\\n', '\\n', '\\nFor Editors\\n', '\\n', '\\nFor Librarians\\n', '\\n', '\\nFor Publishers\\n', '\\n', '\\nFor Societies\\n', '\\n', '\\nFor Conference Organizers\\n', '\\n', '\\n', '\\n', '\\nMDPI Initiatives\\n', '\\n', '\\nSciforum\\n', '\\n', '\\nMDPI Books\\n', '\\n', '\\nPreprints\\n', '\\n', '\\nScilit\\n', '\\n', '\\nSciProfiles\\n', '\\n', '\\nEncyclopedia\\n', '\\n', '\\nJAMS\\n', '\\n', '\\nProceedings Series\\n', '\\n', '\\n', '\\n', '\\nFollow MDPI\\n', '\\n', '\\nLinkedIn\\n', '\\n', '\\nFacebook\\n', '\\n', '\\nTwitter\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nSubscribe to receive issue release notifications and newsletters from MDPI journals\\n', '\\n', '\\n', 'Acoustics', '\\n', 'Actuators', '\\n', 'Administrative Sciences', '\\n', 'Adolescents', '\\n', 'Aerospace', '\\n', 'Agriculture', '\\n', 'AgriEngineering', '\\n', 'Agronomy', '\\n', 'AI', '\\n', 'Algorithms', '\\n', 'Allergies', '\\n', 'Alloys', '\\n', 'Analytica', '\\n', 'Analytics', '\\n', 'Anatomia', '\\n', 'Animals', '\\n', 'Antibiotics', '\\n', 'Antibodies', '\\n', 'Antioxidants', '\\n', 'Applied Biosciences', '\\n', 'Applied Mechanics', '\\n', 'Applied Microbiology', '\\n', 'Applied Nano', '\\n', 'Applied Sciences', '\\n', 'Applied System Innovation', '\\n', 'AppliedChem', '\\n', 'AppliedMath', '\\n', 'Aquaculture Journal', '\\n', 'Architecture', '\\n', 'Arts', '\\n', 'Astronomy', '\\n', 'Atmosphere', '\\n', 'Atoms', '\\n', 'Audiology Research', '\\n', 'Automation', '\\n', 'Axioms', '\\n', 'Bacteria', '\\n', 'Batteries', '\\n', 'Behavioral Sciences', '\\n', 'Beverages', '\\n', 'Big Data and Cognitive Computing', '\\n', 'BioChem', '\\n', 'Bioengineering', '\\n', 'Biologics', '\\n', 'Biology', '\\n', 'Biology and Life Sciences Forum', '\\n', 'Biomass', '\\n', 'Biomechanics', '\\n', 'BioMed', '\\n', 'Biomedicines', '\\n', 'BioMedInformatics', '\\n', 'Biomimetics', '\\n', 'Biomolecules', '\\n', 'Biophysica', '\\n', 'Biosensors', '\\n', 'BioTech', '\\n', 'Birds', '\\n', 'Brain Sciences', '\\n', 'Buildings', '\\n', 'Businesses', '\\n', 'C', '\\n', 'Cancers', '\\n', 'Cardiogenetics', '\\n', 'Catalysts', '\\n', 'Cells', '\\n', 'Ceramics', '\\n', 'Challenges', '\\n', 'ChemEngineering', '\\n', 'Chemistry', '\\n', 'Chemistry Proceedings', '\\n', 'Chemosensors', '\\n', 'Children', '\\n', 'Chips', '\\n', 'CivilEng', '\\n', 'Clean Technologies', '\\n', 'Climate', '\\n', 'Clinical and Translational Neuroscience', '\\n', 'Clinics and Practice', '\\n', 'Clocks & Sleep', '\\n', 'Coasts', '\\n', 'Coatings', '\\n', 'Colloids and Interfaces', '\\n', 'Colorants', '\\n', 'Commodities', '\\n', 'Compounds', '\\n', 'Computation', '\\n', 'Computer Sciences & Mathematics Forum', '\\n', 'Computers', '\\n', 'Condensed Matter', '\\n', 'Conservation', '\\n', 'Construction Materials', '\\n', 'Corrosion and Materials Degradation', '\\n', 'Cosmetics', '\\n', 'COVID', '\\n', 'Crops', '\\n', 'Cryptography', '\\n', 'Crystals', '\\n', 'Current Issues in Molecular Biology', '\\n', 'Current Oncology', '\\n', 'Dairy', '\\n', 'Data', '\\n ', 'Dentistry Journal', '\\n', 'Dermato', '\\n', 'Dermatopathology', '\\n', 'Designs', '\\n', 'Diabetology', '\\n', 'Diagnostics', '\\n', 'Dietetics', '\\n', 'Digital', '\\n', 'Disabilities', '\\n', 'Diseases', '\\n', 'Diversity', '\\n', 'DNA', '\\n', 'Drones', '\\n', 'Dynamics', '\\n', 'Earth', '\\n', 'Ecologies', '\\n', 'Econometrics', '\\n', 'Economies', '\\n', 'Education Sciences', '\\n', 'Electricity', '\\n', 'Electrochem', '\\n', 'Electronic Materials', '\\n', 'Electronics', '\\n', 'Encyclopedia', '\\n', 'Endocrines', '\\n', 'Energies', '\\n', 'Eng', '\\n', 'Engineering Proceedings', '\\n', 'Entomology', '\\n', 'Entropy', '\\n', 'Environmental Sciences Proceedings', '\\n', 'Environments', '\\n', 'Epidemiologia', '\\n', 'Epigenomes', '\\n', 'European Burn Journal', '\\n', 'European Journal of Investigation in Health, Psychology and Education', '\\n', 'Fermentation', '\\n', 'Fibers', '\\n', 'FinTech', '\\n', 'Fire', '\\n', 'Fishes', '\\n', 'Fluids', '\\n', 'Foods', '\\n', 'Forecasting', '\\n', 'Forensic Sciences', '\\n', 'Forests', '\\n', 'Foundations', '\\n', 'Fractal and Fractional', '\\n', 'Fuels', '\\n', 'Future Internet', '\\n', 'Future Pharmacology', '\\n', 'Future Transportation', '\\n', 'Galaxies', '\\n', 'Games', '\\n', 'Gases', '\\n', 'Gastroenterology Insights', '\\n', 'Gastrointestinal Disorders', '\\n', 'Gels', '\\n', 'Genealogy', '\\n', 'Genes', '\\n', 'Geographies', '\\n', 'GeoHazards', '\\n', 'Geomatics', '\\n', 'Geosciences', '\\n', 'Geotechnics', '\\n', 'Geriatrics', '\\n', 'Healthcare', '\\n', 'Hearts', '\\n', 'Hemato', '\\n', 'Hematology Reports', '\\n', 'Heritage', '\\n', 'Histories', '\\n', 'Horticulturae', '\\n', 'Humanities', '\\n', 'Humans', '\\n', 'Hydrobiology', '\\n', 'Hydrogen', '\\n', 'Hydrology', '\\n', 'Hygiene', '\\n', 'Immuno', '\\n', 'Infectious Disease Reports', '\\n', 'Informatics', '\\n', 'Information', '\\n', 'Infrastructures', '\\n', 'Inorganics', '\\n', 'Insects', '\\n', 'Instruments', '\\n', 'International Journal of Environmental Research and Public Health', '\\n', 'International Journal of Financial Studies', '\\n', 'International Journal of Molecular Sciences', '\\n', 'International Journal of Neonatal Screening', '\\n', 'International Journal of Plant Biology', '\\n', 'International Journal of Translational Medicine', '\\n', 'International Journal of Turbomachinery, Propulsion and Power', '\\n', 'International Medical Education', '\\n', 'Inventions', '\\n', 'IoT', '\\n', 'ISPRS International Journal of Geo-Information', '\\n', 'J', '\\n', 'Journal of Ageing and Longevity', '\\n', 'Journal of Cardiovascular Development and Disease', '\\n', 'Journal of Clinical Medicine', '\\n', 'Journal of Composites Science', '\\n', 'Journal of Cybersecurity and Privacy', '\\n', 'Journal of Developmental Biology', '\\n', 'Journal of Functional Biomaterials', '\\n', 'Journal of Functional Morphology and Kinesiology', '\\n', 'Journal of Fungi', '\\n', 'Journal of Imaging', '\\n', 'Journal of Intelligence', '\\n', 'Journal of Low Power Electronics and Applications', '\\n', 'Journal of Manufacturing and Materials Processing', '\\n', 'Journal of Marine Science and Engineering', '\\n', 'Journal of Molecular Pathology', '\\n ', 'Journal of Nanotheranostics', '\\n', 'Journal of Nuclear Engineering', '\\n', 'Journal of Open Innovation: Technology, Market, and Complexity', '\\n', 'Journal of Otorhinolaryngology, Hearing and Balance Medicine', '\\n', 'Journal of Personalized Medicine', '\\n', 'Journal of Respiration', '\\n', 'Journal of Risk and Financial Management', '\\n', 'Journal of Sensor and Actuator Networks', '\\n', 'Journal of Theoretical and Applied Electronic Commerce Research', '\\n', 'Journal of Vascular Diseases', '\\n', 'Journal of Xenobiotics', '\\n', 'Journal of Zoological and Botanical Gardens', '\\n', 'Journalism and Media', '\\n', 'Kidney and Dialysis', '\\n', 'Knowledge', '\\n', 'Land', '\\n', 'Languages', '\\n', 'Laws', '\\n', 'Life', '\\n', 'Liquids', '\\n', 'Literature', '\\n', 'Livers', '\\n', 'Logics', '\\n', 'Logistics', '\\n', 'Lubricants', '\\n', 'Machine Learning and Knowledge Extraction', '\\n', 'Machines', '\\n', 'Macromol', '\\n', 'Magnetism', '\\n', 'Magnetochemistry', '\\n', 'Marine Drugs', '\\n', 'Materials', '\\n', 'Materials Proceedings', '\\n', 'Mathematical and Computational Applications', '\\n', 'Mathematics', '\\n', 'Medical Sciences', '\\n', 'Medical Sciences Forum', '\\n', 'Medicina', '\\n', 'Medicines', '\\n', 'Membranes', '\\n', 'Merits', '\\n', 'Metabolites', '\\n', 'Metals', '\\n', 'Meteorology', '\\n', 'Methane', '\\n', 'Methods and Protocols', '\\n', 'Metrology', '\\n', 'Micro', '\\n', 'Microbiology Research', '\\n', 'Micromachines', '\\n', 'Microorganisms', '\\n', 'Microplastics', '\\n', 'Minerals', '\\n', 'Mining', '\\n', 'Modelling', '\\n', 'Molbank', '\\n', 'Molecules', '\\n ', 'Multimodal Technologies and Interaction', '\\n', 'Muscles', '\\n', 'Nanoenergy Advances', '\\n', 'Nanomanufacturing', '\\n', 'Nanomaterials', '\\n', 'Network', '\\n', 'Neuroglia', '\\n', 'Neurology International', '\\n', 'NeuroSci', '\\n', 'Nitrogen', '\\n', 'Non-Coding RNA', '\\n', 'Nursing Reports', '\\n', 'Nutraceuticals', '\\n', 'Nutrients', '\\n', 'Obesities', '\\n', 'Oceans', '\\n', 'Onco', '\\n', 'Optics', '\\n', 'Oral', '\\n', 'Organics', '\\n', 'Organoids', '\\n', 'Osteology', '\\n', 'Oxygen', '\\n', 'Parasitologia', '\\n', 'Particles', '\\n', 'Pathogens', '\\n', 'Pathophysiology', '\\n', 'Pediatric Reports', '\\n', 'Pharmaceuticals', '\\n', 'Pharmaceutics', '\\n', 'Pharmacoepidemiology', '\\n', 'Pharmacy', '\\n', 'Philosophies', '\\n', 'Photochem', '\\n', 'Photonics', '\\n', 'Phycology', '\\n', 'Physchem', '\\n', 'Physical Sciences Forum', '\\n', 'Physics', '\\n', 'Physiologia', '\\n', 'Plants', '\\n', 'Plasma', '\\n', 'Pollutants', '\\n', 'Polymers', '\\n', 'Polysaccharides', '\\n', 'Poultry', '\\n', 'Powders', '\\n', 'Proceedings', '\\n', 'Processes', '\\n', 'Prosthesis', '\\n', 'Proteomes', '\\n', 'Psych', '\\n', 'Psychiatry International', '\\n', 'Psychoactives', '\\n', 'Publications', '\\n', 'Quantum Beam Science', '\\n', 'Quantum Reports', '\\n', 'Quaternary', '\\n', 'Radiation', '\\n', 'Reactions', '\\n', 'Receptors', '\\n', 'Recycling', '\\n', 'Religions', '\\n', 'Remote Sensing', '\\n', 'Reports', '\\n', 'Reproductive Medicine', '\\n', 'Resources', '\\n', 'Rheumato', '\\n', 'Risks', '\\n', 'Robotics', '\\n', 'Ruminants', '\\n', 'Safety', '\\n', 'Sci', '\\n', 'Scientia Pharmaceutica', '\\n', 'Seeds', '\\n', 'Sensors', '\\n', 'Separations', '\\n', 'Sexes', '\\n', 'Signals', '\\n', 'Sinusitis', '\\n', 'Smart Cities', '\\n', 'Social Sciences', '\\n', 'Societies', '\\n', 'Software', '\\n', 'Soil Systems', '\\n', 'Solar', '\\n', 'Solids', '\\n', 'Sports', '\\n', 'Standards', '\\n', 'Stats', '\\n', 'Stresses', '\\n', 'Surfaces', '\\n', 'Surgeries', '\\n', 'Surgical Techniques Development', '\\n', 'Sustainability', '\\n', 'Sustainable Chemistry', '\\n', 'Symmetry', '\\n', 'SynBio', '\\n', 'Systems', '\\n', 'Taxonomy', '\\n', 'Technologies', '\\n', 'Telecom', '\\n', 'Textiles', '\\n', 'Thalassemia Reports', '\\n', 'Thermo', '\\n', 'Tomography', '\\n', 'Tourism and Hospitality', '\\n', 'Toxics', '\\n', 'Toxins', '\\n', 'Transplantology', '\\n', 'Trauma Care', '\\n', 'Tropical Medicine and Infectious Disease', '\\n', 'Universe', '\\n', 'Urban Science', '\\n', 'Uro', '\\n', 'Vaccines', '\\n', 'Vehicles', '\\n', 'Venereology', '\\n ', 'Veterinary Sciences', '\\n', 'Vibration', '\\n', 'Virtual Worlds', '\\n', 'Viruses', '\\n', 'Vision', '\\n', 'Water', '\\n', 'Wind', '\\n', 'Women', '\\n', 'World', '\\n', 'World Electric Vehicle Journal', '\\n', 'Youth', '\\n', 'Zoonotic Diseases', '\\n', '\\n', '\\n', 'Subscribe', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n© 1996-2022 MDPI (Basel, Switzerland) unless otherwise stated\\n', '\\n', '\\n', '\\nDisclaimer\\n', '\\n', '\\nThe statements, opinions and data contained in the journals are solely\\nthose of the individual authors and contributors and not of the publisher and the editor(s).\\nMDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n', '\\n', '\\nTerms and Conditions\\n', '\\n', '\\nPrivacy Policy\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\nWe use cookies on our website to ensure you get the best experience.', '\\nRead more about our cookies ', 'here', '.\\n', '\\n', '\\n', 'Accept', '\\n', '\\n', '\\n', '\\n', '\\n', 'We have just recently launched a new version of our website.', '\\n', '\\nHelp us to further improve by taking part in this short 5 minute survey ', '\\n', 'here', '.', '\\n', 'here', '.', '\\n', '\\n', '\\n', '\\n', '\\n', 'Never show this again', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Share Link', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Copy', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'Share', '\\n', '\\n', '\\n', '\\n\\n\\n', '\\n', 'https://www.mdpi.com/1391944', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'clear', '\\n', '\\n', '\\n', 'Back to Top', 'Top', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n\\n', '\\n\\n', \"(function(){window['__CF$cv$params']={r:'717ab4d6bb577697',m:'puGPcH2z0UJQjTPqiBdZR.VKizVCMD4jDho3_hETd94-1654618735-0-AcJo/pLNr+NbSDraVAUgjMQCs+sMbpETAs45yzD9M7uYXOPYgHgmQ8W7Hf1Xeu7ADJ7HKTApShCOTKUUd0Gh/9Jz2oBX1gwNCVfTKb5LESLq6z3Vyt1qzR3WoUz5BQ+VdLYkf5Yqrmw1dzEZriai9aM=',s:[0x6b4cb4bde8,0x523482f19e],}})();\", '\\n\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "print(body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a7c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_text = [x.replace('\\n', ' ') for x in body_text]\n",
    "body_text = [x.replace('    ', ' ') for x in body_text]\n",
    "body_text = [x.replace('   ', ' ') for x in body_text]\n",
    "body_text = [x.replace('  ', ' ') for x in body_text]\n",
    "body_text = [x.lower() for x in body_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae656889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditions\n",
    "\n",
    "def alphachars(x): return sum(a.isalpha() for a in x) > 4\n",
    "\n",
    "def charchar(x): return bool(re.match(r\".*[a-zA-Z][a-zA-Z].*\", x)) == True\n",
    "\n",
    "def istitle(x): return ((('ethod' in x) or ('aterial' in x) or ('esult' in x) or ('iscussion' in x) or ('onclusion' in x)) \n",
    "                        and (sum(l.isalpha() for l in x) < 30))\n",
    "\n",
    "def istextblock(x): return sum(l.isalpha() for l in x) > 100\n",
    "\n",
    "def methodtitle(x): return ((('ethod' in x) or ('aterial' in x)) and (sum(l.isalpha() for l in x) < 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "808b86ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' all articles published by mdpi are made immediately available worldwide under an open access license. no special permission is required to reuse all or part of the article published by mdpi, including figures and tables. for articles published under an open access creative common cc by license, any part of the article may be reused without permission provided that the original article is clearly cited. ',\n",
       " ' feature papers represent the most advanced research with significant potential for high impact in the field. feature papers are submitted upon individual invitation or recommendation by the scientific editors and undergo peer review prior to publication. ',\n",
       " ' the feature paper can be either an original research article, a substantial novel research study that often involves several techniques or approaches, or a comprehensive review paper with concise and precise updates on the latest progress in the field that systematically reviews the most exciting advances in scientific literature. this type of paper provides an outlook on future directions of research or possible applications. ',\n",
       " ' editor’s choice articles are based on recommendations by the scientific editors of mdpi journals from around the world. editors select a small number of articles recently published in the journal that they believe will be particularly interesting to authors, or important in this field. the aim is to provide a snapshot of some of the most exciting work published in the various research areas of the journal. ',\n",
       " \"  you seem to have javascript disabled. please note that many of the page functionalities won't work as expected without javascript enabled. \",\n",
       " ' construction materials ',\n",
       " ' electronic materials ',\n",
       " ' materials ',\n",
       " ' materials proceedings ',\n",
       " ' methods and protocols (mps) ',\n",
       " ' nanomaterials ',\n",
       " 'discussion',\n",
       " 'supplementary material',\n",
       " 'division of surgery and interventional science, faculty of medical sciences, university college london, london wc1e 6bt, uk',\n",
       " ' international guidelines recommend multiparametric magnetic resonance imaging (mpmri) of the prostate for use by radiologists to identify lesions containing clinically significant prostate cancer, prior to confirmatory biopsy. automatic assessment of prostate mpmri using artificial intelligence algorithms holds a currently unrealized potential to improve the diagnostic accuracy achievable by radiologists alone, improve the reporting consistency between radiologists, and enhance reporting quality. in this work, we introduce autoprostate: a deep learning-powered framework for automatic mri-based prostate cancer assessment. in particular, autoprostate utilizes patient data and biparametric mri to populate an automatic web-based report which includes segmentations of the whole prostate, prostatic zones, and candidate clinically significant prostate cancer lesions, and in addition, several derived characteristics with clinical value are presented. notably, autoprostate performed well in external validation using the picture study dataset, suggesting value in prospective multicentre validation, with a view towards future deployment into the prostate cancer diagnostic pathway. ',\n",
       " ' multiparametric magnetic resonance imaging (mpmri) of the prostate is used by radiologists to identify, score, and stage abnormalities that may correspond to clinically significant prostate cancer (cspca). automatic assessment of prostate mpmri using artificial intelligence algorithms may facilitate a reduction in missed cancers and unnecessary biopsies, an increase in inter-observer agreement between radiologists, and an improvement in reporting quality. in this work, we introduce autoprostate, a deep learning-powered framework for automatic mri-based prostate cancer assessment. autoprostate comprises of three modules: zone-segmenter, cspca-segmenter, and report-generator. zone-segmenter segments the prostatic zones on t2-weighted imaging, cspca-segmenter detects and segments cspca lesions using biparametric mri, and report-generator generates an automatic web-based report containing four sections: ',\n",
       " '. in our experiment, autoprostate was trained using the publicly available prostatex dataset, and externally validated using the picture dataset. moreover, the performance of autoprostate was compared to the performance of an experienced radiologist who prospectively read picture dataset cases. in comparison to the radiologist, autoprostate showed statistically significant improvements in prostate volume and prostate-specific antigen density estimation. furthermore, autoprostate matched the cspca lesion detection sensitivity of the radiologist, which is paramount, but produced more false positive detections. ',\n",
       " 'automatic report; computer-aided diagnosis; convolutional neural network; deep learning; lesion detection; lesion classification; magnetic resonance imaging; prostate cancer; segmentation',\n",
       " 'radiologists use prostate multiparametric magnetic resonance imaging (mpmri) to detect, score, and stage lesions that may correspond to clinically significant prostate cancer (cspca), whose status can later be confirmed using mr-guided targeted biopsy and histopathological grading [',\n",
       " ']. however, the current diagnostic approach must be improved to reduce the small proportion of men with cspca who are missed by mpmri, to reduce the large number of men who undergo unnecessary biopsies, and to increase the inter-observer agreement between readers [',\n",
       " ']. in addition to lesion assessment, radiologists use prostate mpmri to estimate prostate volume using the ellipsoid formula [',\n",
       " ']. primarily, prostate volume is required for calculating prostate-specific antigen density (psad), which has been shown to be a predictor of cspca [',\n",
       " '], therefore more accurate volume estimation methods are sought. computer-aided diagnosis (cad) systems that use mpmri for prostate volume estimation and cspca lesion detection and/or segmentation may provide the desired performance improvements over current clinical practice.',\n",
       " 'automatic segmentation of the prostate may enable accurate prostate volume estimation. several automatic methods for prostate segmentation have been published [',\n",
       " ']. foremost, the promise12 challenge has driven consistent improvements in the performance of prostate segmentation algorithms over the past decade [',\n",
       " ']; an unpublished deep learning method named msd-net currently tops the leader board with a mean dice coefficient of 0.92 for whole-prostate segmentation. to the best of our knowledge, only the work by lee et al. [',\n",
       " '] has compared prostate volume estimation using an automatic segmentation method to the clinically utilized ellipsoid formula. on a 70-patient test set, their 3d cnn for whole-prostate segmentation achieved a mean dice coefficient of 0.87 and a mean absolute percentage error (abs%err) of 11.78% for volume estimation, while the mean abs%err for the ellipsoid formula was 11.92%. in the discussion section of their paper, lee et al. mention the potential benefit of more accurate volume estimation methods on the calculation of psad, but their study stopped short of providing a quantitative comparison.',\n",
       " 'cad systems for lesion detection and segmentation are actively being investigated, as demonstrated by a vast and growing literature [',\n",
       " '] directly compared cad systems for cspca lesion detection against radiologist mpmri assessment. cao et al. showed that their proposed focalnet convolutional neural network (cnn), trained using biparametric mri (bpmri), had a cspca lesion detection sensitivity of 87.9%, which was only 1.5% lower than pi-rads v2 scoring by three experienced radiologists who read a subset of cases each. their result was obtained from a fivefold cross-validation of 417 preoperative patients who later underwent radical prostatectomy. similarly, the study by schelb et al. showed that a u-net cnn [',\n",
       " '] produced similar cspca detection performance to pi-rads v2 scoring by eight radiologists who each read a subset of cases. on the held-out test cohort of 62 men sampled from the same study cohort as the training data, their method achieved a patient-level sensitivity of 92% and specificity of 47%, while radiologist assessment yielded a sensitivity of 88% and a specificity of 50%; differences in sensitivity and specificity between the proposed cnn approach and radiologist scoring were not statistically significant. while the studies by cao et al. and schelb et al. evaluated cad systems using test data sampled from the same study cohort as the training data, the study by thon et al. [',\n",
       " ' did not perform satisfactorily on external test data due to differences in the instrumentation and acquisition parameters used to collect training and test data. moreover, they remarked that optimistic performances of cad systems reported in other studies may be dataset-specific, and therefore advocated for the necessity of external validation of cad systems.',\n",
       " 'this work has two aims. the first aim is to introduce autoprostate: a deep learning-powered framework for automatic mri-based prostate cancer detection and assessment that we have developed. in particular, autoprostate segments the prostatic zones on t2-weighted imaging (t2wi), detects and segments cspca lesions using bpmri, and generates a novel automatic web-based report containing four sections: ',\n",
       " ', which posits it close to clinical deployment. notably, autoprostate uses up-to-date deep learning techniques for training and inference, such as hybrid losses [',\n",
       " '], and model ensembling, to enhance performance. the second aim of this work is to perform a high-quality single-centre external validation of autoprostate, as a first step towards clinical deployment, ahead of multicentre external validation and prospective validation in a clinical setting. in our experiment, autoprostate is trained using the publicly available prostatex dataset [',\n",
       " '], and externally validated using the prostate imaging compared to transperineal ultrasound-guided biopsy for significant prostate cancer risk evaluation (picture) trial dataset [',\n",
       " ']. the external validation follows the key considerations for authors, reviewers, and readers of ai manuscripts in radiology by bluemke et al. [',\n",
       " ']. in particular, the external test set contains mris acquired using scanners manufactured by a different vendor to the scanners used to acquire the training set and is confirmed using transperineal template prostate-mapping (ttpm) biopsy, which avoids the biases associated with mr-guided targeted biopsy and prostatectomy [',\n",
       " ']. furthermore, we compare the performance of autoprostate to the performance of an experienced radiologist who, at the time of the picture trial, had 10 years’ experience in reading prostate mpmri.',\n",
       " ' 2. methods',\n",
       " ', consists of three modules: zone-segmenter, cspca-segmenter, and report-generator. methodological aspects of each module are described in detail in the subsections to follow, while specific experimental parameters used to collect results are described in ',\n",
       " 't2w images are first resampled to a common in-plane resolution and cropped to a common in-plane shape, and then normalized by whitening of image voxel intensities.',\n",
       " 'after pre-processing, each t2wi slice is segmented by an ensemble of 2d nnu-nets with task-specific hyperparameter modifications; we refer to each constituent 2d nnu-net as zone-u-net and the ensemble of zone-u-nets as zone-u-net-e. a detailed description of the zone-u-net architecture is given in ',\n",
       " '. the output of each zone-u-net is slice-wise pz, cg, and background probability maps. per-voxel averaging is used to combine the probability map outputs of each zone-u-net ∈ zone-u-net-e, followed by restacking of slices to form pz, cg, and background probability map volumes.',\n",
       " 'the pz, cg, and background probability maps output by zone-u-net-e are transformed to the original t2wi shape and voxel resolution using padding and resampling operations. as a final step, a zonal segmentation map is obtained from the pz, cg, and background probability maps using a per-voxel argmax operation.',\n",
       " 'the cspca-segmenter module detects and segments cspca lesions using each patient’s t2wi, apparent diffusion coefficient (adc) map, low b-value diffusion-weighted imaging (dwi), and pz and cg probability maps output by zone-segmenter.',\n",
       " 'image registration is used to align adc maps and computed high b-value dwi to t2wi to account for voluntary/involuntary patient movement between t2wi and dwi acquisitions and differences in resolution. first, adc maps are affinely registered to t2wi using the symmetric block matching algorithm [',\n",
       " '], with the convolution-based fast local normalized correlation coefficient (lncc) similarity measure to enable robustness to bias field inhomogeneity [',\n",
       " ']. finally, the transformation obtained from the composition of both types of registration is used to register computed high b-value dwi to t2wi.',\n",
       " 't2wi, registered adc map and computed high b-value dwi, and pz and cg probability maps are resampled to a common in-plane resolution and cropped to a common in-plane shape, centred on the prostate; image cropping is used for memory efficiency. then, t2wi and computed high b-value dwi are normalized by dividing voxel intensities by the interquartile mean of cg voxel intensities. our approach is a modification of the normalization approach suggested by bonekamp et al. [',\n",
       " '], where voxel intensities were divided by the mean of pz voxel intensities. we opt for normalization using cg voxel intensities since cg segmentations are typically more reliable than pz segmentations [',\n",
       " '], and we opt for the interquartile mean of cg voxel intensities as opposed to the mean of all cg voxel intensities, to remove extremes that may correspond to abnormalities unique to a patient. adc maps were not normalized as they contain a quantitative measurement.',\n",
       " 'after pre-processing, each slice of a patient’s t2wi, adc map, computed high b-value dwi, and pz and cg probability maps are input channel-wise to an ensemble of 2d nnu-nets for cspca lesion segmentation; the addition of pz and cg guidance as input has been shown to increase cspca lesion detection performance as the occurrence and appearance of prostate cancer is dependent on its zonal location [',\n",
       " ']. we refer to each constituent 2d nnu-net as cspca-u-net and the ensemble of cspca-u-nets as cspca-u-net-e. a detailed description of the cspca-u-net architecture is given in ',\n",
       " '], i.e., dropout layers are inserted after the central three encoder units and two decoder units, with dropout probability equal to p. we model aleatoric uncertainty using test-time augmentation as in wang et al. [',\n",
       " 'the output of each cspca-u-net is slice-wise cspca probability maps. per-voxel averaging is used to combine the probability map outputs of each cspca-u-net ∈ cspca-u-net-e, followed by restacking of slices to form a probability map volume.',\n",
       " 'the cspca probability map output by cspca-u-net-e is transformed to the original t2wi shape and voxel resolution using padding and resampling operations. next, probabilities are calibrated using an isotonic regression calibration module [',\n",
       " '], to allow more interpretable cspca likelihoods. cspca lesion segmentations are obtained by thresholding cspca probability maps using a cut-off value c; c is chosen during experimentation using training data to match autoprostate’s detection sensitivity and specificity to that of an experienced radiologist. finally, a false-positive reduction step is applied to remove connected components smaller than minsize mm',\n",
       " 'the report-generator module generates an automatic report using input bpmri and clinical data, and the outputs of the zone-segmenter and cspca-segmenter modules; the report template is shown in ',\n",
       " 'the left-hand pane contains interactive report elements including a patient selector and transverse, frontal, and sagittal views of zone and cspca lesion segmentation outputs overlaid on t2wi, with associated widgets for slice selection.',\n",
       " ' lengths of the prostate, in cm, are calculated using the maximum extents of the prostate on the whole-prostate segmentation, where the whole-prostate segmentation is the union of the pz and cg segmentations. ',\n",
       " ' (base, midgland, or apex) are determined based on the location of the lesion centroid; our region determination follows the methodology outlined by litjens et al. [',\n",
       " '] for evaluating the promise12 challenge, where the apex is defined as the caudal-most third of the prostate, the base is the cranio-most third of the prostate, and the midgland is the remaining portion. the ',\n",
       " 'in this section, we describe the datasets used for training and testing autoprostate, the methodological settings employed, and the evaluation measures used to assess performance.',\n",
       " '], and externally validated using the prostate imaging compared to transperineal ultrasound-guided biopsy for significant prostate cancer risk evaluation (picture) study dataset [',\n",
       " 'mpmri was acquired using two 3-tesla magnetic field scanners (magnetom trio and skyra, siemens) and a pelvic-phased array coil. sequences collected included t2wi, adc map computed from dwi acquired at multiple b-values (50, 400, 800), and dcei with a temporal resolution of 3.5 s. all mpmri studies were reported by an experienced radiologist with over 20 years’ experience in reading prostate mpmri, who highlighted areas of suspicion per modality with a point marker and scored them using pi-rads v1. mr-guided targeted biopsies of marked points with pi-rads v1 score ≥ 3 were performed, while marked points with pi-rads v1 score 3 (unlikely for cspca) were not biopsied and assumed to be clinically insignificant (5% incidence of cspca in pi-rads v1 3 lesions at radboud university medical center). subsequently, biopsy specimens were graded by a histopathologist. the marked point coordinate and a ground-truth label (clinically significant equal to true or false) for each marked lesion was released publicly for 204 of the 346 patients, hence only these 204 patients feature in our work; clinical and histopathological characteristics are shown in ',\n",
       " ']. in summary, contours were produced in consensus by radiology residents (2 years’ experience in reading prostate mpmri) and board-certified radiologists (5 years’ experience in reading prostate mpmri) at the university of naples. radiology residents and board-certified radiologists worked in pairs for quality control and annotation. whole-prostate and zonal contours (pz and cg) were drawn for each patient. in addition, 299 lesions were delineated, including 76 cspca lesions and 223 low-grade or benign lesions (ncspca).',\n",
       " ']. men were examined at university college london hospital between 2012 and 2014. inclusion criteria for the picture study were: (i) men who had undergone an initial standard transrectal ultrasound-guided (trus) biopsy, but concern remained over the accuracy of the subsequent diagnosis; and (ii) men suitable for further characterization using transperineal template prostate-mapping (ttpm) biopsy. exclusion criteria were: (i) previous history of prostate cancer treatment; and (ii) lack of complete gland sampling or inadequate sampling density at ttpm.',\n",
       " 'mpmri was acquired using a 3-tesla magnetic field scanner (achieva, philips healthcare) and a pelvic-phased array coil. sequences collected included t2wi, dwi with high b-value (2000), adc map computed from dwi acquired at multiple b-values (0, 150, 500, 1000), and dcei with a temporal resolution of 13 s.',\n",
       " 'all mpmri studies were reported by an experienced radiologist with 10 years’ experience in reading prostate mpmri, using a five-point likert impression scale for the likelihood of cspca [',\n",
       " ']; cspca was defined as gleason score ≥ 3 + 4. scoring was completed at the lesion, sector, and patient-levels. clinical information, including the referral psa (ng/ml), was available to the radiologist during scoring to reflect clinical practice. men underwent mr-guided targeted biopsy of focal index lesions and ttpm biopsy with 5 mm sampling as the reference standard. ttpm biopsy was used to overcome the inaccuracies of trus biopsy [',\n",
       " 'in this work, two patients were removed due to missing mri data. clinical and histopathological characteristics for the 247 included patients are shown in ',\n",
       " 'whole-prostate and zonal contours were drawn by a board-certified radiologist (e.w.j., 3 years’ experience in the quantitative analysis of prostate mpmri), for 80 patients. lesions were delineated by two board-certified radiologists (s.s. and n.g., 5 and 4-years’ experience in scoring prostate mpmri using likert assessment and pi-rads v2, respectively), who drew contours on a subset of cases each. the protocol for lesion contouring was agreed between the radiologists beforehand. first, histopathology reports from mr-guided targeted and ttpm biopsies were reviewed alongside mpmri to locate the highest gleason grade focal lesion; if there were multiple focal lesions with the maximum gleason grade, the highest scoring focal lesion according to likert or pi-rads v2 was identified. next, a single axial t2wi slice was selected corresponding to the centre of the identified lesion. then, all focal lesions on the selected slice were contoured. additionally, focal benign lesions that were scored likert or pi-rads v2 ≥ 4 were contoured in patients that were biopsy-negative for cancer. a total of 210 lesions were delineated, including 147 cspca lesions and 63 ncspca lesions.',\n",
       " ' 3.2. methodological settings',\n",
       " 'a tenfold cross-validation analysis of zone-u-net was conducted using the prostatex dataset to optimize training hyperparameters, loss function, and augmentations. fold splits are shown in ',\n",
       " '. zone-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to eight, adam optimization [',\n",
       " 'following the tenfold cross-validation, the ten trained zone-u-nets were used to construct zone-u-net-e; cross-validation ensembles have been shown to be an effective ensembling strategy [',\n",
       " 'the registration of adc maps to t2wi employed default parameters for affine registration via symmetric block-matching. the subsequent non-rigid ffd registration used a gaussian kernel with standard deviation equal to 5 mm for lncc calculation, control point spacing equal to 10 mm, and bending energy constraint equal to 0.1. registrations were run using niftyreg (version 1.3; available online: ',\n",
       " ' (accessed on 1 october 2018). through visual inspection, satisfactory registration was observed for the majority of prostatex and picture dataset cases. no manual steps were taken to correct any instances of misregistration, and cases with misregistration were not excluded from our analysis.',\n",
       " 't2wi, registered adc maps and computed b2000 (cb2000) dwi, and pz and cg probability maps, were resampled to a common in-plane resolution of 0.4018 mm × 0.4018 mm and cropped to a common in-plane shape of 256 × 256, centred on the prostate.',\n",
       " 'like zone-u-net, the training settings for cspca-u-net were determined through tenfold cross-validation using the prostatex dataset with the fold splits shown in ',\n",
       " '. cspca-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to 12, adam optimization, a dropout probability of ',\n",
       " ' for central dropout, a hybrid loss composed of the sum of dice loss multiplied by 0.5 and focal loss multiplied by 1.0, and horizontal flip (probability = 0.5), rotation (−20°, 20°), and scaling (−10%, +20%) augmentations. the same dropout probability and augmentation settings were used for test-time dropout and test-time augmentation.',\n",
       " 'cspca probability maps output by cspca-u-net for each fold were calibrated using separate isotonic calibration modules for each fold. following calibration, cspca probability maps were thresholded using cut-off values determined for each fold, corresponding to a lesion-level sensitivity of 93% and specificity of 37%, in the fold’s training set. the aforementioned sensitivity and specificity correspond to reference radiologist performance at pi-rads v1 cut-off ≥ 4 on a separate patient cohort from radboud medical center, reported on in litjens et al. [',\n",
       " '], which was used since prospective radiologist performance was not available for the prostatex dataset. as a final post-processing step, connected components smaller than 40 mm',\n",
       " 'following the tenfold cross-validation, the ten trained cspca-u-nets were used to construct cspca-u-net-e. cspca-u-net-e was calibrated using isotonic calibration. for thresholding, a cut-off value c = 4.5% was determined to match radiologist performance in the training set for cspca-u-net-e i.e., the entire prostatex dataset. for false-positive reduction, connected components smaller than 40 mm',\n",
       " 'whole-prostate and zonal segmentations were evaluated using the dice coefficient. prostate size measurements (transverse, anterior–posterior, and cranio–caudal lengths), as well as whole-prostate and zonal volumes, were evaluated using the abs%err; the ground-truth lengths and volumes used in the calculation of abs%err were derived from the manually-drawn whole-prostate and zonal contours. the psad estimated by autoprostate was evaluated using absolute error (abserr), since the absolute value of psad has a meaning relative to risk definitions [',\n",
       " ']; the ground-truth psad value used in the calculation of abserr was obtained by dividing psa by the whole-prostate volume calculated using the manually-drawn whole-prostate contour. the aforementioned evaluation metrics were calculated over the 80 patients from the picture dataset for which manually drawn whole-prostate and zonal segmentations were available.',\n",
       " 'receiver operating characteristic (roc) area under the curve (auc) and precision-recall (pr) auc were calculated to quantify autoprostate’s ability to differentiate between cspca lesions and ncspca lesions. after thresholding and false-positive reduction, sensitivity, specificity, and precision were calculated at lesion-level and average false positives were calculated at patient-level. for the picture dataset, the calculation of average false positives was made using 93 patients who were biopsy-negative for cspca, due to limitations in the ground-truth prohibiting false-positive determination in biopsy positive patients. in addition, cspca lesion dice and abs%err of lesion area were calculated on slices containing a contour.',\n",
       " 'prostate volume, psad, and lesion detection metrics computed for autoprostate were compared to the same metrics calculated for an experienced radiologist (s.p., 10 years’ experience in scoring prostate mpmri) who prospectively filled out a case report for each patient. prostate volume was estimated using the ellipsoid formula and lesions were scored using a five-point likert scale [',\n",
       " ']. statistical tests were used to compare the performances of autoprostate and the experienced radiologist. the wilcoxon’s signed-rank test [',\n",
       " '] was used to statistically compare precision, and wilcoxon’s signed-rank test was used to statistically compare average false positives.',\n",
       " ' 4. results',\n",
       " 'autoprostate, trained using the prostatex dataset, was externally validated using the picture dataset. this section presents the results of the cross-validation of zone-u-net and cspca-u-net (the building blocks of autoprostate) and a detailed analysis of the external validation of autoprostate using the picture dataset, with comparisons made to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpmri, where possible.',\n",
       " '., cspca-u-net achieved a mean roc auc of 0.85 and a mean pr auc of 0.70. after thresholding, cspca-u-net achieved a mean sensitivity of 93%, a mean specificity of 37%, a mean precision of 34%, and a mean false-positive count per patient of 6.9. following false-positive reduction, mean sensitivity dropped marginally to 92%, mean specificity increased to 46%, mean precision increased to 37%, and mean false positives per patient dropped significantly to 3.3 (',\n",
       " ' 4.2. autoprostate external validation analysis: whole-prostate and zonal segmentations, prostate size measurements, and psa density',\n",
       " ' present summaries of the distribution of dice coefficients for whole-prostate and zonal segmentations, the distribution of abs%err for prostate size measurements, and the distribution of abserr for psad calculation, for 80 patients from the picture dataset for which ground-truth segmentations were available.',\n",
       " 'mean dice coefficients of 0.75, 0.80, and 0.89 were obtained for the pz, cg, and whole-prostate, respectively. autoprostate’s zone-segmenter module found pz segmentation a more difficult task than cg segmentation, while whole-prostate segmentation had a higher mean dice coefficient than both zonal segmentations, suggesting an ease of distinguishing prostate tissue from background tissues, but a difficulty in distinguishing between pz and cg tissue. as expected, the mean dice coefficients for the pz, cg, and whole-prostate segmentations were lower than those obtained on the prostatex dataset during the tenfold cross-validation of zone-u-net (0.78, 0.86, and 0.91 for pz, cg, and whole-prostate segmentation, respectively) which may be indicative of a generalization gap due to acquisition/population differences.',\n",
       " 'the transverse, anterior–posterior, and cranio–caudal lengths of the prostate were estimated using the whole-prostate segmentation output by zone-segmenter. mean abs%err of 3%, 5%, and 20% were obtained for transverse, anterior–posterior, and cranio–caudal lengths, respectively. in addition to the lowest mean abs%err, the transverse length had a smaller standard deviation than anterior–posterior and cranio–caudal lengths. through visual inspection of segmentation outputs, we attribute the variability in the accuracy of the anterior–posterior measurement to the difficulty of determining prostate extent in the anterior fibromuscular stroma, and similarly, we attribute the variability in the accuracy of the cranio–caudal measurement to the difficulty of determining prostate extent at the base and apex regions of the prostate. strikingly, a large maximum abs%err of 100% was observed for the cranio–caudal measurement, due to under-segmentation of the base region in the ground-truth.',\n",
       " 'pz, cg, and whole-prostate volumes were calculated using the pz, cg, and whole-prostate segmentations output by zone-segmenter. mean abs%errs of 12%, 18%, and 9% were obtained for pz, cg, and whole-prostate volumes, respectively. strikingly, a large maximum abs%err of 112% was observed for the cg, which was found to be due to over-segmentation of the cg in the base region.',\n",
       " 'we compare the abs%err of the whole-prostate volume calculated by autoprostate to the same calculated by the experienced radiologist who used the ellipsoid formula, which is clinically advocated. autoprostate had a mean abs%err of 9%, while the experienced radiologist’s mean abs%err was 13%; the difference was statistically significant (',\n",
       " ' 0.05). using the whole-prostate volumes computed by autoprostate and the experienced radiologist, psad was calculated. autoprostate achieved a mean abserr of 0.019, while the experienced radiologist’s mean abserr was 0.031; again, the difference was statistically significant (',\n",
       " ' 4.3. autoprostate external validation analysis: clinically significant prostate cancer lesion detection and segmentation',\n",
       " 'autoprostate achieved a mean roc auc of 0.70 and a mean pr auc of 0.84, calculated using output cspca probability maps prior to thresholding. after thresholding the cspca probability maps using a cut-off value equal to 4.5%, the following were obtained: a sensitivity of 78%, a specificity of 49%, a precision of 78%, and a mean false-positive count of 6.1. following false-positive reduction, mean sensitivity dropped marginally to 76%, mean specificity increased to 57%, mean precision increased marginally to 80%, and the mean false-positive count per patient dropped to 2.5.',\n",
       " 'likert scores assigned to suspicious lesions by the experienced radiologist were used to calculate roc and pr curves; radiologist likert scoring gave a roc auc of 0.64 and pr auc of 0.78. after thresholding at cut-off score likert ≥ 4, the following were obtained: a sensitivity of 78%, a specificity of 48%, a precision of 78%, and a mean false-positive count of 0.3. differences between the roc auc, pr auc, sensitivity, specificity, and precision of autoprostate and the experienced radiologist were not statistically significant. however, the difference between mean false positives was statistically significant (',\n",
       " 'a further analysis was completed to assess the level of agreement between autoprostate and the experienced radiologist’s likert scores, on annotated lesions, as shown in ',\n",
       " '. for cspca lesions, there was a 78% (114/147) concordance between autoprostate and the experienced radiologist, while for ncspca lesions, there was a 62% (39/63) concordance.',\n",
       " 'autoprostate’s lesion segmentations enable the calculation of lesion volume and lesion minimum adc. lesion segmentation accuracy, evaluated using the dice coefficient, was calculated using slices containing a corresponding ground-truth cspca lesion contour. the following dice coefficient metrics were obtained: a mean of 0.46 (sd: 0.32), a median of 0.58 (iqr: 0.10–0.72), and a min–max range of 0.00–0.90. several example cspca lesion segmentations are presented in ',\n",
       " '. examples are shown in the pz and cg, and in the base, midgland, and apex regions of the prostate. in addition, examples have been included to demonstrate autoprostate’s robustness to magnetic susceptibility artifacts. furthermore, an example automatic report generated by autoprostate is shown in ',\n",
       " ' 5. discussion',\n",
       " 'in this work, we introduced autoprostate, a deep learning-powered framework for automatic mri-based prostate cancer assessment. autoprostate consists of three modules: zone-segmenter, cspca-segmenter, and report-generator. the output of autoprostate is an automatic web-based report that presents patient details, prostate size measurements and psad, a listing of candidate cspca lesions with derived characteristics, and a findings summary. autoprostate, trained using the publicly available prostatex dataset, was externally validated using the picture dataset. during the external validation, the performance of autoprostate was compared to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpmri, who prospectively estimated prostate volume and psad using the ellipsoid formula, and scored lesions using a five-point likert scale.',\n",
       " 'pz, cg, and whole-prostate segmentations are output by autoprostate’s zone-segmenter module. during the experimental setup phase, we tested zone-u-net, prior to ensembling of zone-u-nets to form zone-u-net-e. zone-u-net achieved mean dice coefficients of 0.78, 0.86, and 0.91 for pz, cg, and whole-prostate segmentation, respectively, in tenfold cross-validation using the prostatex dataset. our result compares well to recent works by aldoj et al. [',\n",
       " '], where their proposed dense-2 u-net cnn was evaluated using fourfold cross-validation of a 188-patient subset from the prostatex dataset, and to a recent work by cuocolo et al. [',\n",
       " '] was evaluated using a 105-patient test set from the prostatex dataset. aldoj et al. obtained mean dice coefficients of 0.78, 0.91, and 0.92, and cuocolo et al. obtained mean dice coefficients of 0.71, 0.87, and 0.91, for pz, cg, and whole-prostate segmentation, respectively. however, direct comparison between our work and the works of aldoj et al. and cuocolo et al. is not possible due to the use of different subsets of data for testing. during the external validation of autoprostate using the picture dataset, where zone-u-net-e was used for pz, cg, and whole-prostate segmentation, autoprostate achieved mean dice coefficients of 0.75, 0.80, and 0.89, respectively, on 80 patients for which ground-truth segmentations were available. antonelli et al. [',\n",
       " '] previously reported segmentation results for the picture dataset. a multi-atlas segmentation approach featuring a novel genetic atlas selection strategy was proposed; mean dice coefficients of 0.72 and 0.83 were reported for pz and cg segmentation, using leave-one-out cross-validation, and a mean dice coefficient of 0.83 was reported for whole-prostate segmentation, using atlases from the promise12 dataset [',\n",
       " ']. autoprostate’s estimate of prostate volume was compared to an estimate obtained using the ellipsoid formula, which is clinically advocated [',\n",
       " ']. autoprostate achieved a mean abs%err of 9%, while the radiologist computed ellipsoid formula estimate had a mean abs%err of 13%. notably, the difference in mean abs%err was statistically significant (',\n",
       " '. furthermore, we compared psad estimates obtained using the volume estimates; we found a mean abserr of 0.019 for autoprostate and a mean abserr of 0.031 for the radiologist; again, the difference was statistically significant (',\n",
       " 'autoprostate’s foremost purpose is to detect and segment cspca lesions. during the experimental setup phase, we tested cspca-u-net, prior to ensembling of cspca-u-nets to form cspca-u-net-e. markedly, cspca-u-net achieved a lesion-level mean roc auc of 0.85 in tenfold cross-validation using the prostatex dataset, while previous studies have reported a lesion-level mean roc auc of 0.81 on the same subset of prostatex data used in this study, using the same input modalities. during the external validation of autoprostate using the picture dataset, where cspca-u-net-e was used to segment cspca lesions, autoprostate achieved a lesion-level roc auc of 0.70. notably, we observed a large reduction in roc auc on the picture dataset from that seen during the prostatex dataset tenfold cross-validation. we believe that the main reason for the reduction in roc auc is the use of ttpm biopsy in the picture study, which allowed lesions that were not prospectively identified by the radiologist, to be retrospectively contoured using ttpm biopsy findings. other reasons may include a high occurrence of magnetic susceptibility artifacts on dwi in the picture dataset and a possible generalization gap between training data and external testing data due to population/acquisition differences. on the picture dataset, radiologist likert assessment achieved a lesion-level roc auc of 0.64; the difference in roc auc between autoprostate and the experienced radiologist was not statistically significant. following thresholding and false-positive reduction, autoprostate achieved a lesion-level sensitivity of 76%, a lesion-level specificity of 57%, and 2.5 false positives per patient (calculated over patients without cspca, only). in comparison, radiologist likert assessment thresholded at likert ≥ 4, achieved a lesion-level sensitivity of 78%, a lesion-level specificity of 48%, and 0.3 false positives per patient (calculated over patients without cspca, only); only the difference between the number of false positive detections by autoprostate and the experienced radiologist was statistically significant (',\n",
       " '). while autoprostate has demonstrated an ability to differentiate between cspca lesions and low-grade/benign lesions at the level of an experienced radiologist, further work is needed to reduce the number of false positives produced. interestingly, autoprostate achieved a similar sensitivity and improved specificity compared to the radiologist on annotated cspca and ncspca lesions but had a higher overall false-positive count. therefore, it’s possible that the additional false positives produced by autoprostate, that were not prospectively scored by the radiologist, may be easy for radiologists to rule-out.',\n",
       " 'several aspects of this study have been guided by the set of nine key considerations for authors, reviewers, and readers of artificial intelligence studies in radiology by bluemke et al. [',\n",
       " ']. as recommended, we maintained a clear separation between training data and testing data. in particular, we avoided a common pitfall observed in previous studies [',\n",
       " '], by determining the probability cut-off value using training data, rather than a biased approach involving the test data itself. in line with further recommendations by bluemke et al., we were able to externally validate autoprostate using the picture dataset. furthermore, the picture dataset was acquired using phillips’ scanners, while the prostatex dataset, used to train autoprostate, was acquired using siemens’ scanners, meaning a further recommendation on using multivendor data for evaluation was met. moreover, we compared autoprostate to an expert radiologist who prospectively reported picture dataset patients, and both autoprostate and the radiologist were compared to an accepted reference standard which combined ttpm and mr-guided targeted biopsies; ttpm biopsy is highly accurate and avoids biases associated to mr-guided targeted biopsy, transrectal ultrasound-guided (trus) biopsy, and prostatectomy [',\n",
       " 'cad system studies should describe how the cad system will be deployed clinically, so future prospective trials can be planned accordingly. our goal in this study was to understand the strengths, weaknesses, and idiosyncrasies of autoprostate through a comparison against an experienced radiologist. in the clinical workflow, we envision autoprostate as a radiologist companion system during clinical reads to allow enhanced clinical reporting. it should be acknowledged that current cad systems for mri-based prostate cancer diagnosis contain varying degrees of error in terms of producing too many false positives, false negatives, or both. since the automatic report produced by autoprostate presents visual segmentation outputs, as well as derived measurements, all outputs produced by autoprostate can be rapidly verified by the radiologist. in particular, automatic report information deemed to be accurate can be used to prepare the patient’s clinical report, while erroneous information can be recalculated using current clinical methods or ignored if not required.',\n",
       " 'there were three limitations in our study. firstly, our training data was limited to 76 cspca lesions and 223 ncspca lesions; we may expect improved detection sensitivity and reduced false positives if a bigger training dataset with more lesions is available. secondly, our external validation was limited to a single external site. thirdly, lesion contours for each picture dataset patient were drawn by a single radiologist only. while the location and gleason score of lesions was confirmed by a combination of ttpm and mr-guided targeted biopsies, we were not able to overcome the inter-reader variation known to exist in lesion boundary determination [',\n",
       " 'our future work will be to perform a prospective validation of autoprostate. in particular, we will plan a clinical trial that investigates the impact of the automatic report on the prospective clinical read of radiologists of varying levels of experience. in preparation for the prospective validation, we will seek a larger multi-centre and multi-vendor training dataset.',\n",
       " ' 6. conclusions',\n",
       " 'in this work, we presented autoprostate for automatic mri-based prostate cancer assessment. external validation using the picture dataset demonstrated statistically significant improvements in prostate volume and psa density estimation and no statistically significant differences in cspca lesion detection performance, when compared to an experienced radiologist with over 10 years’ experience in reading prostate mpmri. however, further work is needed to reduce the number of false positives produced by autoprostate, prior to prospective validation.',\n",
       " ' supplementary materials',\n",
       " ', section s1: zone-u-net architecture, section s2: cspca-u-net architecture, table s1: prostatex dataset characteristics, table s2: picture dataset characteristics, table s3: ten-fold cross-validation fold split of the prostatex dataset. lesion significance, size, and zone were used for fold stratification.',\n",
       " 'conceptualization, p.m., m.a. and s.o.; methodology, p.m. and m.a.; software, p.m.; formal analysis, p.m. and m.a.; data curation, p.m., m.a., s.s., n.g., e.w.j., h.u.a., m.e. and s.p.; writing—original draft preparation, p.m.; writing—review and editing, p.m., m.a., s.s., n.g., e.w.j., h.u.a., m.e., s.p. and s.o.; supervision, m.a., s.p. and s.o. all authors have read and agreed to the published version of the manuscript.',\n",
       " 'our institutional review board approved the study and waived the requirement for individual consent for retrospective analysis of prospectively acquired patient data collected as part of clinical trials/routine care (rd no: 12/0195, 16 july 2012).',\n",
       " 'prostatex dataset data citation: geert litjens, oscar debats, jelle barentsz, nico karssemeijer, and henkjan huisman. “prostatex challenge data”, the cancer imaging archive (2017). doi: 10.7937/k9tcia.2017.murs5cl. prostatex dataset masks citation: r. cuocolo, a. stanzione, a. castaldo, d.r. de lucia, m. imbriaco, quality control and whole-gland, zonal and lesion annotations for the prostatex challenge public dataset, eur. j. radiol. (2021).',\n",
       " 'p.m.’s research is supported by the engineering and physical sciences research council (epsrc) [ep/r512400/1]. p.m.’s work was additionally supported by the epsrc-funded ucl centre for doctoral training in intelligent, integrated imaging in healthcare (i4health) [ep/s021930/1]. m.a.’s research is supported by the wellcome/epsrc centre for medical engineering king’s college london and by the london medical imaging and ai centre for value-based healthcare. h.u.a.’s research is supported by core funding from the uk’s national institute of health research (nihr) imperial biomedical research centre. hua currently also receives funding from the wellcome trust, medical research council (uk), cancer research uk, prostate cancer uk, the urology foundation, bma foundation, imperial health charity, sonacare inc., trod medical and sophiris biocorp for trials in prostate cancer. m.e. and s.p. receive research support from the university college london/university college london hospital (ucl/uclh) biomedical research centre.',\n",
       " 'h.u.a. is a paid consultant to boston scientific for teaching and training on rezum for benign prostate hyperplasia treatment and cryotherapy for prostate cancer treatment and is paid for teaching and proctoring hifu for treating prostate cancer. m.e. receives honoraria from consulting, educational activities, and training from: sonacare inc.; nina medical; and angiodynamics inc. all other authors declare no conflicts of interest.',\n",
       " 'ahmed, h.u.; el-shater bosaily, a.; brown, l.c.; gabe, r.; kaplan, r.; parmar, m.k.; collaco-moraes, y.; ward, k.; hindley, r.g.; freeman, a.; et al. diagnostic accuracy of multi-parametric mri and trus biopsy in prostate cancer (promis): a paired validating confirmatory study. ',\n",
       " 'brembilla, g.; dell’oglio, p.; stabile, a.; damascelli, a.; brunetti, l.; ravelli, s.; cristel, g.; schiani, e.; venturini, e.; grippaldi, d.; et al. interreader variability in prostate mri reporting using prostate imaging reporting and data system version 2.1. ',\n",
       " 'stanzione, a.; ponsiglione, a.; di fiore, g.a.; picchi, s.g.; di stasi, m.; verde, f.; petretta, m.; imbriaco, m.; cuocolo, r. prostate volume estimation on mri: accuracy and effects of ellipsoid and bullet-shaped measurements on psa density. ',\n",
       " 'distler, f.a.; radtke, j.p.; bonekamp, d.; kesch, c.; schlemmer, h.-p.; wieczorek, k.; kirchner, m.; pahernik, s.; hohenfellner, m.; hadaschik, b.a. the value of psa density in combination with pi-rads',\n",
       " 'yang, x.; lei, y.; wang, t.; jiang, x.; jani, a.; mao, h.; curran, w.; patel, p.; liu, t.; wang, b. 3d prostate segmentation in mr image using 3d deeply supervised convolutional neural networks. ',\n",
       " 'aldoj, n.; biavati, f.; michallek, f.; stober, s.; dewey, m. automatic prostate and prostate zones segmentation of magnetic resonance images using densenet-like u-net. ',\n",
       " 'cuocolo, r.; comelli, a.; stefano, a.; benfante, v.; dahiya, n.; stanzione, a.; castaldo, a.; de lucia, d.r.; yezzi, a.; imbriaco, m. deep learning whole-gland and zonal prostate segmentation on a public mri dataset. ',\n",
       " 'milletari, f.; navab, n.; ahmadi, s. v-net: fully convolutional neural networks for volumetric medical image segmentation. in proceedings of the fourth international conference on 3d vision (3dv), stanford, ca, usa, 25–28 october 2016. [',\n",
       " 'comelli, a.; dahiya, n.; stefano, a.; vernuccio, f.; portoghese, m.; cutaia, g.; bruno, a.; salvaggio, g.; yezzi, a. deep learning-based methods for prostate segmentation in magnetic resonance imaging. ',\n",
       " 'lee, d.k.; sung, d.j.; kim, c.-s.; heo, y.; lee, j.y.; park, b.j.; kim, m.j. three-dimensional convolutional neural network for prostate mri segmentation and comparison of prostate volume measurements by use of artificial neural network and ellipsoid formula. ',\n",
       " 'litjens, g.; toth, r.; van de ven, w.; hoeks, c.; kerkstra, s.; van ginneken, b.; vincent, g.; guillard, g.; birbeck, n.; zhang, j.; et al. evaluation of prostate segmentation algorithms for mri: the promise12 challenge. ',\n",
       " 'cao, r.; mohammadian bajgiran, a.; afshari mirak, s.; shakeri, s.; zhong, x.; enzmann, d.; raman, s.; sung, k. joint prostate cancer detection and gleason score prediction in mp-mri via focalnet. ',\n",
       " 'giannini, v.; mazzetti, s.; armando, e.; carabalona, s.; russo, f.; giacobbe, a.; muto, g.; regge, d. multiparametric magnetic resonance imaging of the prostate with computer-aided detection: experienced observer performance study. ',\n",
       " 'schelb, p.; kohl, s.; radtke, j.p.; wiesenfarth, m.; kickingereder, p.; bickelhaupt, s.; kuder, t.a.; stenzinger, a.; hohenfellner, m.; schlemmer, h.-p.; et al. classification of cancer at prostate mri: deep learning versus clinical pi-rads assessment. ',\n",
       " 'thon, a.; teichgraber, u.; tennstedt-schenk, c.; hadjidemetriou, s.; winzler, s.; malich, a.; papageorgiou, i. computer aided detection in prostate cancer diagnostics: a promising alternative to biopsy? a retrospective study from 104 lesions with histological ground truth. ',\n",
       " 'greer, m.d.; lay, n.; shih, j.h.; barrett, t.; bittencourt, l.k.; borofsky, s.; kabakus, i.; law, y.m.; marko, j.; shebel, h.; et al. computer-aided diagnosis prior to conventional interpretation of prostate mpmri: an international multi-reader study. ',\n",
       " 'gaur, s.; lay, n.; harmon, s.a.; doddakashi, s.; mehralivand, s.; argun, b.; barrett, t.; bednarova, s.; girometti, r.; karaarslan, e.; et al. can computer-aided diagnosis assist in the identification of prostate cancer on prostate mri? a multi-center, multi-reader investigation. ',\n",
       " 'zhu, l.; gao, g.; liu, y.; han, c.; liu, j.; zhang, x.; wang, x. feasibility of integrating computer-aided diagnosis with structured reports of prostate multiparametric mri. ',\n",
       " 'ronneberger, o.; fischer, p.; brox, t. u-net: convolutional networks for biomedical image segmentation. in proceedings of the international conference on medical image computing and computer-assisted intervention, munich, germany, 5–9 october 2015; springer: cham, switzerland, 2015; pp. 234–241. [',\n",
       " 'zhu, w.; huang, y.; zeng, l.; chen, x.; liu, y.; qian, z.; du, n.; fan, w.; xie, x. anatomynet: deep learning for fast and fully automated whole-volume segmentation of head and neck anatomy. ',\n",
       " 'gal, y.; ghahramani, z. dropout as a bayesian approximation: representing model uncertainty in deep learning. in proceedings of the 33rd international conference on machine learning, icml 2016, new york, ny, usa, 20–22 june 2016; volume 48, pp. 1651–1660. [',\n",
       " 'wang, g.; li, w.; aertsen, m.; deprest, j.; ourselin, s.; vercauteren, t. aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks. ',\n",
       " 'simmons, l.a.m.; kanthabalan, a.; arya, m.; briggs, t.; barratt, d.; charman, s.c.; freeman, a.; gelister, j.; hawkes, d.; hu, y.; et al. the picture study: diagnostic accuracy of multiparametric mri in men requiring a repeat prostate biopsy. ',\n",
       " 'bluemke, d.a.; moy, l.; bredella, m.a.; ertl-wagner, b.b.; fowler, k.j.; goh, v.j.; halpern, e.f.; hess, c.p.; schiebler, m.l.; weiss, c.r. assessing radiology research on artificial intelligence: a brief guide for authors, reviewers, and readers-from the radiology editorial board. ',\n",
       " 'verma, s.; sarkar, s.; young, j.; venkataraman, r.; yang, x.; bhavsar, a.; patil, n.; donovan, j.; gaitonde, k. evaluation of the impact of computed high b-value diffusion-weighted imaging on prostate cancer detection. ',\n",
       " 'blackledge, m.d.; leach, m.o.; collins, d.j.; koh, d.-m.; may, i.; tumor, i.; blackledge, m.d.; leach, m.o.; collins, d.j. computed diffusion-weighted mr imaging may improve tumor detection. ',\n",
       " 'modat, m.; ridgway, g.r.; taylor, z.a.; lehmann, m.; barnes, j.; hawkes, d.j.; fox, n.c.; ourselin, s. fast free-form deformation using graphics processing units. ',\n",
       " 'comput. methods programs biomed.',\n",
       " 'bonekamp, d.; kohl, s.; wiesenfarth, m.; schelb, p.; radtke, j.p.; gotz, m.; kickingereder, p.; yaqubi, k.; hitthaler, b.; gahlert, n.; et al. radiomic machine learning for characterization of prostate lesions with mri: comparison to adc values. ',\n",
       " 'isensee, f.; petersen, j.; klein, a.; zimmerer, d.; jaeger, p.f.; kohl, s.; wasserthal, j.; koehler, g.; norajitra, t.; wirkert, s.; et al. nnu-net: self-adapting framework for u-net-based medical image segmentation. ',\n",
       " 'hosseinzadeh, m.; brand, p.; huisman, h. effect of adding probabilistic zonal prior in deep learning-based prostate cancer detection. in proceedings of the medical imaging with deep learning (midl), london, uk, 8–10 july 2019. [',\n",
       " 'kendall, a.; badrinarayanan, v.; cipolla, r. bayesian segnet: model uncertainty in deep convolutional encoder-decoder architectures for scene understanding. in proceedings of the proceedings of the british machine vision conference (bmvc), london, uk, 4–7 september 2017. [',\n",
       " 'zadrozny, b.; elkan, c. transforming classifier scores into accurate multiclass probability estimates. in proceedings of the proceedings of the acm sigkdd international conference on knowledge discovery and data mining, edmonton, ab, canada, 23–26 july 2002; pp. 694–699. [',\n",
       " 'cuocolo, r.; stanzione, a.; castaldo, a.; de lucia, d.r.; imbriaco, m. quality control and whole-gland, zonal and lesion annotations for the prostatex challenge public dataset. ',\n",
       " 'picture: prostate imaging (multi-sequence mri and prostate histoscanning tm ) compared to transperineal ultrasound guided biopsy for significant prostate cancer risk evaluation case report form',\n",
       " 'dickinson, l.; ahmed, h.u.; allen, c.; barentsz, j.o.; carey, b.; futterer, j.j.; heijmink, s.w.; hoskin, p.j.; kirkham, a.; padhani, a.r.; et al. magnetic resonance imaging for the detection, localisation, and characterisation of prostate cancer: recommendations from a european consensus meeting. ',\n",
       " 'wang, n.n.; fan, r.e.; leppert, j.t.; ghanouni, p.; kunder, c.a.; brooks, j.d.; chung, b.i.; sonn, g.a. performance of multiparametric mri appears better when measured in patients who undergo radical prostatectomy. ',\n",
       " 'kingma, d.p.; ba, j. adam: a method for stochastic optimization. in proceedings of the international conference on learning representations, san diego, ca, usa, 7–9 may 2015. [',\n",
       " 'litjens, g.j.; barentsz, j.o.; karssemeijer, n.; huisman, h.j. clinical evaluation of a computer-aided diagnosis system for determining cancer aggressiveness in prostate mri. ',\n",
       " 'nice prostate cancer: diagnosis and management. national institute of health and care excellence: guidelines. 2019. available online: ',\n",
       " 'delong, e.r.; delong, d.m.; clarke-pearson, d.l. comparing the areas under two or more correlated receiver operating characteristic curves : a nonparametric approach. ',\n",
       " 'antonelli, m.; cardoso, m.j.; johnston, e.w.; appayya, m.b.; presles, b.; modat, m.; punwani, s.; ourselin, s. gas: a genetic atlas selection strategy in multi-atlas segmentation framework. ',\n",
       " 'borofsky, s.; george, a.k.; gaur, s.; bernardo, m.; greer, m.d.; mertan, f.v.; taffel, m.; moreno, v.; merino, m.j.; wood, b.j.; et al. what are we missing? false-negative cancers at multiparametric mr imaging of the prostate. ',\n",
       " 'littrup, p.j.; williams, c.r.; egglin, t.k.; kane, r.a. determination of prostate volume with transrectal us for cancer screening: part ii. accuracy of in vitro and in vivo techniques. ',\n",
       " 'brizmohun appayya, m.; adshead, j.; ahmed, h.u.; allen, c.; bainbridge, a.; barrett, t.; giganti, f.; graham, j.; haslam, p.; johnston, e.w.; et al. national implementation of multi-parametric magnetic resonance imaging for prostate cancer detection – recommendations from a uk consensus meeting. ',\n",
       " 'steenbergen, p.; haustermans, k.; lerut, e.; oyen, r.; de wever, l.; van den bergh, l.; kerkmeijer, l.g.w.; pameijer, f.a.; veldhuis, w.b.; van der voort van zyp, j.r.n.; et al. prostate tumor delineation using multiparametric magnetic resonance imaging: inter-observer variability and pathology validation. ',\n",
       " ' autoprostate framework diagram. autoprostate consists of three modules: zone-segmenter (green), cspca-segmenter (blue), and report-generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. yellow boxes indicate autoprostate inputs from external sources. ',\n",
       " ' autoprostate framework diagram. autoprostate consists of three modules: zone-segmenter (green), cspca-segmenter (blue), and report-generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. yellow boxes indicate autoprostate inputs from external sources.',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available: (',\n",
       " ') distribution of abserr for psad calculated by autoprostate and the experienced radiologist; the ground-truth psad value used to compute the abserr for autoprostate and the experienced radiologist was calculated by dividing psa by the whole-prostate volume derived from the ground-truth whole-prostate segmentation. ',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available: (',\n",
       " ') distribution of abserr for psad calculated by autoprostate and the experienced radiologist; the ground-truth psad value used to compute the abserr for autoprostate and the experienced radiologist was calculated by dividing psa by the whole-prostate volume derived from the ground-truth whole-prostate segmentation.',\n",
       " ' picture dataset axial t2wi, adc map, cb2000 dwi, ground-truth lesion contour overlaid on t2wi, probability map overlaid on t2wi, and segmentation overlaid on t2wi: (a) 79-year-old man, psa 12.57 ng/ml, midgland pz gs 4 + 3 lesion, likert 5, autoprostate probability of cspca 100%; (b) 66-year-old man, psa 7.50 ng/ml, midgland pz gs 3 + 4 lesion, likert 3, autoprostate probability of cspca 65%; (c) 64-year-old man, psa 10.53 ng/ml, apex cg gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 95%; (d) 56-year-old man, psa 7.91 ng/ml, base cg gs 3 + 4 lesion, likert 4, autoprostate probability of cspca 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on dwi, psa 6.15 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, psa 4.09 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 49%. ',\n",
       " ' picture dataset axial t2wi, adc map, cb2000 dwi, ground-truth lesion contour overlaid on t2wi, probability map overlaid on t2wi, and segmentation overlaid on t2wi: (a) 79-year-old man, psa 12.57 ng/ml, midgland pz gs 4 + 3 lesion, likert 5, autoprostate probability of cspca 100%; (b) 66-year-old man, psa 7.50 ng/ml, midgland pz gs 3 + 4 lesion, likert 3, autoprostate probability of cspca 65%; (c) 64-year-old man, psa 10.53 ng/ml, apex cg gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 95%; (d) 56-year-old man, psa 7.91 ng/ml, base cg gs 3 + 4 lesion, likert 4, autoprostate probability of cspca 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on dwi, psa 6.15 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, psa 4.09 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 49%.',\n",
       " ' autoprostate report for a 64-year-old man with psa equal to 10.53 ng/ml who participated in the picture study. lesion 1 (probability of cspca equal to 95%) corresponds to a biopsy-proven gs 3+4 lesion, while lesion 2 and lesion 3 (probabilities of cspca equal to 46% and 7%, respectively) are false positives. ',\n",
       " ' autoprostate report for a 64-year-old man with psa equal to 10.53 ng/ml who participated in the picture study. lesion 1 (probability of cspca equal to 95%) corresponds to a biopsy-proven gs 3+4 lesion, while lesion 2 and lesion 3 (probabilities of cspca equal to 46% and 7%, respectively) are false positives.',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available. ',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available.',\n",
       " 'abserr: absolute error; abs%err: absolute percentage error; iqr: interquartile range; max: maximum; min: minimum; psa: prostate-specific antigen; sd: standard deviation. ',\n",
       " ' picture dataset cspca lesion detection metrics for the experienced radiologist and autoprostate. mean and standard deviation of false positives per patient were calculated using the 93 picture dataset patients who were biopsy-negative for cspca, rather than over all patients, due to limitations in the ground-truth. all other metrics shown are calculated at the lesion level for the 147 cspca lesions and 63 ncspca lesions. ',\n",
       " ' picture dataset cspca lesion detection metrics for the experienced radiologist and autoprostate. mean and standard deviation of false positives per patient were calculated using the 93 picture dataset patients who were biopsy-negative for cspca, rather than over all patients, due to limitations in the ground-truth. all other metrics shown are calculated at the lesion level for the 147 cspca lesions and 63 ncspca lesions.',\n",
       " '© 2021 by the authors. licensee mdpi, basel, switzerland. this article is an open access article distributed under the terms and conditions of the creative commons attribution (cc by) license (',\n",
       " ' are solely those of the individual authors and contributors and not of the publisher and the editor(s). mdpi stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. ',\n",
       " 'construction materials',\n",
       " 'electronic materials',\n",
       " 'materials',\n",
       " 'materials proceedings',\n",
       " 'methods and protocols',\n",
       " 'nanomaterials',\n",
       " ' the statements, opinions and data contained in the journals are solely those of the individual authors and contributors and not of the publisher and the editor(s). mdpi stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. ',\n",
       " \"(function(){window['__cf$cv$params']={r:'717ab4d6bb577697',m:'pugpch2z0ujqjtpqibdzr.vkizvcmd4jdho3_hetd94-1654618735-0-acjo/plnr+nbsdravaugjmqcs+smbpetas45yzd9m7uyxopyghgmq8w7hf1xeu7adj7hktapshcotkuud0gh/9jz2obx1gwncvftkb5leslq6z3vyt1qzr3wouz5bq+vdlykf5yqrmw1dzezriai9am=',s:[0x6b4cb4bde8,0x523482f19e],}})();\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_text = []\n",
    "\n",
    "for x in body_text:\n",
    "    if (charchar(x) and alphachars(x)) and (istitle(x) or istextblock(x)):\n",
    "        keep_text.append(x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "keep_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "455c0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbracketcount(x): return x.count('{') < 4\n",
    "def rbracketcount(x): return x.count('}') < 4\n",
    "def tagcount(x): return x.count('\".\"') < 4\n",
    "def hashcount(x): return x.count('#') < 4\n",
    "def divcount(x): return x.count('</') < 4\n",
    "def linecount(x): return x.count('||') < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc6b934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' all articles published by mdpi are made immediately available worldwide under an open access license. no special permission is required to reuse all or part of the article published by mdpi, including figures and tables. for articles published under an open access creative common cc by license, any part of the article may be reused without permission provided that the original article is clearly cited. ',\n",
       " ' feature papers represent the most advanced research with significant potential for high impact in the field. feature papers are submitted upon individual invitation or recommendation by the scientific editors and undergo peer review prior to publication. ',\n",
       " ' the feature paper can be either an original research article, a substantial novel research study that often involves several techniques or approaches, or a comprehensive review paper with concise and precise updates on the latest progress in the field that systematically reviews the most exciting advances in scientific literature. this type of paper provides an outlook on future directions of research or possible applications. ',\n",
       " ' editor’s choice articles are based on recommendations by the scientific editors of mdpi journals from around the world. editors select a small number of articles recently published in the journal that they believe will be particularly interesting to authors, or important in this field. the aim is to provide a snapshot of some of the most exciting work published in the various research areas of the journal. ',\n",
       " \"  you seem to have javascript disabled. please note that many of the page functionalities won't work as expected without javascript enabled. \",\n",
       " ' construction materials ',\n",
       " ' electronic materials ',\n",
       " ' materials ',\n",
       " ' materials proceedings ',\n",
       " ' methods and protocols (mps) ',\n",
       " ' nanomaterials ',\n",
       " 'discussion',\n",
       " 'supplementary material',\n",
       " 'division of surgery and interventional science, faculty of medical sciences, university college london, london wc1e 6bt, uk',\n",
       " ' international guidelines recommend multiparametric magnetic resonance imaging (mpmri) of the prostate for use by radiologists to identify lesions containing clinically significant prostate cancer, prior to confirmatory biopsy. automatic assessment of prostate mpmri using artificial intelligence algorithms holds a currently unrealized potential to improve the diagnostic accuracy achievable by radiologists alone, improve the reporting consistency between radiologists, and enhance reporting quality. in this work, we introduce autoprostate: a deep learning-powered framework for automatic mri-based prostate cancer assessment. in particular, autoprostate utilizes patient data and biparametric mri to populate an automatic web-based report which includes segmentations of the whole prostate, prostatic zones, and candidate clinically significant prostate cancer lesions, and in addition, several derived characteristics with clinical value are presented. notably, autoprostate performed well in external validation using the picture study dataset, suggesting value in prospective multicentre validation, with a view towards future deployment into the prostate cancer diagnostic pathway. ',\n",
       " ' multiparametric magnetic resonance imaging (mpmri) of the prostate is used by radiologists to identify, score, and stage abnormalities that may correspond to clinically significant prostate cancer (cspca). automatic assessment of prostate mpmri using artificial intelligence algorithms may facilitate a reduction in missed cancers and unnecessary biopsies, an increase in inter-observer agreement between radiologists, and an improvement in reporting quality. in this work, we introduce autoprostate, a deep learning-powered framework for automatic mri-based prostate cancer assessment. autoprostate comprises of three modules: zone-segmenter, cspca-segmenter, and report-generator. zone-segmenter segments the prostatic zones on t2-weighted imaging, cspca-segmenter detects and segments cspca lesions using biparametric mri, and report-generator generates an automatic web-based report containing four sections: ',\n",
       " '. in our experiment, autoprostate was trained using the publicly available prostatex dataset, and externally validated using the picture dataset. moreover, the performance of autoprostate was compared to the performance of an experienced radiologist who prospectively read picture dataset cases. in comparison to the radiologist, autoprostate showed statistically significant improvements in prostate volume and prostate-specific antigen density estimation. furthermore, autoprostate matched the cspca lesion detection sensitivity of the radiologist, which is paramount, but produced more false positive detections. ',\n",
       " 'automatic report; computer-aided diagnosis; convolutional neural network; deep learning; lesion detection; lesion classification; magnetic resonance imaging; prostate cancer; segmentation',\n",
       " 'radiologists use prostate multiparametric magnetic resonance imaging (mpmri) to detect, score, and stage lesions that may correspond to clinically significant prostate cancer (cspca), whose status can later be confirmed using mr-guided targeted biopsy and histopathological grading [',\n",
       " ']. however, the current diagnostic approach must be improved to reduce the small proportion of men with cspca who are missed by mpmri, to reduce the large number of men who undergo unnecessary biopsies, and to increase the inter-observer agreement between readers [',\n",
       " ']. in addition to lesion assessment, radiologists use prostate mpmri to estimate prostate volume using the ellipsoid formula [',\n",
       " ']. primarily, prostate volume is required for calculating prostate-specific antigen density (psad), which has been shown to be a predictor of cspca [',\n",
       " '], therefore more accurate volume estimation methods are sought. computer-aided diagnosis (cad) systems that use mpmri for prostate volume estimation and cspca lesion detection and/or segmentation may provide the desired performance improvements over current clinical practice.',\n",
       " 'automatic segmentation of the prostate may enable accurate prostate volume estimation. several automatic methods for prostate segmentation have been published [',\n",
       " ']. foremost, the promise12 challenge has driven consistent improvements in the performance of prostate segmentation algorithms over the past decade [',\n",
       " ']; an unpublished deep learning method named msd-net currently tops the leader board with a mean dice coefficient of 0.92 for whole-prostate segmentation. to the best of our knowledge, only the work by lee et al. [',\n",
       " '] has compared prostate volume estimation using an automatic segmentation method to the clinically utilized ellipsoid formula. on a 70-patient test set, their 3d cnn for whole-prostate segmentation achieved a mean dice coefficient of 0.87 and a mean absolute percentage error (abs%err) of 11.78% for volume estimation, while the mean abs%err for the ellipsoid formula was 11.92%. in the discussion section of their paper, lee et al. mention the potential benefit of more accurate volume estimation methods on the calculation of psad, but their study stopped short of providing a quantitative comparison.',\n",
       " 'cad systems for lesion detection and segmentation are actively being investigated, as demonstrated by a vast and growing literature [',\n",
       " '] directly compared cad systems for cspca lesion detection against radiologist mpmri assessment. cao et al. showed that their proposed focalnet convolutional neural network (cnn), trained using biparametric mri (bpmri), had a cspca lesion detection sensitivity of 87.9%, which was only 1.5% lower than pi-rads v2 scoring by three experienced radiologists who read a subset of cases each. their result was obtained from a fivefold cross-validation of 417 preoperative patients who later underwent radical prostatectomy. similarly, the study by schelb et al. showed that a u-net cnn [',\n",
       " '] produced similar cspca detection performance to pi-rads v2 scoring by eight radiologists who each read a subset of cases. on the held-out test cohort of 62 men sampled from the same study cohort as the training data, their method achieved a patient-level sensitivity of 92% and specificity of 47%, while radiologist assessment yielded a sensitivity of 88% and a specificity of 50%; differences in sensitivity and specificity between the proposed cnn approach and radiologist scoring were not statistically significant. while the studies by cao et al. and schelb et al. evaluated cad systems using test data sampled from the same study cohort as the training data, the study by thon et al. [',\n",
       " ' did not perform satisfactorily on external test data due to differences in the instrumentation and acquisition parameters used to collect training and test data. moreover, they remarked that optimistic performances of cad systems reported in other studies may be dataset-specific, and therefore advocated for the necessity of external validation of cad systems.',\n",
       " 'this work has two aims. the first aim is to introduce autoprostate: a deep learning-powered framework for automatic mri-based prostate cancer detection and assessment that we have developed. in particular, autoprostate segments the prostatic zones on t2-weighted imaging (t2wi), detects and segments cspca lesions using bpmri, and generates a novel automatic web-based report containing four sections: ',\n",
       " ', which posits it close to clinical deployment. notably, autoprostate uses up-to-date deep learning techniques for training and inference, such as hybrid losses [',\n",
       " '], and model ensembling, to enhance performance. the second aim of this work is to perform a high-quality single-centre external validation of autoprostate, as a first step towards clinical deployment, ahead of multicentre external validation and prospective validation in a clinical setting. in our experiment, autoprostate is trained using the publicly available prostatex dataset [',\n",
       " '], and externally validated using the prostate imaging compared to transperineal ultrasound-guided biopsy for significant prostate cancer risk evaluation (picture) trial dataset [',\n",
       " ']. the external validation follows the key considerations for authors, reviewers, and readers of ai manuscripts in radiology by bluemke et al. [',\n",
       " ']. in particular, the external test set contains mris acquired using scanners manufactured by a different vendor to the scanners used to acquire the training set and is confirmed using transperineal template prostate-mapping (ttpm) biopsy, which avoids the biases associated with mr-guided targeted biopsy and prostatectomy [',\n",
       " ']. furthermore, we compare the performance of autoprostate to the performance of an experienced radiologist who, at the time of the picture trial, had 10 years’ experience in reading prostate mpmri.',\n",
       " ' 2. methods',\n",
       " ', consists of three modules: zone-segmenter, cspca-segmenter, and report-generator. methodological aspects of each module are described in detail in the subsections to follow, while specific experimental parameters used to collect results are described in ',\n",
       " 't2w images are first resampled to a common in-plane resolution and cropped to a common in-plane shape, and then normalized by whitening of image voxel intensities.',\n",
       " 'after pre-processing, each t2wi slice is segmented by an ensemble of 2d nnu-nets with task-specific hyperparameter modifications; we refer to each constituent 2d nnu-net as zone-u-net and the ensemble of zone-u-nets as zone-u-net-e. a detailed description of the zone-u-net architecture is given in ',\n",
       " '. the output of each zone-u-net is slice-wise pz, cg, and background probability maps. per-voxel averaging is used to combine the probability map outputs of each zone-u-net ∈ zone-u-net-e, followed by restacking of slices to form pz, cg, and background probability map volumes.',\n",
       " 'the pz, cg, and background probability maps output by zone-u-net-e are transformed to the original t2wi shape and voxel resolution using padding and resampling operations. as a final step, a zonal segmentation map is obtained from the pz, cg, and background probability maps using a per-voxel argmax operation.',\n",
       " 'the cspca-segmenter module detects and segments cspca lesions using each patient’s t2wi, apparent diffusion coefficient (adc) map, low b-value diffusion-weighted imaging (dwi), and pz and cg probability maps output by zone-segmenter.',\n",
       " 'image registration is used to align adc maps and computed high b-value dwi to t2wi to account for voluntary/involuntary patient movement between t2wi and dwi acquisitions and differences in resolution. first, adc maps are affinely registered to t2wi using the symmetric block matching algorithm [',\n",
       " '], with the convolution-based fast local normalized correlation coefficient (lncc) similarity measure to enable robustness to bias field inhomogeneity [',\n",
       " ']. finally, the transformation obtained from the composition of both types of registration is used to register computed high b-value dwi to t2wi.',\n",
       " 't2wi, registered adc map and computed high b-value dwi, and pz and cg probability maps are resampled to a common in-plane resolution and cropped to a common in-plane shape, centred on the prostate; image cropping is used for memory efficiency. then, t2wi and computed high b-value dwi are normalized by dividing voxel intensities by the interquartile mean of cg voxel intensities. our approach is a modification of the normalization approach suggested by bonekamp et al. [',\n",
       " '], where voxel intensities were divided by the mean of pz voxel intensities. we opt for normalization using cg voxel intensities since cg segmentations are typically more reliable than pz segmentations [',\n",
       " '], and we opt for the interquartile mean of cg voxel intensities as opposed to the mean of all cg voxel intensities, to remove extremes that may correspond to abnormalities unique to a patient. adc maps were not normalized as they contain a quantitative measurement.',\n",
       " 'after pre-processing, each slice of a patient’s t2wi, adc map, computed high b-value dwi, and pz and cg probability maps are input channel-wise to an ensemble of 2d nnu-nets for cspca lesion segmentation; the addition of pz and cg guidance as input has been shown to increase cspca lesion detection performance as the occurrence and appearance of prostate cancer is dependent on its zonal location [',\n",
       " ']. we refer to each constituent 2d nnu-net as cspca-u-net and the ensemble of cspca-u-nets as cspca-u-net-e. a detailed description of the cspca-u-net architecture is given in ',\n",
       " '], i.e., dropout layers are inserted after the central three encoder units and two decoder units, with dropout probability equal to p. we model aleatoric uncertainty using test-time augmentation as in wang et al. [',\n",
       " 'the output of each cspca-u-net is slice-wise cspca probability maps. per-voxel averaging is used to combine the probability map outputs of each cspca-u-net ∈ cspca-u-net-e, followed by restacking of slices to form a probability map volume.',\n",
       " 'the cspca probability map output by cspca-u-net-e is transformed to the original t2wi shape and voxel resolution using padding and resampling operations. next, probabilities are calibrated using an isotonic regression calibration module [',\n",
       " '], to allow more interpretable cspca likelihoods. cspca lesion segmentations are obtained by thresholding cspca probability maps using a cut-off value c; c is chosen during experimentation using training data to match autoprostate’s detection sensitivity and specificity to that of an experienced radiologist. finally, a false-positive reduction step is applied to remove connected components smaller than minsize mm',\n",
       " 'the report-generator module generates an automatic report using input bpmri and clinical data, and the outputs of the zone-segmenter and cspca-segmenter modules; the report template is shown in ',\n",
       " 'the left-hand pane contains interactive report elements including a patient selector and transverse, frontal, and sagittal views of zone and cspca lesion segmentation outputs overlaid on t2wi, with associated widgets for slice selection.',\n",
       " ' lengths of the prostate, in cm, are calculated using the maximum extents of the prostate on the whole-prostate segmentation, where the whole-prostate segmentation is the union of the pz and cg segmentations. ',\n",
       " ' (base, midgland, or apex) are determined based on the location of the lesion centroid; our region determination follows the methodology outlined by litjens et al. [',\n",
       " '] for evaluating the promise12 challenge, where the apex is defined as the caudal-most third of the prostate, the base is the cranio-most third of the prostate, and the midgland is the remaining portion. the ',\n",
       " 'in this section, we describe the datasets used for training and testing autoprostate, the methodological settings employed, and the evaluation measures used to assess performance.',\n",
       " '], and externally validated using the prostate imaging compared to transperineal ultrasound-guided biopsy for significant prostate cancer risk evaluation (picture) study dataset [',\n",
       " 'mpmri was acquired using two 3-tesla magnetic field scanners (magnetom trio and skyra, siemens) and a pelvic-phased array coil. sequences collected included t2wi, adc map computed from dwi acquired at multiple b-values (50, 400, 800), and dcei with a temporal resolution of 3.5 s. all mpmri studies were reported by an experienced radiologist with over 20 years’ experience in reading prostate mpmri, who highlighted areas of suspicion per modality with a point marker and scored them using pi-rads v1. mr-guided targeted biopsies of marked points with pi-rads v1 score ≥ 3 were performed, while marked points with pi-rads v1 score 3 (unlikely for cspca) were not biopsied and assumed to be clinically insignificant (5% incidence of cspca in pi-rads v1 3 lesions at radboud university medical center). subsequently, biopsy specimens were graded by a histopathologist. the marked point coordinate and a ground-truth label (clinically significant equal to true or false) for each marked lesion was released publicly for 204 of the 346 patients, hence only these 204 patients feature in our work; clinical and histopathological characteristics are shown in ',\n",
       " ']. in summary, contours were produced in consensus by radiology residents (2 years’ experience in reading prostate mpmri) and board-certified radiologists (5 years’ experience in reading prostate mpmri) at the university of naples. radiology residents and board-certified radiologists worked in pairs for quality control and annotation. whole-prostate and zonal contours (pz and cg) were drawn for each patient. in addition, 299 lesions were delineated, including 76 cspca lesions and 223 low-grade or benign lesions (ncspca).',\n",
       " ']. men were examined at university college london hospital between 2012 and 2014. inclusion criteria for the picture study were: (i) men who had undergone an initial standard transrectal ultrasound-guided (trus) biopsy, but concern remained over the accuracy of the subsequent diagnosis; and (ii) men suitable for further characterization using transperineal template prostate-mapping (ttpm) biopsy. exclusion criteria were: (i) previous history of prostate cancer treatment; and (ii) lack of complete gland sampling or inadequate sampling density at ttpm.',\n",
       " 'mpmri was acquired using a 3-tesla magnetic field scanner (achieva, philips healthcare) and a pelvic-phased array coil. sequences collected included t2wi, dwi with high b-value (2000), adc map computed from dwi acquired at multiple b-values (0, 150, 500, 1000), and dcei with a temporal resolution of 13 s.',\n",
       " 'all mpmri studies were reported by an experienced radiologist with 10 years’ experience in reading prostate mpmri, using a five-point likert impression scale for the likelihood of cspca [',\n",
       " ']; cspca was defined as gleason score ≥ 3 + 4. scoring was completed at the lesion, sector, and patient-levels. clinical information, including the referral psa (ng/ml), was available to the radiologist during scoring to reflect clinical practice. men underwent mr-guided targeted biopsy of focal index lesions and ttpm biopsy with 5 mm sampling as the reference standard. ttpm biopsy was used to overcome the inaccuracies of trus biopsy [',\n",
       " 'in this work, two patients were removed due to missing mri data. clinical and histopathological characteristics for the 247 included patients are shown in ',\n",
       " 'whole-prostate and zonal contours were drawn by a board-certified radiologist (e.w.j., 3 years’ experience in the quantitative analysis of prostate mpmri), for 80 patients. lesions were delineated by two board-certified radiologists (s.s. and n.g., 5 and 4-years’ experience in scoring prostate mpmri using likert assessment and pi-rads v2, respectively), who drew contours on a subset of cases each. the protocol for lesion contouring was agreed between the radiologists beforehand. first, histopathology reports from mr-guided targeted and ttpm biopsies were reviewed alongside mpmri to locate the highest gleason grade focal lesion; if there were multiple focal lesions with the maximum gleason grade, the highest scoring focal lesion according to likert or pi-rads v2 was identified. next, a single axial t2wi slice was selected corresponding to the centre of the identified lesion. then, all focal lesions on the selected slice were contoured. additionally, focal benign lesions that were scored likert or pi-rads v2 ≥ 4 were contoured in patients that were biopsy-negative for cancer. a total of 210 lesions were delineated, including 147 cspca lesions and 63 ncspca lesions.',\n",
       " ' 3.2. methodological settings',\n",
       " 'a tenfold cross-validation analysis of zone-u-net was conducted using the prostatex dataset to optimize training hyperparameters, loss function, and augmentations. fold splits are shown in ',\n",
       " '. zone-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to eight, adam optimization [',\n",
       " 'following the tenfold cross-validation, the ten trained zone-u-nets were used to construct zone-u-net-e; cross-validation ensembles have been shown to be an effective ensembling strategy [',\n",
       " 'the registration of adc maps to t2wi employed default parameters for affine registration via symmetric block-matching. the subsequent non-rigid ffd registration used a gaussian kernel with standard deviation equal to 5 mm for lncc calculation, control point spacing equal to 10 mm, and bending energy constraint equal to 0.1. registrations were run using niftyreg (version 1.3; available online: ',\n",
       " ' (accessed on 1 october 2018). through visual inspection, satisfactory registration was observed for the majority of prostatex and picture dataset cases. no manual steps were taken to correct any instances of misregistration, and cases with misregistration were not excluded from our analysis.',\n",
       " 't2wi, registered adc maps and computed b2000 (cb2000) dwi, and pz and cg probability maps, were resampled to a common in-plane resolution of 0.4018 mm × 0.4018 mm and cropped to a common in-plane shape of 256 × 256, centred on the prostate.',\n",
       " 'like zone-u-net, the training settings for cspca-u-net were determined through tenfold cross-validation using the prostatex dataset with the fold splits shown in ',\n",
       " '. cspca-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to 12, adam optimization, a dropout probability of ',\n",
       " ' for central dropout, a hybrid loss composed of the sum of dice loss multiplied by 0.5 and focal loss multiplied by 1.0, and horizontal flip (probability = 0.5), rotation (−20°, 20°), and scaling (−10%, +20%) augmentations. the same dropout probability and augmentation settings were used for test-time dropout and test-time augmentation.',\n",
       " 'cspca probability maps output by cspca-u-net for each fold were calibrated using separate isotonic calibration modules for each fold. following calibration, cspca probability maps were thresholded using cut-off values determined for each fold, corresponding to a lesion-level sensitivity of 93% and specificity of 37%, in the fold’s training set. the aforementioned sensitivity and specificity correspond to reference radiologist performance at pi-rads v1 cut-off ≥ 4 on a separate patient cohort from radboud medical center, reported on in litjens et al. [',\n",
       " '], which was used since prospective radiologist performance was not available for the prostatex dataset. as a final post-processing step, connected components smaller than 40 mm',\n",
       " 'following the tenfold cross-validation, the ten trained cspca-u-nets were used to construct cspca-u-net-e. cspca-u-net-e was calibrated using isotonic calibration. for thresholding, a cut-off value c = 4.5% was determined to match radiologist performance in the training set for cspca-u-net-e i.e., the entire prostatex dataset. for false-positive reduction, connected components smaller than 40 mm',\n",
       " 'whole-prostate and zonal segmentations were evaluated using the dice coefficient. prostate size measurements (transverse, anterior–posterior, and cranio–caudal lengths), as well as whole-prostate and zonal volumes, were evaluated using the abs%err; the ground-truth lengths and volumes used in the calculation of abs%err were derived from the manually-drawn whole-prostate and zonal contours. the psad estimated by autoprostate was evaluated using absolute error (abserr), since the absolute value of psad has a meaning relative to risk definitions [',\n",
       " ']; the ground-truth psad value used in the calculation of abserr was obtained by dividing psa by the whole-prostate volume calculated using the manually-drawn whole-prostate contour. the aforementioned evaluation metrics were calculated over the 80 patients from the picture dataset for which manually drawn whole-prostate and zonal segmentations were available.',\n",
       " 'receiver operating characteristic (roc) area under the curve (auc) and precision-recall (pr) auc were calculated to quantify autoprostate’s ability to differentiate between cspca lesions and ncspca lesions. after thresholding and false-positive reduction, sensitivity, specificity, and precision were calculated at lesion-level and average false positives were calculated at patient-level. for the picture dataset, the calculation of average false positives was made using 93 patients who were biopsy-negative for cspca, due to limitations in the ground-truth prohibiting false-positive determination in biopsy positive patients. in addition, cspca lesion dice and abs%err of lesion area were calculated on slices containing a contour.',\n",
       " 'prostate volume, psad, and lesion detection metrics computed for autoprostate were compared to the same metrics calculated for an experienced radiologist (s.p., 10 years’ experience in scoring prostate mpmri) who prospectively filled out a case report for each patient. prostate volume was estimated using the ellipsoid formula and lesions were scored using a five-point likert scale [',\n",
       " ']. statistical tests were used to compare the performances of autoprostate and the experienced radiologist. the wilcoxon’s signed-rank test [',\n",
       " '] was used to statistically compare precision, and wilcoxon’s signed-rank test was used to statistically compare average false positives.',\n",
       " ' 4. results',\n",
       " 'autoprostate, trained using the prostatex dataset, was externally validated using the picture dataset. this section presents the results of the cross-validation of zone-u-net and cspca-u-net (the building blocks of autoprostate) and a detailed analysis of the external validation of autoprostate using the picture dataset, with comparisons made to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpmri, where possible.',\n",
       " '., cspca-u-net achieved a mean roc auc of 0.85 and a mean pr auc of 0.70. after thresholding, cspca-u-net achieved a mean sensitivity of 93%, a mean specificity of 37%, a mean precision of 34%, and a mean false-positive count per patient of 6.9. following false-positive reduction, mean sensitivity dropped marginally to 92%, mean specificity increased to 46%, mean precision increased to 37%, and mean false positives per patient dropped significantly to 3.3 (',\n",
       " ' 4.2. autoprostate external validation analysis: whole-prostate and zonal segmentations, prostate size measurements, and psa density',\n",
       " ' present summaries of the distribution of dice coefficients for whole-prostate and zonal segmentations, the distribution of abs%err for prostate size measurements, and the distribution of abserr for psad calculation, for 80 patients from the picture dataset for which ground-truth segmentations were available.',\n",
       " 'mean dice coefficients of 0.75, 0.80, and 0.89 were obtained for the pz, cg, and whole-prostate, respectively. autoprostate’s zone-segmenter module found pz segmentation a more difficult task than cg segmentation, while whole-prostate segmentation had a higher mean dice coefficient than both zonal segmentations, suggesting an ease of distinguishing prostate tissue from background tissues, but a difficulty in distinguishing between pz and cg tissue. as expected, the mean dice coefficients for the pz, cg, and whole-prostate segmentations were lower than those obtained on the prostatex dataset during the tenfold cross-validation of zone-u-net (0.78, 0.86, and 0.91 for pz, cg, and whole-prostate segmentation, respectively) which may be indicative of a generalization gap due to acquisition/population differences.',\n",
       " 'the transverse, anterior–posterior, and cranio–caudal lengths of the prostate were estimated using the whole-prostate segmentation output by zone-segmenter. mean abs%err of 3%, 5%, and 20% were obtained for transverse, anterior–posterior, and cranio–caudal lengths, respectively. in addition to the lowest mean abs%err, the transverse length had a smaller standard deviation than anterior–posterior and cranio–caudal lengths. through visual inspection of segmentation outputs, we attribute the variability in the accuracy of the anterior–posterior measurement to the difficulty of determining prostate extent in the anterior fibromuscular stroma, and similarly, we attribute the variability in the accuracy of the cranio–caudal measurement to the difficulty of determining prostate extent at the base and apex regions of the prostate. strikingly, a large maximum abs%err of 100% was observed for the cranio–caudal measurement, due to under-segmentation of the base region in the ground-truth.',\n",
       " 'pz, cg, and whole-prostate volumes were calculated using the pz, cg, and whole-prostate segmentations output by zone-segmenter. mean abs%errs of 12%, 18%, and 9% were obtained for pz, cg, and whole-prostate volumes, respectively. strikingly, a large maximum abs%err of 112% was observed for the cg, which was found to be due to over-segmentation of the cg in the base region.',\n",
       " 'we compare the abs%err of the whole-prostate volume calculated by autoprostate to the same calculated by the experienced radiologist who used the ellipsoid formula, which is clinically advocated. autoprostate had a mean abs%err of 9%, while the experienced radiologist’s mean abs%err was 13%; the difference was statistically significant (',\n",
       " ' 0.05). using the whole-prostate volumes computed by autoprostate and the experienced radiologist, psad was calculated. autoprostate achieved a mean abserr of 0.019, while the experienced radiologist’s mean abserr was 0.031; again, the difference was statistically significant (',\n",
       " ' 4.3. autoprostate external validation analysis: clinically significant prostate cancer lesion detection and segmentation',\n",
       " 'autoprostate achieved a mean roc auc of 0.70 and a mean pr auc of 0.84, calculated using output cspca probability maps prior to thresholding. after thresholding the cspca probability maps using a cut-off value equal to 4.5%, the following were obtained: a sensitivity of 78%, a specificity of 49%, a precision of 78%, and a mean false-positive count of 6.1. following false-positive reduction, mean sensitivity dropped marginally to 76%, mean specificity increased to 57%, mean precision increased marginally to 80%, and the mean false-positive count per patient dropped to 2.5.',\n",
       " 'likert scores assigned to suspicious lesions by the experienced radiologist were used to calculate roc and pr curves; radiologist likert scoring gave a roc auc of 0.64 and pr auc of 0.78. after thresholding at cut-off score likert ≥ 4, the following were obtained: a sensitivity of 78%, a specificity of 48%, a precision of 78%, and a mean false-positive count of 0.3. differences between the roc auc, pr auc, sensitivity, specificity, and precision of autoprostate and the experienced radiologist were not statistically significant. however, the difference between mean false positives was statistically significant (',\n",
       " 'a further analysis was completed to assess the level of agreement between autoprostate and the experienced radiologist’s likert scores, on annotated lesions, as shown in ',\n",
       " '. for cspca lesions, there was a 78% (114/147) concordance between autoprostate and the experienced radiologist, while for ncspca lesions, there was a 62% (39/63) concordance.',\n",
       " 'autoprostate’s lesion segmentations enable the calculation of lesion volume and lesion minimum adc. lesion segmentation accuracy, evaluated using the dice coefficient, was calculated using slices containing a corresponding ground-truth cspca lesion contour. the following dice coefficient metrics were obtained: a mean of 0.46 (sd: 0.32), a median of 0.58 (iqr: 0.10–0.72), and a min–max range of 0.00–0.90. several example cspca lesion segmentations are presented in ',\n",
       " '. examples are shown in the pz and cg, and in the base, midgland, and apex regions of the prostate. in addition, examples have been included to demonstrate autoprostate’s robustness to magnetic susceptibility artifacts. furthermore, an example automatic report generated by autoprostate is shown in ',\n",
       " ' 5. discussion',\n",
       " 'in this work, we introduced autoprostate, a deep learning-powered framework for automatic mri-based prostate cancer assessment. autoprostate consists of three modules: zone-segmenter, cspca-segmenter, and report-generator. the output of autoprostate is an automatic web-based report that presents patient details, prostate size measurements and psad, a listing of candidate cspca lesions with derived characteristics, and a findings summary. autoprostate, trained using the publicly available prostatex dataset, was externally validated using the picture dataset. during the external validation, the performance of autoprostate was compared to the performance of an experienced radiologist with 10 years’ experience in reading prostate mpmri, who prospectively estimated prostate volume and psad using the ellipsoid formula, and scored lesions using a five-point likert scale.',\n",
       " 'pz, cg, and whole-prostate segmentations are output by autoprostate’s zone-segmenter module. during the experimental setup phase, we tested zone-u-net, prior to ensembling of zone-u-nets to form zone-u-net-e. zone-u-net achieved mean dice coefficients of 0.78, 0.86, and 0.91 for pz, cg, and whole-prostate segmentation, respectively, in tenfold cross-validation using the prostatex dataset. our result compares well to recent works by aldoj et al. [',\n",
       " '], where their proposed dense-2 u-net cnn was evaluated using fourfold cross-validation of a 188-patient subset from the prostatex dataset, and to a recent work by cuocolo et al. [',\n",
       " '] was evaluated using a 105-patient test set from the prostatex dataset. aldoj et al. obtained mean dice coefficients of 0.78, 0.91, and 0.92, and cuocolo et al. obtained mean dice coefficients of 0.71, 0.87, and 0.91, for pz, cg, and whole-prostate segmentation, respectively. however, direct comparison between our work and the works of aldoj et al. and cuocolo et al. is not possible due to the use of different subsets of data for testing. during the external validation of autoprostate using the picture dataset, where zone-u-net-e was used for pz, cg, and whole-prostate segmentation, autoprostate achieved mean dice coefficients of 0.75, 0.80, and 0.89, respectively, on 80 patients for which ground-truth segmentations were available. antonelli et al. [',\n",
       " '] previously reported segmentation results for the picture dataset. a multi-atlas segmentation approach featuring a novel genetic atlas selection strategy was proposed; mean dice coefficients of 0.72 and 0.83 were reported for pz and cg segmentation, using leave-one-out cross-validation, and a mean dice coefficient of 0.83 was reported for whole-prostate segmentation, using atlases from the promise12 dataset [',\n",
       " ']. autoprostate’s estimate of prostate volume was compared to an estimate obtained using the ellipsoid formula, which is clinically advocated [',\n",
       " ']. autoprostate achieved a mean abs%err of 9%, while the radiologist computed ellipsoid formula estimate had a mean abs%err of 13%. notably, the difference in mean abs%err was statistically significant (',\n",
       " '. furthermore, we compared psad estimates obtained using the volume estimates; we found a mean abserr of 0.019 for autoprostate and a mean abserr of 0.031 for the radiologist; again, the difference was statistically significant (',\n",
       " 'autoprostate’s foremost purpose is to detect and segment cspca lesions. during the experimental setup phase, we tested cspca-u-net, prior to ensembling of cspca-u-nets to form cspca-u-net-e. markedly, cspca-u-net achieved a lesion-level mean roc auc of 0.85 in tenfold cross-validation using the prostatex dataset, while previous studies have reported a lesion-level mean roc auc of 0.81 on the same subset of prostatex data used in this study, using the same input modalities. during the external validation of autoprostate using the picture dataset, where cspca-u-net-e was used to segment cspca lesions, autoprostate achieved a lesion-level roc auc of 0.70. notably, we observed a large reduction in roc auc on the picture dataset from that seen during the prostatex dataset tenfold cross-validation. we believe that the main reason for the reduction in roc auc is the use of ttpm biopsy in the picture study, which allowed lesions that were not prospectively identified by the radiologist, to be retrospectively contoured using ttpm biopsy findings. other reasons may include a high occurrence of magnetic susceptibility artifacts on dwi in the picture dataset and a possible generalization gap between training data and external testing data due to population/acquisition differences. on the picture dataset, radiologist likert assessment achieved a lesion-level roc auc of 0.64; the difference in roc auc between autoprostate and the experienced radiologist was not statistically significant. following thresholding and false-positive reduction, autoprostate achieved a lesion-level sensitivity of 76%, a lesion-level specificity of 57%, and 2.5 false positives per patient (calculated over patients without cspca, only). in comparison, radiologist likert assessment thresholded at likert ≥ 4, achieved a lesion-level sensitivity of 78%, a lesion-level specificity of 48%, and 0.3 false positives per patient (calculated over patients without cspca, only); only the difference between the number of false positive detections by autoprostate and the experienced radiologist was statistically significant (',\n",
       " '). while autoprostate has demonstrated an ability to differentiate between cspca lesions and low-grade/benign lesions at the level of an experienced radiologist, further work is needed to reduce the number of false positives produced. interestingly, autoprostate achieved a similar sensitivity and improved specificity compared to the radiologist on annotated cspca and ncspca lesions but had a higher overall false-positive count. therefore, it’s possible that the additional false positives produced by autoprostate, that were not prospectively scored by the radiologist, may be easy for radiologists to rule-out.',\n",
       " 'several aspects of this study have been guided by the set of nine key considerations for authors, reviewers, and readers of artificial intelligence studies in radiology by bluemke et al. [',\n",
       " ']. as recommended, we maintained a clear separation between training data and testing data. in particular, we avoided a common pitfall observed in previous studies [',\n",
       " '], by determining the probability cut-off value using training data, rather than a biased approach involving the test data itself. in line with further recommendations by bluemke et al., we were able to externally validate autoprostate using the picture dataset. furthermore, the picture dataset was acquired using phillips’ scanners, while the prostatex dataset, used to train autoprostate, was acquired using siemens’ scanners, meaning a further recommendation on using multivendor data for evaluation was met. moreover, we compared autoprostate to an expert radiologist who prospectively reported picture dataset patients, and both autoprostate and the radiologist were compared to an accepted reference standard which combined ttpm and mr-guided targeted biopsies; ttpm biopsy is highly accurate and avoids biases associated to mr-guided targeted biopsy, transrectal ultrasound-guided (trus) biopsy, and prostatectomy [',\n",
       " 'cad system studies should describe how the cad system will be deployed clinically, so future prospective trials can be planned accordingly. our goal in this study was to understand the strengths, weaknesses, and idiosyncrasies of autoprostate through a comparison against an experienced radiologist. in the clinical workflow, we envision autoprostate as a radiologist companion system during clinical reads to allow enhanced clinical reporting. it should be acknowledged that current cad systems for mri-based prostate cancer diagnosis contain varying degrees of error in terms of producing too many false positives, false negatives, or both. since the automatic report produced by autoprostate presents visual segmentation outputs, as well as derived measurements, all outputs produced by autoprostate can be rapidly verified by the radiologist. in particular, automatic report information deemed to be accurate can be used to prepare the patient’s clinical report, while erroneous information can be recalculated using current clinical methods or ignored if not required.',\n",
       " 'there were three limitations in our study. firstly, our training data was limited to 76 cspca lesions and 223 ncspca lesions; we may expect improved detection sensitivity and reduced false positives if a bigger training dataset with more lesions is available. secondly, our external validation was limited to a single external site. thirdly, lesion contours for each picture dataset patient were drawn by a single radiologist only. while the location and gleason score of lesions was confirmed by a combination of ttpm and mr-guided targeted biopsies, we were not able to overcome the inter-reader variation known to exist in lesion boundary determination [',\n",
       " 'our future work will be to perform a prospective validation of autoprostate. in particular, we will plan a clinical trial that investigates the impact of the automatic report on the prospective clinical read of radiologists of varying levels of experience. in preparation for the prospective validation, we will seek a larger multi-centre and multi-vendor training dataset.',\n",
       " ' 6. conclusions',\n",
       " 'in this work, we presented autoprostate for automatic mri-based prostate cancer assessment. external validation using the picture dataset demonstrated statistically significant improvements in prostate volume and psa density estimation and no statistically significant differences in cspca lesion detection performance, when compared to an experienced radiologist with over 10 years’ experience in reading prostate mpmri. however, further work is needed to reduce the number of false positives produced by autoprostate, prior to prospective validation.',\n",
       " ' supplementary materials',\n",
       " ', section s1: zone-u-net architecture, section s2: cspca-u-net architecture, table s1: prostatex dataset characteristics, table s2: picture dataset characteristics, table s3: ten-fold cross-validation fold split of the prostatex dataset. lesion significance, size, and zone were used for fold stratification.',\n",
       " 'conceptualization, p.m., m.a. and s.o.; methodology, p.m. and m.a.; software, p.m.; formal analysis, p.m. and m.a.; data curation, p.m., m.a., s.s., n.g., e.w.j., h.u.a., m.e. and s.p.; writing—original draft preparation, p.m.; writing—review and editing, p.m., m.a., s.s., n.g., e.w.j., h.u.a., m.e., s.p. and s.o.; supervision, m.a., s.p. and s.o. all authors have read and agreed to the published version of the manuscript.',\n",
       " 'our institutional review board approved the study and waived the requirement for individual consent for retrospective analysis of prospectively acquired patient data collected as part of clinical trials/routine care (rd no: 12/0195, 16 july 2012).',\n",
       " 'prostatex dataset data citation: geert litjens, oscar debats, jelle barentsz, nico karssemeijer, and henkjan huisman. “prostatex challenge data”, the cancer imaging archive (2017). doi: 10.7937/k9tcia.2017.murs5cl. prostatex dataset masks citation: r. cuocolo, a. stanzione, a. castaldo, d.r. de lucia, m. imbriaco, quality control and whole-gland, zonal and lesion annotations for the prostatex challenge public dataset, eur. j. radiol. (2021).',\n",
       " 'p.m.’s research is supported by the engineering and physical sciences research council (epsrc) [ep/r512400/1]. p.m.’s work was additionally supported by the epsrc-funded ucl centre for doctoral training in intelligent, integrated imaging in healthcare (i4health) [ep/s021930/1]. m.a.’s research is supported by the wellcome/epsrc centre for medical engineering king’s college london and by the london medical imaging and ai centre for value-based healthcare. h.u.a.’s research is supported by core funding from the uk’s national institute of health research (nihr) imperial biomedical research centre. hua currently also receives funding from the wellcome trust, medical research council (uk), cancer research uk, prostate cancer uk, the urology foundation, bma foundation, imperial health charity, sonacare inc., trod medical and sophiris biocorp for trials in prostate cancer. m.e. and s.p. receive research support from the university college london/university college london hospital (ucl/uclh) biomedical research centre.',\n",
       " 'h.u.a. is a paid consultant to boston scientific for teaching and training on rezum for benign prostate hyperplasia treatment and cryotherapy for prostate cancer treatment and is paid for teaching and proctoring hifu for treating prostate cancer. m.e. receives honoraria from consulting, educational activities, and training from: sonacare inc.; nina medical; and angiodynamics inc. all other authors declare no conflicts of interest.',\n",
       " 'ahmed, h.u.; el-shater bosaily, a.; brown, l.c.; gabe, r.; kaplan, r.; parmar, m.k.; collaco-moraes, y.; ward, k.; hindley, r.g.; freeman, a.; et al. diagnostic accuracy of multi-parametric mri and trus biopsy in prostate cancer (promis): a paired validating confirmatory study. ',\n",
       " 'brembilla, g.; dell’oglio, p.; stabile, a.; damascelli, a.; brunetti, l.; ravelli, s.; cristel, g.; schiani, e.; venturini, e.; grippaldi, d.; et al. interreader variability in prostate mri reporting using prostate imaging reporting and data system version 2.1. ',\n",
       " 'stanzione, a.; ponsiglione, a.; di fiore, g.a.; picchi, s.g.; di stasi, m.; verde, f.; petretta, m.; imbriaco, m.; cuocolo, r. prostate volume estimation on mri: accuracy and effects of ellipsoid and bullet-shaped measurements on psa density. ',\n",
       " 'distler, f.a.; radtke, j.p.; bonekamp, d.; kesch, c.; schlemmer, h.-p.; wieczorek, k.; kirchner, m.; pahernik, s.; hohenfellner, m.; hadaschik, b.a. the value of psa density in combination with pi-rads',\n",
       " 'yang, x.; lei, y.; wang, t.; jiang, x.; jani, a.; mao, h.; curran, w.; patel, p.; liu, t.; wang, b. 3d prostate segmentation in mr image using 3d deeply supervised convolutional neural networks. ',\n",
       " 'aldoj, n.; biavati, f.; michallek, f.; stober, s.; dewey, m. automatic prostate and prostate zones segmentation of magnetic resonance images using densenet-like u-net. ',\n",
       " 'cuocolo, r.; comelli, a.; stefano, a.; benfante, v.; dahiya, n.; stanzione, a.; castaldo, a.; de lucia, d.r.; yezzi, a.; imbriaco, m. deep learning whole-gland and zonal prostate segmentation on a public mri dataset. ',\n",
       " 'milletari, f.; navab, n.; ahmadi, s. v-net: fully convolutional neural networks for volumetric medical image segmentation. in proceedings of the fourth international conference on 3d vision (3dv), stanford, ca, usa, 25–28 october 2016. [',\n",
       " 'comelli, a.; dahiya, n.; stefano, a.; vernuccio, f.; portoghese, m.; cutaia, g.; bruno, a.; salvaggio, g.; yezzi, a. deep learning-based methods for prostate segmentation in magnetic resonance imaging. ',\n",
       " 'lee, d.k.; sung, d.j.; kim, c.-s.; heo, y.; lee, j.y.; park, b.j.; kim, m.j. three-dimensional convolutional neural network for prostate mri segmentation and comparison of prostate volume measurements by use of artificial neural network and ellipsoid formula. ',\n",
       " 'litjens, g.; toth, r.; van de ven, w.; hoeks, c.; kerkstra, s.; van ginneken, b.; vincent, g.; guillard, g.; birbeck, n.; zhang, j.; et al. evaluation of prostate segmentation algorithms for mri: the promise12 challenge. ',\n",
       " 'cao, r.; mohammadian bajgiran, a.; afshari mirak, s.; shakeri, s.; zhong, x.; enzmann, d.; raman, s.; sung, k. joint prostate cancer detection and gleason score prediction in mp-mri via focalnet. ',\n",
       " 'giannini, v.; mazzetti, s.; armando, e.; carabalona, s.; russo, f.; giacobbe, a.; muto, g.; regge, d. multiparametric magnetic resonance imaging of the prostate with computer-aided detection: experienced observer performance study. ',\n",
       " 'schelb, p.; kohl, s.; radtke, j.p.; wiesenfarth, m.; kickingereder, p.; bickelhaupt, s.; kuder, t.a.; stenzinger, a.; hohenfellner, m.; schlemmer, h.-p.; et al. classification of cancer at prostate mri: deep learning versus clinical pi-rads assessment. ',\n",
       " 'thon, a.; teichgraber, u.; tennstedt-schenk, c.; hadjidemetriou, s.; winzler, s.; malich, a.; papageorgiou, i. computer aided detection in prostate cancer diagnostics: a promising alternative to biopsy? a retrospective study from 104 lesions with histological ground truth. ',\n",
       " 'greer, m.d.; lay, n.; shih, j.h.; barrett, t.; bittencourt, l.k.; borofsky, s.; kabakus, i.; law, y.m.; marko, j.; shebel, h.; et al. computer-aided diagnosis prior to conventional interpretation of prostate mpmri: an international multi-reader study. ',\n",
       " 'gaur, s.; lay, n.; harmon, s.a.; doddakashi, s.; mehralivand, s.; argun, b.; barrett, t.; bednarova, s.; girometti, r.; karaarslan, e.; et al. can computer-aided diagnosis assist in the identification of prostate cancer on prostate mri? a multi-center, multi-reader investigation. ',\n",
       " 'zhu, l.; gao, g.; liu, y.; han, c.; liu, j.; zhang, x.; wang, x. feasibility of integrating computer-aided diagnosis with structured reports of prostate multiparametric mri. ',\n",
       " 'ronneberger, o.; fischer, p.; brox, t. u-net: convolutional networks for biomedical image segmentation. in proceedings of the international conference on medical image computing and computer-assisted intervention, munich, germany, 5–9 october 2015; springer: cham, switzerland, 2015; pp. 234–241. [',\n",
       " 'zhu, w.; huang, y.; zeng, l.; chen, x.; liu, y.; qian, z.; du, n.; fan, w.; xie, x. anatomynet: deep learning for fast and fully automated whole-volume segmentation of head and neck anatomy. ',\n",
       " 'gal, y.; ghahramani, z. dropout as a bayesian approximation: representing model uncertainty in deep learning. in proceedings of the 33rd international conference on machine learning, icml 2016, new york, ny, usa, 20–22 june 2016; volume 48, pp. 1651–1660. [',\n",
       " 'wang, g.; li, w.; aertsen, m.; deprest, j.; ourselin, s.; vercauteren, t. aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks. ',\n",
       " 'simmons, l.a.m.; kanthabalan, a.; arya, m.; briggs, t.; barratt, d.; charman, s.c.; freeman, a.; gelister, j.; hawkes, d.; hu, y.; et al. the picture study: diagnostic accuracy of multiparametric mri in men requiring a repeat prostate biopsy. ',\n",
       " 'bluemke, d.a.; moy, l.; bredella, m.a.; ertl-wagner, b.b.; fowler, k.j.; goh, v.j.; halpern, e.f.; hess, c.p.; schiebler, m.l.; weiss, c.r. assessing radiology research on artificial intelligence: a brief guide for authors, reviewers, and readers-from the radiology editorial board. ',\n",
       " 'verma, s.; sarkar, s.; young, j.; venkataraman, r.; yang, x.; bhavsar, a.; patil, n.; donovan, j.; gaitonde, k. evaluation of the impact of computed high b-value diffusion-weighted imaging on prostate cancer detection. ',\n",
       " 'blackledge, m.d.; leach, m.o.; collins, d.j.; koh, d.-m.; may, i.; tumor, i.; blackledge, m.d.; leach, m.o.; collins, d.j. computed diffusion-weighted mr imaging may improve tumor detection. ',\n",
       " 'modat, m.; ridgway, g.r.; taylor, z.a.; lehmann, m.; barnes, j.; hawkes, d.j.; fox, n.c.; ourselin, s. fast free-form deformation using graphics processing units. ',\n",
       " 'comput. methods programs biomed.',\n",
       " 'bonekamp, d.; kohl, s.; wiesenfarth, m.; schelb, p.; radtke, j.p.; gotz, m.; kickingereder, p.; yaqubi, k.; hitthaler, b.; gahlert, n.; et al. radiomic machine learning for characterization of prostate lesions with mri: comparison to adc values. ',\n",
       " 'isensee, f.; petersen, j.; klein, a.; zimmerer, d.; jaeger, p.f.; kohl, s.; wasserthal, j.; koehler, g.; norajitra, t.; wirkert, s.; et al. nnu-net: self-adapting framework for u-net-based medical image segmentation. ',\n",
       " 'hosseinzadeh, m.; brand, p.; huisman, h. effect of adding probabilistic zonal prior in deep learning-based prostate cancer detection. in proceedings of the medical imaging with deep learning (midl), london, uk, 8–10 july 2019. [',\n",
       " 'kendall, a.; badrinarayanan, v.; cipolla, r. bayesian segnet: model uncertainty in deep convolutional encoder-decoder architectures for scene understanding. in proceedings of the proceedings of the british machine vision conference (bmvc), london, uk, 4–7 september 2017. [',\n",
       " 'zadrozny, b.; elkan, c. transforming classifier scores into accurate multiclass probability estimates. in proceedings of the proceedings of the acm sigkdd international conference on knowledge discovery and data mining, edmonton, ab, canada, 23–26 july 2002; pp. 694–699. [',\n",
       " 'cuocolo, r.; stanzione, a.; castaldo, a.; de lucia, d.r.; imbriaco, m. quality control and whole-gland, zonal and lesion annotations for the prostatex challenge public dataset. ',\n",
       " 'picture: prostate imaging (multi-sequence mri and prostate histoscanning tm ) compared to transperineal ultrasound guided biopsy for significant prostate cancer risk evaluation case report form',\n",
       " 'dickinson, l.; ahmed, h.u.; allen, c.; barentsz, j.o.; carey, b.; futterer, j.j.; heijmink, s.w.; hoskin, p.j.; kirkham, a.; padhani, a.r.; et al. magnetic resonance imaging for the detection, localisation, and characterisation of prostate cancer: recommendations from a european consensus meeting. ',\n",
       " 'wang, n.n.; fan, r.e.; leppert, j.t.; ghanouni, p.; kunder, c.a.; brooks, j.d.; chung, b.i.; sonn, g.a. performance of multiparametric mri appears better when measured in patients who undergo radical prostatectomy. ',\n",
       " 'kingma, d.p.; ba, j. adam: a method for stochastic optimization. in proceedings of the international conference on learning representations, san diego, ca, usa, 7–9 may 2015. [',\n",
       " 'litjens, g.j.; barentsz, j.o.; karssemeijer, n.; huisman, h.j. clinical evaluation of a computer-aided diagnosis system for determining cancer aggressiveness in prostate mri. ',\n",
       " 'nice prostate cancer: diagnosis and management. national institute of health and care excellence: guidelines. 2019. available online: ',\n",
       " 'delong, e.r.; delong, d.m.; clarke-pearson, d.l. comparing the areas under two or more correlated receiver operating characteristic curves : a nonparametric approach. ',\n",
       " 'antonelli, m.; cardoso, m.j.; johnston, e.w.; appayya, m.b.; presles, b.; modat, m.; punwani, s.; ourselin, s. gas: a genetic atlas selection strategy in multi-atlas segmentation framework. ',\n",
       " 'borofsky, s.; george, a.k.; gaur, s.; bernardo, m.; greer, m.d.; mertan, f.v.; taffel, m.; moreno, v.; merino, m.j.; wood, b.j.; et al. what are we missing? false-negative cancers at multiparametric mr imaging of the prostate. ',\n",
       " 'littrup, p.j.; williams, c.r.; egglin, t.k.; kane, r.a. determination of prostate volume with transrectal us for cancer screening: part ii. accuracy of in vitro and in vivo techniques. ',\n",
       " 'brizmohun appayya, m.; adshead, j.; ahmed, h.u.; allen, c.; bainbridge, a.; barrett, t.; giganti, f.; graham, j.; haslam, p.; johnston, e.w.; et al. national implementation of multi-parametric magnetic resonance imaging for prostate cancer detection – recommendations from a uk consensus meeting. ',\n",
       " 'steenbergen, p.; haustermans, k.; lerut, e.; oyen, r.; de wever, l.; van den bergh, l.; kerkmeijer, l.g.w.; pameijer, f.a.; veldhuis, w.b.; van der voort van zyp, j.r.n.; et al. prostate tumor delineation using multiparametric magnetic resonance imaging: inter-observer variability and pathology validation. ',\n",
       " ' autoprostate framework diagram. autoprostate consists of three modules: zone-segmenter (green), cspca-segmenter (blue), and report-generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. yellow boxes indicate autoprostate inputs from external sources. ',\n",
       " ' autoprostate framework diagram. autoprostate consists of three modules: zone-segmenter (green), cspca-segmenter (blue), and report-generator (purple); solid boxes correspond to module computations, while dashed boxes correspond to module outputs. yellow boxes indicate autoprostate inputs from external sources.',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available: (',\n",
       " ') distribution of abserr for psad calculated by autoprostate and the experienced radiologist; the ground-truth psad value used to compute the abserr for autoprostate and the experienced radiologist was calculated by dividing psa by the whole-prostate volume derived from the ground-truth whole-prostate segmentation. ',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available: (',\n",
       " ') distribution of abserr for psad calculated by autoprostate and the experienced radiologist; the ground-truth psad value used to compute the abserr for autoprostate and the experienced radiologist was calculated by dividing psa by the whole-prostate volume derived from the ground-truth whole-prostate segmentation.',\n",
       " ' picture dataset axial t2wi, adc map, cb2000 dwi, ground-truth lesion contour overlaid on t2wi, probability map overlaid on t2wi, and segmentation overlaid on t2wi: (a) 79-year-old man, psa 12.57 ng/ml, midgland pz gs 4 + 3 lesion, likert 5, autoprostate probability of cspca 100%; (b) 66-year-old man, psa 7.50 ng/ml, midgland pz gs 3 + 4 lesion, likert 3, autoprostate probability of cspca 65%; (c) 64-year-old man, psa 10.53 ng/ml, apex cg gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 95%; (d) 56-year-old man, psa 7.91 ng/ml, base cg gs 3 + 4 lesion, likert 4, autoprostate probability of cspca 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on dwi, psa 6.15 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, psa 4.09 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 49%. ',\n",
       " ' picture dataset axial t2wi, adc map, cb2000 dwi, ground-truth lesion contour overlaid on t2wi, probability map overlaid on t2wi, and segmentation overlaid on t2wi: (a) 79-year-old man, psa 12.57 ng/ml, midgland pz gs 4 + 3 lesion, likert 5, autoprostate probability of cspca 100%; (b) 66-year-old man, psa 7.50 ng/ml, midgland pz gs 3 + 4 lesion, likert 3, autoprostate probability of cspca 65%; (c) 64-year-old man, psa 10.53 ng/ml, apex cg gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 95%; (d) 56-year-old man, psa 7.91 ng/ml, base cg gs 3 + 4 lesion, likert 4, autoprostate probability of cspca 66%; (e) 60-year-old man with stable rectal gas-induced magnetic susceptibility artefact on dwi, psa 6.15 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 88%; and (f) 73-year-old man with bowel peristalsis-induced magnetic susceptibility artifact, psa 4.09 ng/ml, midgland pz gs 3 + 4 lesion, likert 5, autoprostate probability of cspca 49%.',\n",
       " ' autoprostate report for a 64-year-old man with psa equal to 10.53 ng/ml who participated in the picture study. lesion 1 (probability of cspca equal to 95%) corresponds to a biopsy-proven gs 3+4 lesion, while lesion 2 and lesion 3 (probabilities of cspca equal to 46% and 7%, respectively) are false positives. ',\n",
       " ' autoprostate report for a 64-year-old man with psa equal to 10.53 ng/ml who participated in the picture study. lesion 1 (probability of cspca equal to 95%) corresponds to a biopsy-proven gs 3+4 lesion, while lesion 2 and lesion 3 (probabilities of cspca equal to 46% and 7%, respectively) are false positives.',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available. ',\n",
       " ' autoprostate external validation analysis of whole-prostate and zonal segmentations, prostate size measurements, and psad, using 80 patients from the picture dataset for which ground-truth segmentations were available.',\n",
       " 'abserr: absolute error; abs%err: absolute percentage error; iqr: interquartile range; max: maximum; min: minimum; psa: prostate-specific antigen; sd: standard deviation. ',\n",
       " ' picture dataset cspca lesion detection metrics for the experienced radiologist and autoprostate. mean and standard deviation of false positives per patient were calculated using the 93 picture dataset patients who were biopsy-negative for cspca, rather than over all patients, due to limitations in the ground-truth. all other metrics shown are calculated at the lesion level for the 147 cspca lesions and 63 ncspca lesions. ',\n",
       " ' picture dataset cspca lesion detection metrics for the experienced radiologist and autoprostate. mean and standard deviation of false positives per patient were calculated using the 93 picture dataset patients who were biopsy-negative for cspca, rather than over all patients, due to limitations in the ground-truth. all other metrics shown are calculated at the lesion level for the 147 cspca lesions and 63 ncspca lesions.',\n",
       " '© 2021 by the authors. licensee mdpi, basel, switzerland. this article is an open access article distributed under the terms and conditions of the creative commons attribution (cc by) license (',\n",
       " ' are solely those of the individual authors and contributors and not of the publisher and the editor(s). mdpi stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. ',\n",
       " 'construction materials',\n",
       " 'electronic materials',\n",
       " 'materials',\n",
       " 'materials proceedings',\n",
       " 'methods and protocols',\n",
       " 'nanomaterials',\n",
       " ' the statements, opinions and data contained in the journals are solely those of the individual authors and contributors and not of the publisher and the editor(s). mdpi stays neutral with regard to jurisdictional claims in published maps and institutional affiliations. ',\n",
       " \"(function(){window['__cf$cv$params']={r:'717ab4d6bb577697',m:'pugpch2z0ujqjtpqibdzr.vkizvcmd4jdho3_hetd94-1654618735-0-acjo/plnr+nbsdravaugjmqcs+smbpetas45yzd9m7uyxopyghgmq8w7hf1xeu7adj7hktapshcotkuud0gh/9jz2obx1gwncvftkb5leslq6z3vyt1qzr3wouz5bq+vdlykf5yqrmw1dzezriai9am=',s:[0x6b4cb4bde8,0x523482f19e],}})();\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cull_text = []\n",
    "\n",
    "for x in keep_text:\n",
    "    if lbracketcount(x) and rbracketcount(x) and tagcount(x) and hashcount(x) and divcount(x) and linecount(x):\n",
    "        cull_text.append(x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "cull_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe7cae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_candidates = []\n",
    "\n",
    "for i, x in enumerate(keep_text):\n",
    "    \n",
    "    method_following = []\n",
    "    method_text = []\n",
    "    \n",
    "    if methodtitle(x) == True:\n",
    "        method_following = keep_text[i:] #list of all elements following and including methods title\n",
    "        \n",
    "        for i, x in enumerate(method_following):\n",
    "            if 'esult' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"result title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            elif 'iscussion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"discussion title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            elif 'onclusion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"conclusion title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            else:\n",
    "                method_text = method_following\n",
    "        \n",
    "        method = ' '.join(method_text)\n",
    "        method_candidates.append(method)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "len(method_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c11199c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 2. methods , consists of three modules: zone-segmenter, cspca-segmenter, and report-generator. methodological aspects of each module are described in detail in the subsections to follow, while specific experimental parameters used to collect results are described in  t2w images are first resampled to a common in-plane resolution and cropped to a common in-plane shape, and then normalized by whitening of image voxel intensities. after pre-processing, each t2wi slice is segmented by an ensemble of 2d nnu-nets with task-specific hyperparameter modifications; we refer to each constituent 2d nnu-net as zone-u-net and the ensemble of zone-u-nets as zone-u-net-e. a detailed description of the zone-u-net architecture is given in  . the output of each zone-u-net is slice-wise pz, cg, and background probability maps. per-voxel averaging is used to combine the probability map outputs of each zone-u-net ∈ zone-u-net-e, followed by restacking of slices to form pz, cg, and background probability map volumes. the pz, cg, and background probability maps output by zone-u-net-e are transformed to the original t2wi shape and voxel resolution using padding and resampling operations. as a final step, a zonal segmentation map is obtained from the pz, cg, and background probability maps using a per-voxel argmax operation. the cspca-segmenter module detects and segments cspca lesions using each patient’s t2wi, apparent diffusion coefficient (adc) map, low b-value diffusion-weighted imaging (dwi), and pz and cg probability maps output by zone-segmenter. image registration is used to align adc maps and computed high b-value dwi to t2wi to account for voluntary/involuntary patient movement between t2wi and dwi acquisitions and differences in resolution. first, adc maps are affinely registered to t2wi using the symmetric block matching algorithm [ ], with the convolution-based fast local normalized correlation coefficient (lncc) similarity measure to enable robustness to bias field inhomogeneity [ ]. finally, the transformation obtained from the composition of both types of registration is used to register computed high b-value dwi to t2wi. t2wi, registered adc map and computed high b-value dwi, and pz and cg probability maps are resampled to a common in-plane resolution and cropped to a common in-plane shape, centred on the prostate; image cropping is used for memory efficiency. then, t2wi and computed high b-value dwi are normalized by dividing voxel intensities by the interquartile mean of cg voxel intensities. our approach is a modification of the normalization approach suggested by bonekamp et al. [ ], where voxel intensities were divided by the mean of pz voxel intensities. we opt for normalization using cg voxel intensities since cg segmentations are typically more reliable than pz segmentations [ ], and we opt for the interquartile mean of cg voxel intensities as opposed to the mean of all cg voxel intensities, to remove extremes that may correspond to abnormalities unique to a patient. adc maps were not normalized as they contain a quantitative measurement. after pre-processing, each slice of a patient’s t2wi, adc map, computed high b-value dwi, and pz and cg probability maps are input channel-wise to an ensemble of 2d nnu-nets for cspca lesion segmentation; the addition of pz and cg guidance as input has been shown to increase cspca lesion detection performance as the occurrence and appearance of prostate cancer is dependent on its zonal location [ ]. we refer to each constituent 2d nnu-net as cspca-u-net and the ensemble of cspca-u-nets as cspca-u-net-e. a detailed description of the cspca-u-net architecture is given in  ], i.e., dropout layers are inserted after the central three encoder units and two decoder units, with dropout probability equal to p. we model aleatoric uncertainty using test-time augmentation as in wang et al. [ the output of each cspca-u-net is slice-wise cspca probability maps. per-voxel averaging is used to combine the probability map outputs of each cspca-u-net ∈ cspca-u-net-e, followed by restacking of slices to form a probability map volume. the cspca probability map output by cspca-u-net-e is transformed to the original t2wi shape and voxel resolution using padding and resampling operations. next, probabilities are calibrated using an isotonic regression calibration module [ ], to allow more interpretable cspca likelihoods. cspca lesion segmentations are obtained by thresholding cspca probability maps using a cut-off value c; c is chosen during experimentation using training data to match autoprostate’s detection sensitivity and specificity to that of an experienced radiologist. finally, a false-positive reduction step is applied to remove connected components smaller than minsize mm the report-generator module generates an automatic report using input bpmri and clinical data, and the outputs of the zone-segmenter and cspca-segmenter modules; the report template is shown in  the left-hand pane contains interactive report elements including a patient selector and transverse, frontal, and sagittal views of zone and cspca lesion segmentation outputs overlaid on t2wi, with associated widgets for slice selection.  lengths of the prostate, in cm, are calculated using the maximum extents of the prostate on the whole-prostate segmentation, where the whole-prostate segmentation is the union of the pz and cg segmentations.   (base, midgland, or apex) are determined based on the location of the lesion centroid; our region determination follows the methodology outlined by litjens et al. [ ] for evaluating the promise12 challenge, where the apex is defined as the caudal-most third of the prostate, the base is the cranio-most third of the prostate, and the midgland is the remaining portion. the  in this section, we describe the datasets used for training and testing autoprostate, the methodological settings employed, and the evaluation measures used to assess performance. ], and externally validated using the prostate imaging compared to transperineal ultrasound-guided biopsy for significant prostate cancer risk evaluation (picture) study dataset [ mpmri was acquired using two 3-tesla magnetic field scanners (magnetom trio and skyra, siemens) and a pelvic-phased array coil. sequences collected included t2wi, adc map computed from dwi acquired at multiple b-values (50, 400, 800), and dcei with a temporal resolution of 3.5 s. all mpmri studies were reported by an experienced radiologist with over 20 years’ experience in reading prostate mpmri, who highlighted areas of suspicion per modality with a point marker and scored them using pi-rads v1. mr-guided targeted biopsies of marked points with pi-rads v1 score ≥ 3 were performed, while marked points with pi-rads v1 score 3 (unlikely for cspca) were not biopsied and assumed to be clinically insignificant (5% incidence of cspca in pi-rads v1 3 lesions at radboud university medical center). subsequently, biopsy specimens were graded by a histopathologist. the marked point coordinate and a ground-truth label (clinically significant equal to true or false) for each marked lesion was released publicly for 204 of the 346 patients, hence only these 204 patients feature in our work; clinical and histopathological characteristics are shown in  ]. in summary, contours were produced in consensus by radiology residents (2 years’ experience in reading prostate mpmri) and board-certified radiologists (5 years’ experience in reading prostate mpmri) at the university of naples. radiology residents and board-certified radiologists worked in pairs for quality control and annotation. whole-prostate and zonal contours (pz and cg) were drawn for each patient. in addition, 299 lesions were delineated, including 76 cspca lesions and 223 low-grade or benign lesions (ncspca). ]. men were examined at university college london hospital between 2012 and 2014. inclusion criteria for the picture study were: (i) men who had undergone an initial standard transrectal ultrasound-guided (trus) biopsy, but concern remained over the accuracy of the subsequent diagnosis; and (ii) men suitable for further characterization using transperineal template prostate-mapping (ttpm) biopsy. exclusion criteria were: (i) previous history of prostate cancer treatment; and (ii) lack of complete gland sampling or inadequate sampling density at ttpm. mpmri was acquired using a 3-tesla magnetic field scanner (achieva, philips healthcare) and a pelvic-phased array coil. sequences collected included t2wi, dwi with high b-value (2000), adc map computed from dwi acquired at multiple b-values (0, 150, 500, 1000), and dcei with a temporal resolution of 13 s. all mpmri studies were reported by an experienced radiologist with 10 years’ experience in reading prostate mpmri, using a five-point likert impression scale for the likelihood of cspca [ ]; cspca was defined as gleason score ≥ 3 + 4. scoring was completed at the lesion, sector, and patient-levels. clinical information, including the referral psa (ng/ml), was available to the radiologist during scoring to reflect clinical practice. men underwent mr-guided targeted biopsy of focal index lesions and ttpm biopsy with 5 mm sampling as the reference standard. ttpm biopsy was used to overcome the inaccuracies of trus biopsy [ in this work, two patients were removed due to missing mri data. clinical and histopathological characteristics for the 247 included patients are shown in  whole-prostate and zonal contours were drawn by a board-certified radiologist (e.w.j., 3 years’ experience in the quantitative analysis of prostate mpmri), for 80 patients. lesions were delineated by two board-certified radiologists (s.s. and n.g., 5 and 4-years’ experience in scoring prostate mpmri using likert assessment and pi-rads v2, respectively), who drew contours on a subset of cases each. the protocol for lesion contouring was agreed between the radiologists beforehand. first, histopathology reports from mr-guided targeted and ttpm biopsies were reviewed alongside mpmri to locate the highest gleason grade focal lesion; if there were multiple focal lesions with the maximum gleason grade, the highest scoring focal lesion according to likert or pi-rads v2 was identified. next, a single axial t2wi slice was selected corresponding to the centre of the identified lesion. then, all focal lesions on the selected slice were contoured. additionally, focal benign lesions that were scored likert or pi-rads v2 ≥ 4 were contoured in patients that were biopsy-negative for cancer. a total of 210 lesions were delineated, including 147 cspca lesions and 63 ncspca lesions.  3.2. methodological settings a tenfold cross-validation analysis of zone-u-net was conducted using the prostatex dataset to optimize training hyperparameters, loss function, and augmentations. fold splits are shown in  . zone-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to eight, adam optimization [ following the tenfold cross-validation, the ten trained zone-u-nets were used to construct zone-u-net-e; cross-validation ensembles have been shown to be an effective ensembling strategy [ the registration of adc maps to t2wi employed default parameters for affine registration via symmetric block-matching. the subsequent non-rigid ffd registration used a gaussian kernel with standard deviation equal to 5 mm for lncc calculation, control point spacing equal to 10 mm, and bending energy constraint equal to 0.1. registrations were run using niftyreg (version 1.3; available online:   (accessed on 1 october 2018). through visual inspection, satisfactory registration was observed for the majority of prostatex and picture dataset cases. no manual steps were taken to correct any instances of misregistration, and cases with misregistration were not excluded from our analysis. t2wi, registered adc maps and computed b2000 (cb2000) dwi, and pz and cg probability maps, were resampled to a common in-plane resolution of 0.4018 mm × 0.4018 mm and cropped to a common in-plane shape of 256 × 256, centred on the prostate. like zone-u-net, the training settings for cspca-u-net were determined through tenfold cross-validation using the prostatex dataset with the fold splits shown in  . cspca-u-net performed optimally when trained for 50 epochs with learning rate equal to 0.0001, batch size equal to 12, adam optimization, a dropout probability of   for central dropout, a hybrid loss composed of the sum of dice loss multiplied by 0.5 and focal loss multiplied by 1.0, and horizontal flip (probability = 0.5), rotation (−20°, 20°), and scaling (−10%, +20%) augmentations. the same dropout probability and augmentation settings were used for test-time dropout and test-time augmentation. cspca probability maps output by cspca-u-net for each fold were calibrated using separate isotonic calibration modules for each fold. following calibration, cspca probability maps were thresholded using cut-off values determined for each fold, corresponding to a lesion-level sensitivity of 93% and specificity of 37%, in the fold’s training set. the aforementioned sensitivity and specificity correspond to reference radiologist performance at pi-rads v1 cut-off ≥ 4 on a separate patient cohort from radboud medical center, reported on in litjens et al. [ ], which was used since prospective radiologist performance was not available for the prostatex dataset. as a final post-processing step, connected components smaller than 40 mm following the tenfold cross-validation, the ten trained cspca-u-nets were used to construct cspca-u-net-e. cspca-u-net-e was calibrated using isotonic calibration. for thresholding, a cut-off value c = 4.5% was determined to match radiologist performance in the training set for cspca-u-net-e i.e., the entire prostatex dataset. for false-positive reduction, connected components smaller than 40 mm whole-prostate and zonal segmentations were evaluated using the dice coefficient. prostate size measurements (transverse, anterior–posterior, and cranio–caudal lengths), as well as whole-prostate and zonal volumes, were evaluated using the abs%err; the ground-truth lengths and volumes used in the calculation of abs%err were derived from the manually-drawn whole-prostate and zonal contours. the psad estimated by autoprostate was evaluated using absolute error (abserr), since the absolute value of psad has a meaning relative to risk definitions [ ]; the ground-truth psad value used in the calculation of abserr was obtained by dividing psa by the whole-prostate volume calculated using the manually-drawn whole-prostate contour. the aforementioned evaluation metrics were calculated over the 80 patients from the picture dataset for which manually drawn whole-prostate and zonal segmentations were available. receiver operating characteristic (roc) area under the curve (auc) and precision-recall (pr) auc were calculated to quantify autoprostate’s ability to differentiate between cspca lesions and ncspca lesions. after thresholding and false-positive reduction, sensitivity, specificity, and precision were calculated at lesion-level and average false positives were calculated at patient-level. for the picture dataset, the calculation of average false positives was made using 93 patients who were biopsy-negative for cspca, due to limitations in the ground-truth prohibiting false-positive determination in biopsy positive patients. in addition, cspca lesion dice and abs%err of lesion area were calculated on slices containing a contour. prostate volume, psad, and lesion detection metrics computed for autoprostate were compared to the same metrics calculated for an experienced radiologist (s.p., 10 years’ experience in scoring prostate mpmri) who prospectively filled out a case report for each patient. prostate volume was estimated using the ellipsoid formula and lesions were scored using a five-point likert scale [ ]. statistical tests were used to compare the performances of autoprostate and the experienced radiologist. the wilcoxon’s signed-rank test [ ] was used to statistically compare precision, and wilcoxon’s signed-rank test was used to statistically compare average false positives.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_candidates[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70398639",
   "metadata": {},
   "source": [
    "# scrape urls - loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74149bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_doi = doi_list[1950:2000]\n",
    "#test_pmid = pmid_list[1950:2000]\n",
    "#test_url = url_list[1950:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b811d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditions\n",
    "\n",
    "def alphachars(x): return sum(a.isalpha() for a in x) > 4\n",
    "def charchar(x): return bool(re.match(r\".*[a-zA-Z][a-zA-Z].*\", x)) == True\n",
    "def istitle(x): return ((('method' in x) or ('material' in x) or ('result' in x) or ('discussion' in x) or ('conclusion' in x)\n",
    "                        or ('references' in x) or ('bibliography' in x)) \n",
    "                        and (sum(l.isalpha() for l in x) < 30))\n",
    "def istextblock(x): return sum(l.isalpha() for l in x) > 100\n",
    "def methodtitle(x): return ((('method' in x)) and (sum(l.isalpha() for l in x)<30)) #or ('material' in x)\n",
    "\n",
    "## symbol cleaning\n",
    "\n",
    "def lbracketcount(x): return x.count('{') < 4\n",
    "def rbracketcount(x): return x.count('}') < 4\n",
    "def tagcount(x): return x.count('\".\"') < 4\n",
    "def hashcount(x): return x.count('#') < 4\n",
    "def divcount(x): return x.count('</') < 4\n",
    "def linecount(x): return x.count('||') < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab985aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318aa3a54b8f4544a6847349fe2a086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\anaconda3\\envs\\scraper\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: session deleted because of page crash\nfrom tab crashed\n  (Session info: chrome=102.0.5005.63)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0073D953+2414931]\n\tOrdinal0 [0x006CF5E1+1963489]\n\tOrdinal0 [0x005BC580+836992]\n\tOrdinal0 [0x005AD517+775447]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005ACEBC+773820]\n\tOrdinal0 [0x005C2197+860567]\n\tOrdinal0 [0x00614B55+1198933]\n\tOrdinal0 [0x006042B6+1131190]\n\tOrdinal0 [0x005DE860+976992]\n\tOrdinal0 [0x005DF756+980822]\n\tGetHandleVerifier [0x009ACC62+2510274]\n\tGetHandleVerifier [0x0099F760+2455744]\n\tGetHandleVerifier [0x007CEABA+551962]\n\tGetHandleVerifier [0x007CD916+547446]\n\tOrdinal0 [0x006D5F3B+1990459]\n\tOrdinal0 [0x006DA898+2009240]\n\tOrdinal0 [0x006DA985+2009477]\n\tOrdinal0 [0x006E3AD1+2046673]\n\tBaseThreadInitThunk [0x75DEFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77407A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77407A4E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8924\\3471445015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m## set up chrome driver and get link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'C:\\chromedriver\\chromedriver.exe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m## get page source and xpath extract all body text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: session deleted because of page crash\nfrom tab crashed\n  (Session info: chrome=102.0.5005.63)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0073D953+2414931]\n\tOrdinal0 [0x006CF5E1+1963489]\n\tOrdinal0 [0x005BC580+836992]\n\tOrdinal0 [0x005AD517+775447]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005ACEBC+773820]\n\tOrdinal0 [0x005C2197+860567]\n\tOrdinal0 [0x00614B55+1198933]\n\tOrdinal0 [0x006042B6+1131190]\n\tOrdinal0 [0x005DE860+976992]\n\tOrdinal0 [0x005DF756+980822]\n\tGetHandleVerifier [0x009ACC62+2510274]\n\tGetHandleVerifier [0x0099F760+2455744]\n\tGetHandleVerifier [0x007CEABA+551962]\n\tGetHandleVerifier [0x007CD916+547446]\n\tOrdinal0 [0x006D5F3B+1990459]\n\tOrdinal0 [0x006DA898+2009240]\n\tOrdinal0 [0x006DA985+2009477]\n\tOrdinal0 [0x006E3AD1+2046673]\n\tBaseThreadInitThunk [0x75DEFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77407A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77407A4E+238]\n"
     ]
    }
   ],
   "source": [
    "methods_list = []\n",
    "\n",
    "for url in tqdm(url_list):\n",
    "    \n",
    "    ## refresh lists\n",
    "    keep_text = []\n",
    "    cull_text = []\n",
    "    method_candidates = []\n",
    "    \n",
    "    ## set up chrome driver and get link\n",
    "    driver = webdriver.Chrome(options=options, executable_path=r'C:\\chromedriver\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "\n",
    "    ## get page source and xpath extract all body text\n",
    "    page = driver.page_source\n",
    "    tree = html.fromstring(page)\n",
    "    body_text = tree.xpath('//body/descendant-or-self::*/text()')\n",
    "    \n",
    "    ## stop driver\n",
    "    driver.quit()\n",
    "    \n",
    "    ## cleaning and convert to lower case\n",
    "    body_text = [x.replace('\\n', ' ') for x in body_text]\n",
    "    body_text = [x.replace('    ', ' ') for x in body_text]\n",
    "    body_text = [x.replace('   ', ' ') for x in body_text]\n",
    "    body_text = [x.replace('  ', ' ') for x in body_text]\n",
    "    body_text = [x.lower() for x in body_text]\n",
    "    \n",
    "    ## keep list elements if conforms to conditions\n",
    "    for x in body_text:\n",
    "        if (charchar(x) and alphachars(x)) and (istitle(x) or istextblock(x)):\n",
    "            keep_text.append(x)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for x in keep_text:\n",
    "        if (lbracketcount(x) and rbracketcount(x) and tagcount(x) and hashcount(x) and divcount(x) and linecount(x)):\n",
    "            cull_text.append(x)\n",
    "        else:\n",
    "            continue\n",
    "                 \n",
    "    #########\n",
    "    #########\n",
    "    #########\n",
    "    \n",
    "    ## now pull out methods titles and text that follows, up to first occurance of 'results/discussion/conclusion title'\n",
    "    ## all candidates joined as strings, and held in method_candidates\n",
    "    \n",
    "    for i, x in enumerate(cull_text):    \n",
    "        method_following = [] #list of all elements following and including methods title\n",
    "        method_only = [] #list of all elements inbetween 'method' title and next section title\n",
    "\n",
    "        if methodtitle(x) == True:\n",
    "            method_following = cull_text[i:] \n",
    "            \n",
    "            for i, x in enumerate(method_following):\n",
    "                if 'result' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"result title!\")\n",
    "                    method_only = method_following[:i]\n",
    "                    break\n",
    "                elif 'discussion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"discussion title!\")\n",
    "                    method_only = method_following[:i]                \n",
    "                    break\n",
    "                elif 'conclusion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"conclusion title!\")\n",
    "                    method_only = method_following[:i]               \n",
    "                    break\n",
    "                elif 'references' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"reference title!\")\n",
    "                    method_only = method_following[:i]            \n",
    "                    break\n",
    "                elif 'bibliography' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"reference title!\")\n",
    "                    method_only = method_following[:i]                 \n",
    "                    break                      \n",
    "                else:\n",
    "                    method_only = method_following #if none of these are found to end text block, then take the whole text block\n",
    "    \n",
    "            method_string = ' '.join(method_only)        \n",
    "            method_candidates.append(method_string)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    methods_list.append(method_candidates) # each paper now has a list of method candidates (each is a string)\n",
    "\n",
    "print(len(methods_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8af1794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2440"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(methods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08454ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_doi_list = doi_list[0:2440]\n",
    "temp_pmid_list = pmid_list[0:2440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e92a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'doi':temp_doi_list, 'pmid':temp_pmid_list, 'methods_candidates':methods_list})\n",
    "\n",
    "results_df.to_csv('output/html_parse_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dbd73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df = pd.DataFrame(results_df['methods_candidates'].tolist())\n",
    "explode_df['pmid'] = temp_pmid_list\n",
    "explode_df.to_csv('output/html_explode_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872a12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbe8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165daaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8be365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005668d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
