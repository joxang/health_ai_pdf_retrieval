{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import wget\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa6c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from random import randint\n",
    "from random import sample\n",
    "from time import sleep\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14282182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173ed37",
   "metadata": {},
   "source": [
    "# extract doi list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f084113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_abstracts = pd.read_csv('data/included_abstracts.csv', index_col = 0)\n",
    "#len(all_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2279407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_abstracts['article_date'] = pd.to_datetime(all_abstracts['article_date'])\n",
    "#decade_df = all_abstracts[(all_abstracts['article_date'] > '2012-01-01') & (all_abstracts['article_date'] <'2022-01-01')]\n",
    "#len(decade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ec0f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decade_df.sort_values(by='article_date',  ascending=False, inplace=True)\n",
    "#decade_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f92df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_1 = pd.read_csv('output/failed_link_retrieval.csv', index_col = 0)\n",
    "#retrieval_2 = pd.read_csv('output/no_links_for_open_access.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643a6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra_df = pd.concat([retrieval_1, retrieval_2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b2090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape_df = extra_df[['pmid', 'doi']].copy()\n",
    "scrape_df = retrieval_1[['pmid', 'doi']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf007002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3437 entries, 3 to 28677\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   pmid    3437 non-null   int64 \n",
      " 1   doi     3437 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 80.6+ KB\n"
     ]
    }
   ],
   "source": [
    "doi_df = scrape_df[~scrape_df['doi'].isnull()]\n",
    "doi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e11db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = dict(zip(doi_df['pmid'], doi_df['doi']))\n",
    "pmid_list = doi_df['pmid'].tolist()\n",
    "doi_list = doi_df['doi'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a9d5c",
   "metadata": {},
   "source": [
    "# create urls for dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7e9e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = []\n",
    "\n",
    "for doi in doi_list:\n",
    "    link = \"https://doi.org/{}\".format(doi)\n",
    "    url_list.append(link)\n",
    "\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf48140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for manual download!\n",
    "#url_df = pd.DataFrame(url_list, columns=['url'])\n",
    "#url_df.to_csv('output/manual_url_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547d221",
   "metadata": {},
   "source": [
    "# scrape urls - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f8a64a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\anaconda3\\envs\\scraper\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options, executable_path=r'C:\\chromedriver\\chromedriver.exe')\n",
    "\n",
    "driver.get(random.choice(url_list))\n",
    "\n",
    "page = driver.page_source\n",
    "\n",
    "tree = html.fromstring(page)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7da70210",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_text = tree.xpath('//body/descendant-or-self::*/text()')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "73d7df6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Your Privacy',\n",
       " '\\n\\t\\t\\t',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    We use cookies to make sure that our website works properly, as well as some ‘optional’ cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on ‘Manage Settings’, where you can also find more information about how your personal data is processed. \\n                    Further information can be found in our ',\n",
       " 'privacy policy',\n",
       " '.\\n\\t\\t\\t\\t',\n",
       " '\\n            ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Accept all ',\n",
       " 'cookies',\n",
       " '\\n                \\n                ',\n",
       " 'Manage preferences',\n",
       " '\\n            ',\n",
       " '\\n\\t\\t',\n",
       " '\\n    ',\n",
       " '\\n\\n',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n    ',\n",
       " 'Skip to main content',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n    ',\n",
       " '\\n        \\n        ',\n",
       " 'Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\\n            and JavaScript.',\n",
       " '\\n\\n    ',\n",
       " '\\n',\n",
       " '\\n\\n    \\n\\n    ',\n",
       " '\\n            \\n    \\n        ',\n",
       " '\\n\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " 'Advertisement',\n",
       " '\\n                    \\n        \\n            \\n    ',\n",
       " '\\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n        ',\n",
       " '\\n    ',\n",
       " '\\n\\n        \\n    \\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    ',\n",
       " '\\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    \\n                    \\n                    ',\n",
       " '\\n                        \\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                    \\n                    ',\n",
       " '\\n                    \\n                    ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                                ',\n",
       " 'View all journals',\n",
       " '\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                                ',\n",
       " 'Search',\n",
       " '\\n                            ',\n",
       " '\\n    ',\n",
       " '\\n        ',\n",
       " 'Search',\n",
       " '\\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " 'Search articles by subject, keyword or author',\n",
       " '\\n                    ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n\\n                        ',\n",
       " '\\n                            ',\n",
       " 'Show results from',\n",
       " '\\n                            ',\n",
       " '\\n                                \\n                                    \\n                                        ',\n",
       " 'All journals',\n",
       " '\\n                                        ',\n",
       " 'This journal',\n",
       " '\\n                                    \\n                                \\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " 'Search',\n",
       " '\\n                        ',\n",
       " '\\n                    ',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n\\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    Advanced search\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n        ',\n",
       " 'Quick links',\n",
       " '\\n        ',\n",
       " '\\n            ',\n",
       " 'Explore articles by subject',\n",
       " '\\n            ',\n",
       " 'Find a job',\n",
       " '\\n            ',\n",
       " 'Guide to authors',\n",
       " '\\n            ',\n",
       " 'Editorial policies',\n",
       " '\\n        ',\n",
       " '\\n    ',\n",
       " '\\n',\n",
       " '\\n                        ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n    ',\n",
       " 'My Account',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n    ',\n",
       " 'Login',\n",
       " '\\n',\n",
       " '\\n\\n                        ',\n",
       " '\\n                    ',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n        \\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " '\\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                                \\n                                    ',\n",
       " '\\n                                        ',\n",
       " '\\n                                            ',\n",
       " 'Explore',\n",
       " ' content',\n",
       " '\\n                                        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Explore content',\n",
       " '\\n                ',\n",
       " '\\n                    \\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Research articles\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Reviews & Analysis\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    News & Comment\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Videos\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Current issue\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Collections\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                    \\n                    \\n                    \\n                        ',\n",
       " '\\n                            ',\n",
       " 'Follow us on Twitter\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                    \\n                    \\n                    \\n                        ',\n",
       " '\\n                            ',\n",
       " 'Sign up for alerts',\n",
       " '\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                    \\n                    \\n                        ',\n",
       " '\\n                            ',\n",
       " '\\n                                ',\n",
       " 'RSS feed',\n",
       " '\\n                            ',\n",
       " '\\n                        ',\n",
       " '\\n                    \\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n                                    ',\n",
       " '\\n                                \\n                                \\n                                    ',\n",
       " '\\n                                        ',\n",
       " '\\n                                            ',\n",
       " 'About ',\n",
       " 'the journal',\n",
       " '\\n                                        ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " 'About the journal',\n",
       " '\\n                    ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Aims & Scope\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Journal Information\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Journal Metrics\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    About the Editors\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Meet our Chief Editor\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Our publishing models\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Editorial Values Statement\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Editorial Policies\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Content Types\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Web Feeds\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Contact\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                    ',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n                                    ',\n",
       " '\\n                                    \\n                                        ',\n",
       " '\\n                                            ',\n",
       " '\\n                                                ',\n",
       " 'Publish ',\n",
       " 'with us',\n",
       " '\\n                                            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " 'Publish with us',\n",
       " '\\n                    ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    Submission Guidelines\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " '\\n                                    For Reviewers\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                        \\n                            ',\n",
       " '\\n                                ',\n",
       " 'Submit manuscript',\n",
       " '\\n                                ',\n",
       " '\\n                            ',\n",
       " '\\n                        \\n                    ',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n                                        ',\n",
       " '\\n                                    \\n                                \\n                            ',\n",
       " '\\n\\n                            \\n                        ',\n",
       " '\\n\\n                        ',\n",
       " '\\n                            \\n                                ',\n",
       " '\\n                                    ',\n",
       " '\\n                                        ',\n",
       " 'Sign up for alerts',\n",
       " '\\n                                    ',\n",
       " '\\n                                ',\n",
       " '\\n                            \\n                            \\n                                ',\n",
       " '\\n                                    ',\n",
       " '\\n                                        ',\n",
       " 'RSS feed',\n",
       " '\\n                                    ',\n",
       " '\\n                                ',\n",
       " '\\n                            \\n                        ',\n",
       " '\\n                    ',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        \\n    ',\n",
       " '\\n\\n\\n    \\n    \\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " 'nature',\n",
       " '\\n                                    ',\n",
       " '\\n                                        ',\n",
       " '\\n                                    ',\n",
       " '\\n                                ',\n",
       " 'nature metabolism',\n",
       " '\\n                                    ',\n",
       " '\\n                                        ',\n",
       " '\\n                                    ',\n",
       " '\\n                                ',\n",
       " 'articles',\n",
       " '\\n                                    ',\n",
       " '\\n                                        ',\n",
       " '\\n                                    ',\n",
       " '\\n                                ',\n",
       " '\\n                                    ',\n",
       " 'article',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    \\n\\n\\n\\n    \\n\\n',\n",
       " '\\n\\n\\n',\n",
       " '\\n    ',\n",
       " '\\n        \\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " '\\n                        Three-dimensional facial-image analysis to predict heterogeneity of the human ageing rate and the impact of lifestyle\\n                    ',\n",
       " '\\n                    \\n    \\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Download PDF',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    \\n\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        \\n        ',\n",
       " '\\n            \\n            ',\n",
       " '\\n                ',\n",
       " '\\n                    ',\n",
       " '\\n                        \\n    \\n        ',\n",
       " 'Article',\n",
       " '\\n    \\n    \\n    \\n\\n                        ',\n",
       " 'Published: ',\n",
       " '07 September 2020',\n",
       " '\\n                    ',\n",
       " '\\n\\n                    ',\n",
       " 'Three-dimensional facial-image analysis to predict heterogeneity of the human ageing rate and the impact of lifestyle',\n",
       " '\\n                    ',\n",
       " 'Xian Xia',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0002-7772-0618',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " '\\xa0',\n",
       " 'na1',\n",
       " ', ',\n",
       " 'Xingwei Chen',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " '\\xa0',\n",
       " 'na1',\n",
       " ', ',\n",
       " 'Gang Wu',\n",
       " '1',\n",
       " ', ',\n",
       " 'Fang Li',\n",
       " '1',\n",
       " ', ',\n",
       " 'Yiyang Wang',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Yang Chen',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Mingxu Chen',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Xinyu Wang',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '4',\n",
       " ', ',\n",
       " 'Weiyang Chen',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0001-8430-7381',\n",
       " '1',\n",
       " ', ',\n",
       " 'Bo Xian',\n",
       " '1',\n",
       " ', ',\n",
       " 'Weizhong Chen',\n",
       " '1',\n",
       " ', ',\n",
       " 'Yaqiang Cao',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0002-4665-1517',\n",
       " '1',\n",
       " ', ',\n",
       " 'Chi Xu',\n",
       " '1',\n",
       " ', ',\n",
       " 'Wenxuan Gong',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Guoyu Chen',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Donghong Cai',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Wenxin Wei',\n",
       " '5',\n",
       " ', ',\n",
       " 'Yizhen Yan',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0001-7508-9861',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " ',',\n",
       " '3',\n",
       " ', ',\n",
       " 'Kangping Liu',\n",
       " '2',\n",
       " ', ',\n",
       " 'Nan Qiao',\n",
       " '6',\n",
       " ', ',\n",
       " 'Xiaohui Zhao',\n",
       " '6',\n",
       " ', ',\n",
       " 'Jin Jia',\n",
       " '6',\n",
       " ', ',\n",
       " 'Wei Wang',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0002-1430-1360',\n",
       " '7',\n",
       " ', ',\n",
       " 'Brian K. Kennedy',\n",
       " '8',\n",
       " ',',\n",
       " '9',\n",
       " ',',\n",
       " '10',\n",
       " ',',\n",
       " '11',\n",
       " ', ',\n",
       " 'Kang Zhang',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0002-4549-1697',\n",
       " '12',\n",
       " ', ',\n",
       " 'Carlo V. Cannistraci',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0003-0100-8410',\n",
       " '13',\n",
       " ',',\n",
       " '14',\n",
       " ', ',\n",
       " '…',\n",
       " 'Yong Zhou',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0001-5221-8026',\n",
       " '15',\n",
       " ' & ',\n",
       " 'Jing-Dong J. Han',\n",
       " '\\xa0\\n            ',\n",
       " 'ORCID: ',\n",
       " 'orcid.org/0000-0002-9270-7139',\n",
       " '1',\n",
       " ',',\n",
       " '2',\n",
       " '\\xa0',\n",
       " 'Show authors',\n",
       " '\\n\\n                    \\n\\n                    ',\n",
       " '\\n                        \\n    ',\n",
       " 'Nature Metabolism',\n",
       " '\\n\\n                        ',\n",
       " 'volume',\n",
       " '\\xa02',\n",
       " ',\\xa0',\n",
       " 'pages ',\n",
       " '946–957 (',\n",
       " '2020',\n",
       " ')',\n",
       " 'Cite this article',\n",
       " '\\n                    ',\n",
       " '\\n                    \\n    ',\n",
       " '\\n        ',\n",
       " '\\n            \\n                ',\n",
       " '\\n                    ',\n",
       " '1924 ',\n",
       " 'Accesses',\n",
       " '\\n                ',\n",
       " '\\n            \\n            \\n                ',\n",
       " '\\n                    ',\n",
       " '11 ',\n",
       " 'Citations',\n",
       " '\\n                ',\n",
       " '\\n            \\n            \\n                \\n                    ',\n",
       " '\\n                        ',\n",
       " '48 ',\n",
       " 'Altmetric',\n",
       " '\\n                    ',\n",
       " '\\n                \\n            \\n            ',\n",
       " '\\n                ',\n",
       " 'Metrics ',\n",
       " 'details',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    ',\n",
       " '\\n\\n                    \\n                ',\n",
       " '\\n\\n                \\n    \\n\\n                \\n    \\n\\n    \\n\\n                \\n            ',\n",
       " '\\n\\n        ',\n",
       " '\\n            ',\n",
       " 'Abstract',\n",
       " 'Not all individuals age at the same rate. Methods such as the ‘methylation clock’ are invasive, rely on expensive assays of tissue samples and infer the ageing rate by training on chronological age, which is used as a reference for prediction errors. Here, we develop models based on convoluted neural networks through training on non-invasive three-dimensional (3D) facial images of approximately 5,000 Han Chinese individuals that achieve an average difference between chronological or perceived age and predicted age of ±2.8 and 2.9 yr, respectively. We further profile blood transcriptomes from 280 individuals and infer the molecular regulators mediating the impact of lifestyle on the facial-ageing rate through a causal-inference model. These relationships have been deposited and visualized in the Human Blood Gene Expression—3D Facial Image (HuB-Fi) database. Overall, we find that humans age at different rates both in the blood and in the face, but do so coherently and with heterogeneity peaking at middle age. Our study provides an example of how artificial intelligence can be leveraged to determine the perceived age of humans as a marker of biological age, while no longer relying on prediction errors of chronological age, and to estimate the heterogeneity of ageing rates within a population.',\n",
       " '\\n            ',\n",
       " '\\n                \\n                    \\n',\n",
       " '\\n    \\n        ',\n",
       " 'You have full access to this article via your institution.',\n",
       " '\\n        \\n    \\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Download PDF',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    \\n\\n    \\n',\n",
       " '\\n\\n                \\n            ',\n",
       " '\\n\\n                \\n                    ',\n",
       " '\\n                        \\n                            ',\n",
       " '\\n\\n    \\n        ',\n",
       " 'You have full access to this article via ',\n",
       " 'Imperial College London e-Access, Licencing and Subscriptions',\n",
       " '\\n        \\n        \\n            \\n    \\n        ',\n",
       " '\\n            ',\n",
       " '\\n                ',\n",
       " 'Download PDF',\n",
       " '\\n                ',\n",
       " '\\n            ',\n",
       " '\\n        ',\n",
       " '\\n    \\n\\n        \\n    \\n',\n",
       " '\\n\\n                        \\n                    ',\n",
       " '\\n                \\n            \\n                ',\n",
       " 'Main',\n",
       " 'Ageing is a major risk factor for many complex human diseases. Rates of biological ageing are highly variable among individuals of the same chronological age. To quantify ageing, ideally, biological age rather than chronological age should be assessed; however, because of the lack of a gold standard for biological age, the population average of chronological age is often assumed to be the standard of biological age. The deviators or outliers of the average or standard curve are defined and often substantiated as fast or slow agers by other physiological or molecular parameters. On the basis of this assumption, many methods have been developed to quantify ageing. For example, predicting age using the transcriptome in human peripheral blood has a mean absolute difference (MAD) between chronological age and predicted biological age of 7.8 yr (ref. ',\n",
       " '1',\n",
       " '), using the proteome has a Pearson correlation coefficient (PCC) of 0.93–0.97 (ref. ',\n",
       " '2',\n",
       " ') and using the DNA methylome has a MAD of 4.9 yr in whole blood from 656 human cohorts',\n",
       " '3',\n",
       " ' and 3.6 yr in heterogeneous tissues',\n",
       " '4',\n",
       " '. However, because the transcriptome, DNA methylome and proteome have to be measured in blood cells or other tissues, invasiveness and high costs preclude their application to large-scale screens and routine physical examinations.',\n",
       " 'Facial images have been used in traditional Chinese medicine as a major diagnosis tool for evaluating health and disease status. This practice originated more than 2,000 years ago',\n",
       " '5',\n",
       " ', and is increasingly being used by Western-medicine clinicians to diagnose developmental syndromes',\n",
       " '6',\n",
       " '. Our previous work has established 3D human facial image as an ageing marker, generated a partial least squares regression (PLSR) model and used the difference between chronological and predicted age (AgeDiff) to identify outliers in the ageing rate',\n",
       " '7',\n",
       " '.',\n",
       " 'Many biological pathways are known to be associated with ageing or age',\n",
       " '8',\n",
       " ', but no biological process has been directly linked to differential ageing rates (or AgeDiff) across individuals. Indeed, the ageing rate might be associated with a subset of ageing-related changes that are more modifiable by environment, diet, lifestyle or variations in genetic background across different individuals than the genetically hardcoded programme that is fatefully played out for a species. Thus, an understanding of the molecular events contributing to AgeDiff is actionable and pertinent to understanding healthy ageing.',\n",
       " 'Recently, deep CNNs have been successfully used in the classification of Alzheimer’s disease',\n",
       " '9',\n",
       " ' and skin cancer',\n",
       " '10',\n",
       " '. Benefiting from these highly efficient CNN architectures, we trained three classic CNNs (Inception, Visual Geometry Group (VGG) and ResNet) using the large datasets in ImageNet. We then applied them to 3D facial images from a large cohort of 4,719 individuals so they could learn age by transfer learning. In combining the results from the 3 CNNs, the accuracy of age and perceived-age prediction reached a MAD of 2.79 and 2.90 yr, respectively. This allowed us to examine ageing-rate heterogeneity across individuals during ageing, which was otherwise missed by our previous linear PLSR model. Our CNN for perceived-age prediction is designed to learn a representation of biological age instead of chronological age, which is supported by its detection of much-stronger associations of lifestyle and health parameters with ageing than those found by a chronological-age predictor. We used a statistical test',\n",
       " '11',\n",
       " ', coupled with peripheral blood mononuclear cell (PBMC) transcriptome analysis, and built a causal-inference network that reveals circulation factors mediating lifestyle impacts on facial morphologies from blood transcriptomes. We deposited and visualized the associations and inferred causal relationships in the HuB-Fi (',\n",
       " 'http://www.picb.ac.cn/hanlab/hub-fi/',\n",
       " ') database for researchers and the public to explore.',\n",
       " 'Results',\n",
       " 'Deep CNN predicts accurate age and perceived age',\n",
       " 'To construct a highly accurate age-estimating model from 3D facial images, we collected 4,719 facial images from Han Chinese individuals in North China (Jidong) with the 3dMDface System, together with corresponding age, sex, physical-examination and questionnaire information (Supplementary Table ',\n",
       " '1',\n",
       " ' in the ',\n",
       " 'Supplementary Information',\n",
       " '). We developed a fully automated pipeline for analysis of 3D facial images, including pose correction, landmark identification and projection of depth and red, green and blue (RGB) colour of a 3D image onto two-dimensional (2D) images with four channels, for face registration and deep learning. We then used these 2D images to train the CNN model to predict chronological age (FaceCnnAge) (Fig. ',\n",
       " '1a',\n",
       " ', Extended Data Fig. ',\n",
       " '1a',\n",
       " ' and ',\n",
       " 'Methods',\n",
       " '). The predictor achieved a MAD of 2.79 yr by 10-fold cross-validation (',\n",
       " 'Methods',\n",
       " ' and Fig. ',\n",
       " '1b',\n",
       " ', left), compared with 4.47 yr using a PLS model (FacePlsAge) (Fig. ',\n",
       " '1b',\n",
       " ' and Extended Data Fig. ',\n",
       " '1b',\n",
       " '). Because a CNN trained on chronological age by optimizing prediction accuracy for chronological age might not be optimized to detect biological age, we trained another CNN model to predict perceived age, which might better reflect the health state',\n",
       " '12',\n",
       " ', termed FaceCnnPerceivedAge. This model also achieved a high accuracy, with a MAD of 2.90 yr for perceived age and 4.10 yr for chronological age (Fig. ',\n",
       " '1b',\n",
       " '). We then examined the consistency of AgeDiffs or outliers (|AgeDiff| > MAD) given by different models and found that they are highly correlated (Supplementary Table ',\n",
       " '2',\n",
       " ') or significantly overlapped (',\n",
       " 'P',\n",
       " ' < 0.05), especially between the two CNN models (Extended Data Fig. ',\n",
       " '1b',\n",
       " ').',\n",
       " 'Fig. 1: Accuracy of age predictors, and the health parameters and lifestyles associated with AgeDiffs.',\n",
       " 'a',\n",
       " ', The large amount of imaging data we collected and the fully automated pipeline for analysis of 3D facial images (landmark identification and face registration) we developed here enabled us to train CNNs to predict chronological and perceived age in a cohort of 4,719 individuals (Jidong) by cross-validation and by validation in two independent cohorts of ~300 individuals each (Beijing 2012 and Beijing 2015). The ImageNet pretrained weights of Inception (Inception_v1), VGG (VGG_16) and ResNet (ResNet_50) were transferred to learn age or perceived age. Average faces of the cohort are used for illustration. Ageing rate, as defined by predicted versus chronological age (AgeDiff), was examined for associations with health and lifestyle in the Jidong cohort. Ribo-minus RNA-seq of blood PBMCs was generated for the Beijing 2012 cohort, and was used to infer the molecular mediators of lifestyle impact on ageing-rate variations. ',\n",
       " 'b',\n",
       " ', Correlation of predicted age from four approaches with chronological age. ',\n",
       " 'c',\n",
       " ', Association-strength network of 4 AgeDiffs and health parameters, corrected for chronological age, filtered by FDR\\u2009<\\u20090.1. BMD, bone mineral density; DBP, diastolic blood pressure; SBP, systolic blood pressure; BMI, body mass index; NECCIR, neck circumference; ABDCIR, abdominal circumference; WSTCIR, waist circumference; HIPCIR, hip circumference; CR, creatinine; AKP, alkaline phosphatase; ALT, alanine aminotransfersase; AST, aspartate transaminase; TC, total cholesterol; APOA, apolipoprotein A; APOB, apolipoprotein B; GT, transglutaminase; FBG, fasting blood glucose; LDL, low-density lipoprotein; TG, triglycerides. ',\n",
       " 'd',\n",
       " ', Association network between lifestyle and AgeDiffs in the Jidong cohort. Edges are filtered by FDR\\u2009<\\u20090.1. Smoking, smoker or non-smoker; CigNumber, average number of cigarettes per day; CigPasYear, number of years of passive smoking; SnoreFreq, frequency of snoring per week; SnoreSound, whether the sound of a snore is louder than speaking voice; SnoreApnoea: whether snoring is coupled with apnoea; Alchohol, average intake of alcohol per day; Salt, average intake of salt per day; DyeHair, whether have hair dyed in the last three months; Fruit, frequency of consuming fruits; Vegetable, frequency of consuming vegetables; Dair, frequency of consuming dairy products; ExHighMin, average length of vigorous exercise per day.',\n",
       " 'Full size image',\n",
       " 'To validate the CNN models in independent cohorts, we predicted the ages of people in 332 images from the 2012 Beijing cohort (Supplementary Table ',\n",
       " '3',\n",
       " '; these images have only half the resolution of those in the other cohorts) and in 358 images from the 2015 Beijing cohort (Supplementary Table ',\n",
       " '4',\n",
       " ') with the CNN models that learnt from the large Jidong cohort. We achieved a MAD of 3.85 yr for data collected in 2012 and of 3.92 yr for data collected in 2015 for FaceCnnAge, and a MAD of 6.66 yr for 2012 and of 4.12 yr for 2015 for FaceCnnPerceivedAge (Extended Data Fig. ',\n",
       " '1c',\n",
       " '). As a comparison, the PLS model achieved MAD\\u2009=\\u20096.15 and 4.81 yr for the 2012 and 2015 Beijing cohorts, respectively. These results suggest that the CNN models achieve superior accuracy not only over all other linear models by cross-validation in the same cohort but also in at least two other independent cohorts. It should be noted that, due to the small sample sizes of the Beijing cohorts, we could not do the opposite, that is train the CNN models on the Beijing cohorts and validate them on the Jidong cohort.',\n",
       " 'Health and lifestyle parameters associated with AgeDiffs',\n",
       " 'To examine the biological relevance of AgeDiffs, we next examined the association of AgeDiffs with health parameters corrected for age (false-discovery rate (FDR)\\u2009<\\u20090.1) in the Jidong cohort. Indices related to obesity, blood pressure, transglutaminase, alkaline phosphatase and cholesterol were among the factors that were most strongly associated with all AgeDiffs, whereas bone mineral density and creatinine were significantly negatively associated with three out of four AgeDiffs. Interestingly, among all four AgeDiffs, FaceCnnPerceivedAgeDiff associated with remarkably more health parameters than other AgeDiffs did (Fig. ',\n",
       " '1c',\n",
       " '), indicating that it could be a superior predictor of health, even when compared with the model’s training data—human-perceived age.',\n",
       " 'To uncover the associations of lifestyles factors with differential ageing rates, we determined the association between quantitative lifestyle parameters with AgeDiffs in the Jidong cohort. Smoking, number of cigarettes and years of passive smoking were linked to all four AgeDiffs as the factors that most strongly increased the ageing rate. Frequency of snoring, sound of snoring and apnoea during snoring were linked to all but FacePlsAgeDiff. Among factors that decreased the ageing rate, dairy intake was linked to all four AgeDiffs. The associations identified by FaceCnnPerceivedAgeDiff essentially captured all those found by FaceCnnAgeDiff or by FacePerceivedAgeDiff, but captured a greater number of associations (Fig. ',\n",
       " '1d',\n",
       " '). This suggests that both are optimized to accurately detect the ageing rate, with FaceCnnPerceivedAgeDiff being a better estimate of the biological ageing rate than all other age predictors are, including perceived age itself. Similar associations can be observed in the smaller Beijing 2012 cohort (Extended Data Fig. ',\n",
       " '2',\n",
       " ').',\n",
       " 'AgeDiff heterogeneity peaks at middle age',\n",
       " 'In contrast to the s.d. expected from randomly guessing a number between 20–85, which is highest at young and old age (Extended Data Fig. ',\n",
       " '3a',\n",
       " '), the heterogeneity of the ageing rate precisely captured by FaceCnnAgeDiff and FaceCnnPerceivedAgeDiff peaked at middle age (Fig. ',\n",
       " '2a',\n",
       " '). FacePerceivedAgeDiff also peaked at middle age, although it plateaued afterwards in males. FacePlsAgeDiff, however, is very different in that it shows a monotonic increase in s.d. with increasing chronological age and an s.d. that appears random at old age. These patterns are insensitive to the bin size (moving window) (',\n",
       " 'Methods',\n",
       " ' and Extended Data Fig. ',\n",
       " '3b',\n",
       " '). Similar patterns can be observed in the smaller Beijing cohort. Using broken-stick regression to pinpoint the breakpoint in the regression line, we found that all four AgeDiffs predominately show a breakpoint peaking at middle age (Extended Data Fig. ',\n",
       " '4a,b',\n",
       " ').',\n",
       " 'Fig. 2: AgeDiff heterogeneity peaks at middle age.',\n",
       " 'a',\n",
       " ', Relationship between age and the s.d. of 4 AgeDiffs with a bin size of 100. Data are presented as mean ± s.d. ',\n",
       " 'b',\n",
       " ', Heatmap of facial features in the Jidong cohort sorted by increasing chronological age (PCC with age, FDR\\u2009<\\u20090.1 and |PCC| > 0.1 in females and in males). Features are ranked by PCC from lowest to highest in females and in males. ',\n",
       " 'c',\n",
       " ', A heatmap of health parameters in the Jidong cohort sorted by increasing chronological age (PCC with age, FDR\\u2009<\\u20090.1 and |PCC| > 0.1). Features are ordered as in ',\n",
       " 'b',\n",
       " '. UR, uric acid; see Fig. ',\n",
       " '1c',\n",
       " ' for all other abbreviations.',\n",
       " 'Full size image',\n",
       " 'Previous findings show that for human brain ageing transcriptomes, unlike those of very young or very old individuals, middle-aged individuals display high heterogeneity',\n",
       " '13',\n",
       " '. We observed a similar pattern when all samples were visualized by a heatmap of age-related quantitative facial features (Fig. ',\n",
       " '2b',\n",
       " ') and age-related health parameters (Fig. ',\n",
       " '2c',\n",
       " ') in the Jidong cohort and also in the Beijing 2012 cohort (Extended Data Fig. ',\n",
       " '3c',\n",
       " ').',\n",
       " 'Transcriptomic age is consistent with facial age',\n",
       " 'Using the cohort that we collected from the Beijing area (Beijing 2012), we extracted and sequenced the ribo-minus RNA from PBMCs of 280 individuals with matching 3D facial images (Supplementary Table ',\n",
       " '5',\n",
       " '). We performed PLSR analysis on transcriptomes to predict chronological age in the same way that we did for 3D facial images',\n",
       " '7',\n",
       " '. The MAD of the predicted age (RnaPlsAge) by all transcribed genes and the chronological age was 5.68 yr (Extended Data Fig. ',\n",
       " '5a–d',\n",
       " '). Like the s.d. of AgeDiff detected by CNN in both the large and the small cohort, RnaPlsAgeDiff in this small cohort peaked at middle age (around 40–50 yr old) (Extended Data Fig. ',\n",
       " '3d,e',\n",
       " '). Similarly, with broken-stick regression, we found that all four AgeDiffs predominately showed a breakpoint peaking at middle age in the Beijing 2012 cohort (Extended Data Fig. ',\n",
       " '4c,d',\n",
       " ').',\n",
       " 'We also applied the FaceCnnAge and FaceCnnPerceivedAge CNN models that learnt from the large Jidong cohort to the 280 samples and compared them with PLSR-derived models FacePlsAge (trained on the 280 3D facial images) and RnaPlsAge. Despite being derived from different machine-learning algorithms, different training sets and different data types, the AgeDiffs predicted by various models significantly correlated with each other, with higher correlation of RNA with CNN-based models than with the facial PLS model (Supplementary Table ',\n",
       " '6',\n",
       " '), especially among outliers (Supplementary Table ',\n",
       " '7',\n",
       " '). Moreover, the outliers identified by RnaPlsAge significantly overlapped with the two CNN-based models in both fast and slow agers (',\n",
       " 'P <',\n",
       " ' 0.05, Extended Data Fig. ',\n",
       " '5e',\n",
       " '). This confirms that the outliers detected by analysis of the transcriptomes of PBMCs are reflected in 3D facial features.',\n",
       " 'Inflammation is related to AgeDiff at the transcriptome level',\n",
       " 'To identify the blood transcriptome differences associated with differential facial-ageing rates, we compared the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways with gene expression that was correlated with at least two of the four estimated AgeDiffs or with age (Fig. ',\n",
       " '3a',\n",
       " '). Among pathways positively correlated with AgeDiffs (FDR\\u2009<\\u20090.1), most were also positively correlated with age and inflammation, such as those linked to ',\n",
       " 'Escherichia coli',\n",
       " ', salmonella infection and shigellosis. And, similarly to age, AgeDiffs tended to be consistently negatively correlated with biogenesis of ribosome and transfer RNA. Although all four AgeDiffs were uncorrelated with chronological age after age correction, the molecular pathways that correlated with age and the four AgeDiffs were largely consistent, indicating that the acceleration or deceleration of ageing detected by AgeDiffs measurements is largely consistent with the ageing process at the pathway level.',\n",
       " 'Fig. 3: Inflammation is related to AgeDiff at the molecular and cellular level.',\n",
       " 'a',\n",
       " ', KEGG pathway enrichment scores for chronological age and AgeDiffs. Asterisks denote FDR\\u2009<\\u20090.1. ',\n",
       " 'b',\n",
       " ', Distribution of FacePlsAgeDiff (left) or RnaPlsAgeDiff (middle) between the top and bottom 20% of samples on monocyte number derived from haematology analyser (two-sided ',\n",
       " 't',\n",
       " '-test), and the projections on a 3D facial image (right; color scale in arbitrary units). ',\n",
       " 'c',\n",
       " ', Distribution of FacePlsAgeDiff (left) or RnaPlsAgeDiff (middle) between the top and bottom 20% of samples on deconvoluted naive CD4',\n",
       " '+',\n",
       " ' T cells (two-sided ',\n",
       " 't-',\n",
       " 'test), and the projection on 3D facial image (right). ',\n",
       " 'd',\n",
       " ', Distribution of FaceCnnAgeDiff (left) or FaceCnnPerceivedAgeDiff (middle) between the top and bottom 10% of samples on MCV (two-sided ',\n",
       " 't',\n",
       " '-test), and the projection on a 3D facial image (right).',\n",
       " 'Full size image',\n",
       " 'We then sought to further verify the AgeDiff–inflammation association by examining whether inflammatory gene sets are positively related to AgeDiffs. Cytokine expression was positively related to FacePlsAgeDiff, RnaPlsAgeDiff and FaceCnnAgeDiff (Kolmogorov–Smirnov (KS) test, nominal ',\n",
       " 'P',\n",
       " '\\u2009<\\u20090.05), but not FaceCnnPerceivedAgeDiff. Innate-immunity-related genes, such as those linked to antigen processing and presentation, were positively related to all four AgeDiffs (KS test, Extended Data Fig. ',\n",
       " '6a',\n",
       " '). In summary, all four AgeDiffs were significantly positively related to inflammation and innate-immunity processes, which are also important features of ageing per se.',\n",
       " 'Inflammation is related to AgeDiff at the cell-type level',\n",
       " 'We also considered whether cell fractions are differentially associated with AgeDiffs. Using CIBERSORT',\n",
       " '14',\n",
       " ', we found that the monocyte fraction was significantly positively associated with FacePlsAgeDiff, and the direction was consistent, although not significant, with its association with the other three AgeDiffs across all individuals (Extended Data Fig. ',\n",
       " '6b',\n",
       " '). Consistently, monocyte count was even more significantly associated with FacePlsAgeDiff (',\n",
       " 't',\n",
       " '-test, ',\n",
       " 'P',\n",
       " '\\u2009=\\u20090.00056 between the top and bottom 20% of samples, Fig. ',\n",
       " '3b',\n",
       " '). The PLSR components 1 and 2 of 3D facial images regressed to monocyte fractions most significantly mapped to shrinkage of the forehead (Fig. ',\n",
       " '3b',\n",
       " '), which is in agreement with the negative association between inflammatory biomarkers, including interleukin-6, osteoprotegerin and tumour necrosis factor-α, and brain volume as measured by magnetic resonance imaging',\n",
       " '15',\n",
       " '.',\n",
       " 'In contrast, naive CD4',\n",
       " '+',\n",
       " ' T cells were consistently negatively associated with all four AgeDiffs, although the association was significant for only FacePlsAgeDiff and for RnaPlsAgeDiff (Fig. ',\n",
       " '3c',\n",
       " ' and Extended Data Fig. ',\n",
       " '6b',\n",
       " '). The PLSR components 1 and 2 of 3D facial changes to this cell fraction showed mapping to a reduction of under-eye puffiness (Fig. ',\n",
       " '3c',\n",
       " ', ',\n",
       " 'z',\n",
       " ' axis).',\n",
       " 'In addition, both CNN-derived AgeDiffs were significantly associated with the mean corpuscular volume of erythrocytes (MCV), a known chronic-illness indicator that is positively associated with ageing',\n",
       " '16',\n",
       " ', nutrition',\n",
       " '17',\n",
       " ' and alcohol abuse',\n",
       " '18',\n",
       " ', between more-extreme samples (compared between the top and bottom 10% of samples; the association was marginal if the comparison was between the top and bottom 20% of samples). The facial pattern was similar to that associated with the monocyte fraction (Fig. ',\n",
       " '3d',\n",
       " ').',\n",
       " 'The impacts of lifestyle on AgeDiff and the mediating transcriptome regulators',\n",
       " 'Our parallel measurement of lifestyles, blood cell transcriptome and AgeDiffs for the same individuals in the Beijing 2012 cohort offered an opportunity to examine the molecular mediators of the impact of lifestyle on facial AgeDiff. We thus generated a tripartite network of lifestyle–transcriptome–AgeDiff using a causal-inference framework',\n",
       " '11',\n",
       " ',',\n",
       " '19',\n",
       " ' querying all transcriptome clusters, ENCODE transcription factors, signalling and epigenetic factors and cytokines as potential mediators (',\n",
       " 'P',\n",
       " '\\u2009<\\u20090.05 and FDR\\u2009<\\u20090.1, ',\n",
       " 'Methods',\n",
       " '). Cytokines semaphorin 6B (encoded by ',\n",
       " 'SEMA6B',\n",
       " ') and granulin (encoded by ',\n",
       " 'GRN',\n",
       " ') were inferred to be the mediators by which smoking increases FaceCnnAgeDiff and FacePlsAgeDiff, respectively; ',\n",
       " 'SEMA6B',\n",
       " ' was also inferred to be a mediator by which alcohol drinking (measured in ‘Drunkenness days per week’) increased FaceCnnAgeDiff. ZZ-type zinc-finger-containing protein 3 (encoded by ',\n",
       " 'ZZZ3',\n",
       " '), involved in chromatin organization, was inferred to be the mediator of yoghurt’s negative effect on FaceCnnAgeDiff, and to lower ',\n",
       " 'SMAD1',\n",
       " ' to negatively affect FaceCnnPerceivedAgeDiff. RnaPlsAgeDiff had its own separate subnetwork, in which consumption of stem and root crops (for example, potato) were positively related to RnaPlsAgeDiff, mediated by tumour protein p53 (encoded by ',\n",
       " 'TP53',\n",
       " ') (Fig. ',\n",
       " '4a',\n",
       " ', ',\n",
       " 'P',\n",
       " '\\u2009<\\u20090.05 and FDR\\u2009<\\u20090.1). Interestingly, semaphorin is a chemokine, while granulin (cleaved from GRN, the granulin precursor) is also a secreted factor playing important roles in the development of the central nervous system',\n",
       " '20',\n",
       " ', wound healing',\n",
       " '21',\n",
       " ', tumorigenesis',\n",
       " '22',\n",
       " ' and neurodegenerative disease',\n",
       " '23',\n",
       " '. Overall, the network can be partitioned into four modules on the basis of connectivity density: the first, mostly affecting FacePlsAgeDiff and partially affecting FaceCnnAgeDiff, is enriched for proteolysis; the second, mostly affecting FaceCnnAgeDiff, is enriched for glycoprotein, protease and lysosome; the third, mostly affecting FaceCnnAgeDiff, is enriched for transmembrane proteins and zinc-finger transcription factors; and the fourth, exclusively affecting RnaPlsAgeDiff, is enriched for response to antibiotics and ultraviolet radiation (Fig. ',\n",
       " '4a',\n",
       " ').',\n",
       " 'Fig. 4: Inferred molecular mediators of AgeDiffs.',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ', Network of inferred causal relationships (causal-inference test with FDR correction, ',\n",
       " 'Methods',\n",
       " ') from lifestyle factors to AgeDiffs via molecular mediators (transcription factors, cytokines, regulatory genes and commonly expressed non-coding RNAs) among all samples (',\n",
       " 'a',\n",
       " ') or outlier samples (',\n",
       " 'b',\n",
       " ') in the Beijing 2012 cohort. Opaque nodes and edges indicate non-coding RNA mediators.',\n",
       " 'Full size image',\n",
       " 'Ribo-minus RNA sequencing (RNA-seq) allowed us to simultaneously examine coding and non-coding RNA changes during human ageing. We found 935 long non-coding RNAs (lncRNAs) that were commonly expressed (fragments per kilobase of transcript per million reads mapped (FPKM)\\u2009>\\u20092) in at least a quarter of samples. Among them, 62 and 210 were up- and downregulated by age, respectively (FDR\\u2009<\\u20090.1) (Extended Data Fig. ',\n",
       " '7a',\n",
       " '). Twenty-three lncRNAs appeared in the causal-inference network (Fig. ',\n",
       " '4a',\n",
       " '). We found 5,002 circular RNAs (circRNAs) commonly expressed (transcripts per million (TPM)\\u2009>\\u20092) in at least a quarter of samples. Among them, 41 and 8 were up- and downregulated with age, respectively (FDR\\u2009<\\u20090.1) (Extended Data Fig. ',\n",
       " '7b,c',\n",
       " '), and 45 of them appeared in the causal-inference network (Fig. ',\n",
       " '4a',\n",
       " '). Despite a trend of a higher fraction of total circRNAs during ageing (Extended Data Fig. ',\n",
       " '7d',\n",
       " ', PCC\\u2009=\\u20090.26), consistent with global circRNA accumulation with age',\n",
       " '24',\n",
       " ', total circRNA level shows no significant association with AgeDiffs, implicating it to more likely be a consequence of ageing.',\n",
       " 'We applied the same causal-inference approach to only the outliers defined by all four AgeDiffs because we assumed that some associations might be significant only in more-extreme samples. Indeed, we found a very different set of associations among the outliers as compared with those of the whole cohort. Ice-cream intake was inferred to be positively related to FacePlsAgeDiff through two circRNAs and to FaceCnnAgeDiff through AE binding protein 1 (encoded by ',\n",
       " 'AEBP1',\n",
       " '), chromobox 5 (encoded by ',\n",
       " 'CBX5',\n",
       " ') and sterol regulatory element-binding transcription factor 1 (encoded by ',\n",
       " 'SREBF1',\n",
       " '). Yoghurt was negatively related to FaceCnnAgeDiff and FaceCnnPerceivedAgeDiff through a few lncRNAs and circRNAs among the outliers (',\n",
       " 'P',\n",
       " '\\u2009<\\u20090.05 and FDR\\u2009<\\u20090.1, Fig. ',\n",
       " '4b',\n",
       " '). SREBF1 modulates cellular cholesterol metabolism, regulates lipogenesis and glycolysis',\n",
       " '25',\n",
       " ' and has an important role in the immune system',\n",
       " '26',\n",
       " ',',\n",
       " '27',\n",
       " '.',\n",
       " 'To facilitate the full utilization of this dataset, we developed the HuB-Fi database for querying and visualizing health status and transcript changes associated with facial-ageing features, and the impacts of different lifestyles.',\n",
       " 'Discussion',\n",
       " 'In this study, we developed deep-learning CNN models that made age predictions based on high-resolution 3D facial images with high accuracy in a large cohort of ~5,000 people. CNN models identified a larger number of associations, that were stronger in significance, of ageing with health parameters and lifestyles, demonstrating that these models are a high-accuracy method for estimation of the ageing rate that can be complementary to other methods. Despite there being relatively fewer samples of very old ages (>70 yr) included for age prediction in our work, we consistently found many lifestyle and health parameters associated with various AgeDiffs, in particular the AgeDiff given by the artificial intelligence (AI)-based perceived-age predictor (FaceCnnPerceivedAgeDiff). The observation that the AI model often outperforms the PLS model is probably because the AI predictor is less sensitive to imbalanced data structures. In fact, FaceCnnPerceivedAgeDiff not only is associated with many more health parameters but also is more highly significantly associated with blood pressure than are the other three AgeDiffs (Supplementary Table ',\n",
       " '8',\n",
       " '). This suggests that our age predictors, in particular the AI-based predictor of perceived age, are superior health estimators. Unlike using chronological age in machine learning, the unique advantage of using perceived age as a health biomarker has been illustrated before by the Christensen group in Danish twins',\n",
       " '12',\n",
       " '. Here, we trained an AI predictor to learn how humans perceive other people’s ages, which reliably captured human perception and even corrected some human errors through regularization, hence generating a health predictor that is even more accurate than perceived age (the training standards). Although CNNs could give a much more accurate prediction of chronological age by optimizing chronological-age prediction, such prediction might ignore the deviations of biological age from chronological age. This is partially circumvented by training the CNN to learn perceived age, even though perceived age may not be a true reflection of biological age. The PerceivedAge s.d. generally increased with chronological age (PCC = 0.248, ',\n",
       " 'P',\n",
       " '\\u2009<\\u20092.2 × 10',\n",
       " '–16',\n",
       " '). This is perhaps because the judges of age were all young people who are not accustomed to judging older people’s ages from experience, and even by random guessing, a larger number (representing age in this case) will have a larger range of variance than a smaller number will. However, although the PLS model does not predict chronological age as accurately as the CNN does, its simplicity may capture certain aspects of biological age that are ignored by the CNN. Future studies of a panel of gold standards of biological age will allow CNNs to be trained to specifically estimate biological age, and a better judgement to be made of the utility of different models for predicting biological age.',\n",
       " 'As for the specific pipeline and parameters we chose in this study, we first tested the most widely used CNN architectures, GoogleNet, VGG with 16 layers and ResNet with 50 layers. We found very similar performance between ResNet with 101, 152 and 200 layers and ResNet with 50 layers. Therefore, in the final model, we included in the ensemble the results of only ResNet with 50 layers. Using just RGB images, the deep CNN models could predict age with high accuracy, with a MAD of 2.90 yr when using GoogleNet, a MAD of 3.27 yr when using VGG and a MAD of 3.13 yr when using ResNet. Similarly, we also predicted age with only depth information, which produced a MAD of 3.50 yr when using GoogleNet, a MAD of 3.75 yr when using VGG and a MAD of 3.70 yr when using ResNet. An ensemble of the three CNNs reaches a MAD of 2.82 yr for RGB images and a MAD of 3.35 yr for depth images. The final ensemble of the RGB and depth images yielded our reported MAD of 2.79 yr.',\n",
       " 'We further collected parallel data from 280 Han Chinese individuals in Beijing. We applied the CNN models trained on the large cohort to this smaller cohort and compared them with linear facial-image and transcriptome-age prediction models derived from the small cohort. Outliers identified by all four AgeDiffs significantly overlapped (',\n",
       " 'P <',\n",
       " ' 0.05).',\n",
       " 'At the functional level, high AgeDiffs all converged on the upregulation of inflammation and innate-immunity function, which is also supported by the upregulation of monocyte counts, a major player in innate immunity, and MCV, an indicator of chronic illness. Our analysis highlights the functional similarity between RNA-derived and 3D-facial-image-derived AgeDiffs not only at the molecular and functional level, but also at the cellular level.',\n",
       " 'The age-related facial features, health parameters and gene expression, as well as various AgeDiffs (except FacePlsAgeDiff) all revealed a large heterogeneity of the ageing rate at middle age, with a bimodal distribution of the old and young patterns. This suggests that young and old are the alternative steady states, and middle age is a transition stage (Fig. ',\n",
       " '2',\n",
       " ' and Extended Data Fig. ',\n",
       " '3',\n",
       " '), implying that middle age is the ideal stage for ageing interventions. Incidentally, it also avoids the complications of growth/maturation in the young group and the impact of disease status in the older group, and supports ageing-related risk screening for middle-aged people, a target group in which the benefits of implementation of therapies are likely to outweigh the potential harms of screening',\n",
       " '28',\n",
       " '.',\n",
       " 'Finally, by scrutinizing the lifestyle choices responsible for acceleration or deceleration of AgeDiff and their potential molecular mediators in the blood, we found many potential causal associations between lifestyle, transcript and AgeDiff.',\n",
       " 'Overall, our analyses based on various age predictors show that humans age at different rates both in the blood and on the face, but coherently and with heterogeneity peaking at middle age. The differences can be attributed to different lifestyles, which through impacting circulating factors may affect facial morphology. More-accurate CNN-based predictors enabled more-sensitive and statistically robust discoveries of associations between facial features, health and lifestyle.',\n",
       " 'Despite some obvious limitations in our current study that need to be addressed in future studies, such as that individuals of advanced age were not included, that only Han Chinese people were included and that the current model is based only on a high-resolution 3D imaging system, our study represents a step closer to the ultimate goal of identifying actionable lifestyle choices and their molecular mediators to target ageing. The AI technology we developed here aims to easily and widely monitor ageing rates, which will greatly benefit the ever-growing ageing populations and development of effective intervention strategies. However, as this system is based on facial images, the technology is not only sensitive in regard to personal identification but potentially can be abused for unintended purposes; hence, it should be carefully guarded against any unethical use. With an increased sample size, we expect that other lifestyle parameters, their molecular mediators and facial signatures will be discovered by the same type of study in the near future.',\n",
       " 'Methods',\n",
       " 'Ethics statement',\n",
       " 'The Jidong study was carried out according to the guidelines of the Declaration of Helsinki',\n",
       " '29',\n",
       " '. Approval was obtained from Ethical Committees of the Staff Hospital of Jidong oil-field of China National Petroleum Corporation. The approval will be renewed every 5 years. Written informed consent was obtained from each of the participants. The Beijing study was approved by the ethics committee of the Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences. For the detailed recruitment procedure, please refer to the ',\n",
       " 'Reporting Summary',\n",
       " '.',\n",
       " 'Data acquisition',\n",
       " 'We collected 3D facial images of the Han Chinese cohort at Tangshan in Heibei province using the 3dMDface System (',\n",
       " 'www.3dmd.com',\n",
       " '). As a requirement, volunteers sat straight and looked forward to the 3dMDface device for 1\\u2009min, without any facial expression, for the 3D facial images to be taken. The 3dMDface system returned OBJ-formatted 3D facial surfaces with point clouds and corresponding texture images. Also for each participant, baseline information including age, sex, education level, anthropometry and lifestyle factors (for example, frequency of smoking, alcohol drinking, diet and exercise) were collected from questionnaires, weight, height and blood pressure were measured and routine blood tests were done.',\n",
       " 'Three-dimensional facial images, blood and routine physical indicators (full blood count, blood basic metabolic panel and anthropometry) were collected at Beijing Centers for Diseases Control and Prevention (CDC) and Centers for Preventive Medical Research. All participants provided written informed consent prior to this study. All participants (Han Chinese people, 169 females and 163 males) in this study had no history of facial surgery or facial abnormalities. We used the 3dMDface system to capture 3D facial images of about 40,000 vertices per face. The detailed procedure of photography capture has been described in previous work',\n",
       " '7',\n",
       " '.',\n",
       " 'Human-perceived age',\n",
       " 'To compare human-perceived age and CNN-predicted age, we gathered 50 volunteers to evaluate the ages of all samples. We randomly shuffled the images and asked the volunteers to guess the ages of participants by looking at their facial images. Each image was evaluated by 5.33 volunteers on average (at least 3 and no more than 6), and the average guess of the volunteers was used as the human-perceived age of each face.',\n",
       " 'Age prediction using 3D facial images',\n",
       " 'Chronological age',\n",
       " 'Birth dates were obtained by the Chinese-government-issued official Resident Identity Card. Age was rounded to the nearest year for model training.',\n",
       " 'Data structure of 3D facial images',\n",
       " 'The 3D facial images were stored in the OBJ file format and with corresponding texture images. The OBJ-format file contains four types of information for a 3D face surface with ',\n",
       " 'N',\n",
       " ' points: (1) ',\n",
       " 'N',\n",
       " ' lines of ‘v’ plus ',\n",
       " 'XXX',\n",
       " ' (where ',\n",
       " 'X',\n",
       " ' is a floating-count number), representing coordinates of the ',\n",
       " 'N',\n",
       " ' points; (2) ',\n",
       " 'N',\n",
       " ' lines of ‘vn’ plus ',\n",
       " 'XXX',\n",
       " ', representing the normal vector of each of the ',\n",
       " 'N',\n",
       " ' points; (3) ',\n",
       " 'N',\n",
       " ' lines of ‘vt’ plus ',\n",
       " 'XX',\n",
       " ', representing coordinates of each point in the corresponding texture image; and (4) multiple lines starting with ‘f’ and three groups of integers, representing that these three indexes form a triangle, which further constitutes multiple triangle meshes in the 3D facial images.',\n",
       " 'Nose-tip annotation',\n",
       " 'The nose tip is the most salient and stable feature point on 3D facial images. We first detected the nose-tip point on a face using sphere fitting',\n",
       " '30',\n",
       " '. We used a sphere with a radius equal to ',\n",
       " 'r',\n",
       " ' to fit regions over the 3D face and took the point with the smallest least square difference as the nose-tip point. To calculate the least square of every point ',\n",
       " 'p',\n",
       " ' with coordinate (',\n",
       " 'x',\n",
       " 'p',\n",
       " ',',\n",
       " 'y',\n",
       " 'p',\n",
       " ',',\n",
       " 'z',\n",
       " 'p',\n",
       " '), we first summarized all points on the 3D face with a distance of <1.5 cm from point ',\n",
       " 'p',\n",
       " ', and subjected them to the following formula:',\n",
       " '$$\\\\sqrt {\\\\left( {x_p - x_i} \\\\right)^2 + \\\\left( {y_p - y_i} \\\\right)^2 + \\\\left( {z_p - z_i} \\\\right)^2} < 1.5$$',\n",
       " 'where ',\n",
       " 'i',\n",
       " ' represents the ',\n",
       " 'i',\n",
       " 'th vertex on the 3D face. Then, we assumed that there were, in total, ',\n",
       " 'N',\n",
       " ' points with a distance of <1.5 cm to point ',\n",
       " 'p',\n",
       " '. These points were annotated as ',\n",
       " '\\\\(p_i = \\\\left( {x_i,y_i,z_i} \\\\right),1 \\\\le i \\\\le N\\\\)',\n",
       " '. At the same time, we assumed that the centre of the sphere had coordinate (',\n",
       " 'o',\n",
       " 'x',\n",
       " ',',\n",
       " 'o',\n",
       " 'y',\n",
       " ',',\n",
       " 'o',\n",
       " 'z',\n",
       " '); then, the sphere could be represented using the following formula:',\n",
       " '$$\\\\left( {x - o_x} \\\\right)^2 + \\\\left( {y - o_y} \\\\right)^2 + \\\\left( {z - o_z} \\\\right)^2 = r^2$$',\n",
       " 'where ',\n",
       " 'r',\n",
       " ' represents the radius of the sphere. For points ',\n",
       " 'p',\n",
       " 'i',\n",
       " ' = (',\n",
       " 'x',\n",
       " 'i',\n",
       " ',',\n",
       " 'y',\n",
       " 'i',\n",
       " ',',\n",
       " 'z',\n",
       " 'i',\n",
       " '), we calculated the distance between the point and the sphere, which can be represented as the error:',\n",
       " '$$\\\\varepsilon _i = \\\\left| {\\\\left( {x_i - o_x} \\\\right)^2 + \\\\left( {y_i - o_y} \\\\right)^2 + \\\\left( {z_i - o_z} \\\\right)^2 - r^2} \\\\right|$$',\n",
       " '$$\\\\varepsilon _i = \\\\left| {\\\\left( {x_i^2 + y_i^2 + z_i^2} \\\\right) - \\\\left( {2o_xx_i + 2o_yy_i + 2o_zz_i} \\\\right) + \\\\left( {o_x^2 + o_y^2 + o_z^2 - r^2} \\\\right)} \\\\right|$$',\n",
       " 'Then to clearly represent the errors, we reformulated the error as:',\n",
       " '$$\\\\varepsilon _i = \\\\left| {Y - \\\\left( {w_1X_1 + w_2X_2 + w_3X_3 + w_0} \\\\right)} \\\\right|$$',\n",
       " 'where ',\n",
       " '\\\\(w_1 = 2o_x,w_2 = 2o_y,w_3 = 2o_z,w_0 = r^2 - o_x^2 - o_y^2 - o_z^2,Y = x_i^2 + y_i^2 + y_i^2,\\\\)',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a7c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_text = [x.replace('\\n', ' ') for x in body_text]\n",
    "body_text = [x.replace('    ', ' ') for x in body_text]\n",
    "body_text = [x.replace('   ', ' ') for x in body_text]\n",
    "body_text = [x.replace('  ', ' ') for x in body_text]\n",
    "body_text = [x.lower() for x in body_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae656889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditions\n",
    "\n",
    "def alphachars(x): return sum(a.isalpha() for a in x) > 4\n",
    "\n",
    "def charchar(x): return bool(re.match(r\".*[a-zA-Z][a-zA-Z].*\", x)) == True\n",
    "\n",
    "def istitle(x): return ((('ethod' in x) or ('aterial' in x) or ('esult' in x) or ('iscussion' in x) or ('onclusion' in x)) \n",
    "                        and (sum(l.isalpha() for l in x) < 30))\n",
    "\n",
    "def istextblock(x): return sum(l.isalpha() for l in x) > 100\n",
    "\n",
    "def methodtitle(x): return ((('ethod' in x) or ('aterial' in x)) and (sum(l.isalpha() for l in x) < 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "808b86ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' we use cookies to make sure that our website works properly, as well as some ‘optional’ cookies to personalise content and advertising, provide social media features and analyse how people use our site. by accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the european economic area that do not offer the same data protection standards as the country where you live. you can decide which optional cookies to accept by clicking on ‘manage settings’, where you can also find more information about how your personal data is processed.  further information can be found in our ',\n",
       " 'thank you for visiting nature.com. you are using a browser version with limited support for css. to obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in internet explorer). in the meantime, to ensure continued support, we are displaying the site without styles and javascript.',\n",
       " 'show results from',\n",
       " 'not all individuals age at the same rate. methods such as the ‘methylation clock’ are invasive, rely on expensive assays of tissue samples and infer the ageing rate by training on chronological age, which is used as a reference for prediction errors. here, we develop models based on convoluted neural networks through training on non-invasive three-dimensional (3d) facial images of approximately 5,000 han chinese individuals that achieve an average difference between chronological or perceived age and predicted age of ±2.8 and 2.9 yr, respectively. we further profile blood transcriptomes from 280 individuals and infer the molecular regulators mediating the impact of lifestyle on the facial-ageing rate through a causal-inference model. these relationships have been deposited and visualized in the human blood gene expression—3d facial image (hub-fi) database. overall, we find that humans age at different rates both in the blood and in the face, but do so coherently and with heterogeneity peaking at middle age. our study provides an example of how artificial intelligence can be leveraged to determine the perceived age of humans as a marker of biological age, while no longer relying on prediction errors of chronological age, and to estimate the heterogeneity of ageing rates within a population.',\n",
       " 'ageing is a major risk factor for many complex human diseases. rates of biological ageing are highly variable among individuals of the same chronological age. to quantify ageing, ideally, biological age rather than chronological age should be assessed; however, because of the lack of a gold standard for biological age, the population average of chronological age is often assumed to be the standard of biological age. the deviators or outliers of the average or standard curve are defined and often substantiated as fast or slow agers by other physiological or molecular parameters. on the basis of this assumption, many methods have been developed to quantify ageing. for example, predicting age using the transcriptome in human peripheral blood has a mean absolute difference (mad) between chronological age and predicted biological age of 7.8 yr (ref. ',\n",
       " '. however, because the transcriptome, dna methylome and proteome have to be measured in blood cells or other tissues, invasiveness and high costs preclude their application to large-scale screens and routine physical examinations.',\n",
       " 'facial images have been used in traditional chinese medicine as a major diagnosis tool for evaluating health and disease status. this practice originated more than 2,000 years ago',\n",
       " '. our previous work has established 3d human facial image as an ageing marker, generated a partial least squares regression (plsr) model and used the difference between chronological and predicted age (agediff) to identify outliers in the ageing rate',\n",
       " ', but no biological process has been directly linked to differential ageing rates (or agediff) across individuals. indeed, the ageing rate might be associated with a subset of ageing-related changes that are more modifiable by environment, diet, lifestyle or variations in genetic background across different individuals than the genetically hardcoded programme that is fatefully played out for a species. thus, an understanding of the molecular events contributing to agediff is actionable and pertinent to understanding healthy ageing.',\n",
       " '. benefiting from these highly efficient cnn architectures, we trained three classic cnns (inception, visual geometry group (vgg) and resnet) using the large datasets in imagenet. we then applied them to 3d facial images from a large cohort of 4,719 individuals so they could learn age by transfer learning. in combining the results from the 3 cnns, the accuracy of age and perceived-age prediction reached a mad of 2.79 and 2.90 yr, respectively. this allowed us to examine ageing-rate heterogeneity across individuals during ageing, which was otherwise missed by our previous linear plsr model. our cnn for perceived-age prediction is designed to learn a representation of biological age instead of chronological age, which is supported by its detection of much-stronger associations of lifestyle and health parameters with ageing than those found by a chronological-age predictor. we used a statistical test',\n",
       " ', coupled with peripheral blood mononuclear cell (pbmc) transcriptome analysis, and built a causal-inference network that reveals circulation factors mediating lifestyle impacts on facial morphologies from blood transcriptomes. we deposited and visualized the associations and inferred causal relationships in the hub-fi (',\n",
       " 'results',\n",
       " 'to construct a highly accurate age-estimating model from 3d facial images, we collected 4,719 facial images from han chinese individuals in north china (jidong) with the 3dmdface system, together with corresponding age, sex, physical-examination and questionnaire information (supplementary table ',\n",
       " '). we developed a fully automated pipeline for analysis of 3d facial images, including pose correction, landmark identification and projection of depth and red, green and blue (rgb) colour of a 3d image onto two-dimensional (2d) images with four channels, for face registration and deep learning. we then used these 2d images to train the cnn model to predict chronological age (facecnnage) (fig. ',\n",
       " 'methods',\n",
       " 'methods',\n",
       " '). because a cnn trained on chronological age by optimizing prediction accuracy for chronological age might not be optimized to detect biological age, we trained another cnn model to predict perceived age, which might better reflect the health state',\n",
       " ', termed facecnnperceivedage. this model also achieved a high accuracy, with a mad of 2.90 yr for perceived age and 4.10 yr for chronological age (fig. ',\n",
       " '). we then examined the consistency of agediffs or outliers (|agediff| > mad) given by different models and found that they are highly correlated (supplementary table ',\n",
       " ', the large amount of imaging data we collected and the fully automated pipeline for analysis of 3d facial images (landmark identification and face registration) we developed here enabled us to train cnns to predict chronological and perceived age in a cohort of 4,719 individuals (jidong) by cross-validation and by validation in two independent cohorts of ~300 individuals each (beijing 2012 and beijing 2015). the imagenet pretrained weights of inception (inception_v1), vgg (vgg_16) and resnet (resnet_50) were transferred to learn age or perceived age. average faces of the cohort are used for illustration. ageing rate, as defined by predicted versus chronological age (agediff), was examined for associations with health and lifestyle in the jidong cohort. ribo-minus rna-seq of blood pbmcs was generated for the beijing 2012 cohort, and was used to infer the molecular mediators of lifestyle impact on ageing-rate variations. ',\n",
       " ', association-strength network of 4 agediffs and health parameters, corrected for chronological age, filtered by fdr\\u2009<\\u20090.1. bmd, bone mineral density; dbp, diastolic blood pressure; sbp, systolic blood pressure; bmi, body mass index; neccir, neck circumference; abdcir, abdominal circumference; wstcir, waist circumference; hipcir, hip circumference; cr, creatinine; akp, alkaline phosphatase; alt, alanine aminotransfersase; ast, aspartate transaminase; tc, total cholesterol; apoa, apolipoprotein a; apob, apolipoprotein b; gt, transglutaminase; fbg, fasting blood glucose; ldl, low-density lipoprotein; tg, triglycerides. ',\n",
       " ', association network between lifestyle and agediffs in the jidong cohort. edges are filtered by fdr\\u2009<\\u20090.1. smoking, smoker or non-smoker; cignumber, average number of cigarettes per day; cigpasyear, number of years of passive smoking; snorefreq, frequency of snoring per week; snoresound, whether the sound of a snore is louder than speaking voice; snoreapnoea: whether snoring is coupled with apnoea; alchohol, average intake of alcohol per day; salt, average intake of salt per day; dyehair, whether have hair dyed in the last three months; fruit, frequency of consuming fruits; vegetable, frequency of consuming vegetables; dair, frequency of consuming dairy products; exhighmin, average length of vigorous exercise per day.',\n",
       " 'to validate the cnn models in independent cohorts, we predicted the ages of people in 332 images from the 2012 beijing cohort (supplementary table ',\n",
       " '; these images have only half the resolution of those in the other cohorts) and in 358 images from the 2015 beijing cohort (supplementary table ',\n",
       " ') with the cnn models that learnt from the large jidong cohort. we achieved a mad of 3.85 yr for data collected in 2012 and of 3.92 yr for data collected in 2015 for facecnnage, and a mad of 6.66 yr for 2012 and of 4.12 yr for 2015 for facecnnperceivedage (extended data fig. ',\n",
       " '). as a comparison, the pls model achieved mad\\u2009=\\u20096.15 and 4.81 yr for the 2012 and 2015 beijing cohorts, respectively. these results suggest that the cnn models achieve superior accuracy not only over all other linear models by cross-validation in the same cohort but also in at least two other independent cohorts. it should be noted that, due to the small sample sizes of the beijing cohorts, we could not do the opposite, that is train the cnn models on the beijing cohorts and validate them on the jidong cohort.',\n",
       " 'to examine the biological relevance of agediffs, we next examined the association of agediffs with health parameters corrected for age (false-discovery rate (fdr)\\u2009<\\u20090.1) in the jidong cohort. indices related to obesity, blood pressure, transglutaminase, alkaline phosphatase and cholesterol were among the factors that were most strongly associated with all agediffs, whereas bone mineral density and creatinine were significantly negatively associated with three out of four agediffs. interestingly, among all four agediffs, facecnnperceivedagediff associated with remarkably more health parameters than other agediffs did (fig. ',\n",
       " '), indicating that it could be a superior predictor of health, even when compared with the model’s training data—human-perceived age.',\n",
       " 'to uncover the associations of lifestyles factors with differential ageing rates, we determined the association between quantitative lifestyle parameters with agediffs in the jidong cohort. smoking, number of cigarettes and years of passive smoking were linked to all four agediffs as the factors that most strongly increased the ageing rate. frequency of snoring, sound of snoring and apnoea during snoring were linked to all but faceplsagediff. among factors that decreased the ageing rate, dairy intake was linked to all four agediffs. the associations identified by facecnnperceivedagediff essentially captured all those found by facecnnagediff or by faceperceivedagediff, but captured a greater number of associations (fig. ',\n",
       " '). this suggests that both are optimized to accurately detect the ageing rate, with facecnnperceivedagediff being a better estimate of the biological ageing rate than all other age predictors are, including perceived age itself. similar associations can be observed in the smaller beijing 2012 cohort (extended data fig. ',\n",
       " 'in contrast to the s.d. expected from randomly guessing a number between 20–85, which is highest at young and old age (extended data fig. ',\n",
       " '), the heterogeneity of the ageing rate precisely captured by facecnnagediff and facecnnperceivedagediff peaked at middle age (fig. ',\n",
       " '). faceperceivedagediff also peaked at middle age, although it plateaued afterwards in males. faceplsagediff, however, is very different in that it shows a monotonic increase in s.d. with increasing chronological age and an s.d. that appears random at old age. these patterns are insensitive to the bin size (moving window) (',\n",
       " 'methods',\n",
       " '). similar patterns can be observed in the smaller beijing cohort. using broken-stick regression to pinpoint the breakpoint in the regression line, we found that all four agediffs predominately show a breakpoint peaking at middle age (extended data fig. ',\n",
       " ', heatmap of facial features in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1 in females and in males). features are ranked by pcc from lowest to highest in females and in males. ',\n",
       " ', a heatmap of health parameters in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1). features are ordered as in ',\n",
       " 'previous findings show that for human brain ageing transcriptomes, unlike those of very young or very old individuals, middle-aged individuals display high heterogeneity',\n",
       " '. we observed a similar pattern when all samples were visualized by a heatmap of age-related quantitative facial features (fig. ',\n",
       " 'using the cohort that we collected from the beijing area (beijing 2012), we extracted and sequenced the ribo-minus rna from pbmcs of 280 individuals with matching 3d facial images (supplementary table ',\n",
       " '). we performed plsr analysis on transcriptomes to predict chronological age in the same way that we did for 3d facial images',\n",
       " '). like the s.d. of agediff detected by cnn in both the large and the small cohort, rnaplsagediff in this small cohort peaked at middle age (around 40–50 yr old) (extended data fig. ',\n",
       " '). similarly, with broken-stick regression, we found that all four agediffs predominately showed a breakpoint peaking at middle age in the beijing 2012 cohort (extended data fig. ',\n",
       " 'we also applied the facecnnage and facecnnperceivedage cnn models that learnt from the large jidong cohort to the 280 samples and compared them with plsr-derived models faceplsage (trained on the 280 3d facial images) and rnaplsage. despite being derived from different machine-learning algorithms, different training sets and different data types, the agediffs predicted by various models significantly correlated with each other, with higher correlation of rna with cnn-based models than with the facial pls model (supplementary table ',\n",
       " '). moreover, the outliers identified by rnaplsage significantly overlapped with the two cnn-based models in both fast and slow agers (',\n",
       " 'to identify the blood transcriptome differences associated with differential facial-ageing rates, we compared the kyoto encyclopedia of genes and genomes (kegg) pathways with gene expression that was correlated with at least two of the four estimated agediffs or with age (fig. ',\n",
       " '). among pathways positively correlated with agediffs (fdr\\u2009<\\u20090.1), most were also positively correlated with age and inflammation, such as those linked to ',\n",
       " ', salmonella infection and shigellosis. and, similarly to age, agediffs tended to be consistently negatively correlated with biogenesis of ribosome and transfer rna. although all four agediffs were uncorrelated with chronological age after age correction, the molecular pathways that correlated with age and the four agediffs were largely consistent, indicating that the acceleration or deceleration of ageing detected by agediffs measurements is largely consistent with the ageing process at the pathway level.',\n",
       " ', distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on monocyte number derived from haematology analyser (two-sided ',\n",
       " ', distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on deconvoluted naive cd4',\n",
       " ', distribution of facecnnagediff (left) or facecnnperceivedagediff (middle) between the top and bottom 10% of samples on mcv (two-sided ',\n",
       " 'we then sought to further verify the agediff–inflammation association by examining whether inflammatory gene sets are positively related to agediffs. cytokine expression was positively related to faceplsagediff, rnaplsagediff and facecnnagediff (kolmogorov–smirnov (ks) test, nominal ',\n",
       " '\\u2009<\\u20090.05), but not facecnnperceivedagediff. innate-immunity-related genes, such as those linked to antigen processing and presentation, were positively related to all four agediffs (ks test, extended data fig. ',\n",
       " '). in summary, all four agediffs were significantly positively related to inflammation and innate-immunity processes, which are also important features of ageing per se.',\n",
       " ', we found that the monocyte fraction was significantly positively associated with faceplsagediff, and the direction was consistent, although not significant, with its association with the other three agediffs across all individuals (extended data fig. ',\n",
       " '). the plsr components 1 and 2 of 3d facial images regressed to monocyte fractions most significantly mapped to shrinkage of the forehead (fig. ',\n",
       " '), which is in agreement with the negative association between inflammatory biomarkers, including interleukin-6, osteoprotegerin and tumour necrosis factor-α, and brain volume as measured by magnetic resonance imaging',\n",
       " ' t cells were consistently negatively associated with all four agediffs, although the association was significant for only faceplsagediff and for rnaplsagediff (fig. ',\n",
       " '). the plsr components 1 and 2 of 3d facial changes to this cell fraction showed mapping to a reduction of under-eye puffiness (fig. ',\n",
       " 'in addition, both cnn-derived agediffs were significantly associated with the mean corpuscular volume of erythrocytes (mcv), a known chronic-illness indicator that is positively associated with ageing',\n",
       " ', between more-extreme samples (compared between the top and bottom 10% of samples; the association was marginal if the comparison was between the top and bottom 20% of samples). the facial pattern was similar to that associated with the monocyte fraction (fig. ',\n",
       " 'our parallel measurement of lifestyles, blood cell transcriptome and agediffs for the same individuals in the beijing 2012 cohort offered an opportunity to examine the molecular mediators of the impact of lifestyle on facial agediff. we thus generated a tripartite network of lifestyle–transcriptome–agediff using a causal-inference framework',\n",
       " ' querying all transcriptome clusters, encode transcription factors, signalling and epigenetic factors and cytokines as potential mediators (',\n",
       " 'methods',\n",
       " ' was also inferred to be a mediator by which alcohol drinking (measured in ‘drunkenness days per week’) increased facecnnagediff. zz-type zinc-finger-containing protein 3 (encoded by ',\n",
       " '), involved in chromatin organization, was inferred to be the mediator of yoghurt’s negative effect on facecnnagediff, and to lower ',\n",
       " ' to negatively affect facecnnperceivedagediff. rnaplsagediff had its own separate subnetwork, in which consumption of stem and root crops (for example, potato) were positively related to rnaplsagediff, mediated by tumour protein p53 (encoded by ',\n",
       " '\\u2009<\\u20090.05 and fdr\\u2009<\\u20090.1). interestingly, semaphorin is a chemokine, while granulin (cleaved from grn, the granulin precursor) is also a secreted factor playing important roles in the development of the central nervous system',\n",
       " '. overall, the network can be partitioned into four modules on the basis of connectivity density: the first, mostly affecting faceplsagediff and partially affecting facecnnagediff, is enriched for proteolysis; the second, mostly affecting facecnnagediff, is enriched for glycoprotein, protease and lysosome; the third, mostly affecting facecnnagediff, is enriched for transmembrane proteins and zinc-finger transcription factors; and the fourth, exclusively affecting rnaplsagediff, is enriched for response to antibiotics and ultraviolet radiation (fig. ',\n",
       " 'methods',\n",
       " ') from lifestyle factors to agediffs via molecular mediators (transcription factors, cytokines, regulatory genes and commonly expressed non-coding rnas) among all samples (',\n",
       " 'ribo-minus rna sequencing (rna-seq) allowed us to simultaneously examine coding and non-coding rna changes during human ageing. we found 935 long non-coding rnas (lncrnas) that were commonly expressed (fragments per kilobase of transcript per million reads mapped (fpkm)\\u2009>\\u20092) in at least a quarter of samples. among them, 62 and 210 were up- and downregulated by age, respectively (fdr\\u2009<\\u20090.1) (extended data fig. ',\n",
       " '). we found 5,002 circular rnas (circrnas) commonly expressed (transcripts per million (tpm)\\u2009>\\u20092) in at least a quarter of samples. among them, 41 and 8 were up- and downregulated with age, respectively (fdr\\u2009<\\u20090.1) (extended data fig. ',\n",
       " ', total circrna level shows no significant association with agediffs, implicating it to more likely be a consequence of ageing.',\n",
       " 'we applied the same causal-inference approach to only the outliers defined by all four agediffs because we assumed that some associations might be significant only in more-extreme samples. indeed, we found a very different set of associations among the outliers as compared with those of the whole cohort. ice-cream intake was inferred to be positively related to faceplsagediff through two circrnas and to facecnnagediff through ae binding protein 1 (encoded by ',\n",
       " '). yoghurt was negatively related to facecnnagediff and facecnnperceivedagediff through a few lncrnas and circrnas among the outliers (',\n",
       " 'to facilitate the full utilization of this dataset, we developed the hub-fi database for querying and visualizing health status and transcript changes associated with facial-ageing features, and the impacts of different lifestyles.',\n",
       " 'discussion',\n",
       " 'in this study, we developed deep-learning cnn models that made age predictions based on high-resolution 3d facial images with high accuracy in a large cohort of ~5,000 people. cnn models identified a larger number of associations, that were stronger in significance, of ageing with health parameters and lifestyles, demonstrating that these models are a high-accuracy method for estimation of the ageing rate that can be complementary to other methods. despite there being relatively fewer samples of very old ages (>70 yr) included for age prediction in our work, we consistently found many lifestyle and health parameters associated with various agediffs, in particular the agediff given by the artificial intelligence (ai)-based perceived-age predictor (facecnnperceivedagediff). the observation that the ai model often outperforms the pls model is probably because the ai predictor is less sensitive to imbalanced data structures. in fact, facecnnperceivedagediff not only is associated with many more health parameters but also is more highly significantly associated with blood pressure than are the other three agediffs (supplementary table ',\n",
       " '). this suggests that our age predictors, in particular the ai-based predictor of perceived age, are superior health estimators. unlike using chronological age in machine learning, the unique advantage of using perceived age as a health biomarker has been illustrated before by the christensen group in danish twins',\n",
       " '. here, we trained an ai predictor to learn how humans perceive other people’s ages, which reliably captured human perception and even corrected some human errors through regularization, hence generating a health predictor that is even more accurate than perceived age (the training standards). although cnns could give a much more accurate prediction of chronological age by optimizing chronological-age prediction, such prediction might ignore the deviations of biological age from chronological age. this is partially circumvented by training the cnn to learn perceived age, even though perceived age may not be a true reflection of biological age. the perceivedage s.d. generally increased with chronological age (pcc = 0.248, ',\n",
       " '). this is perhaps because the judges of age were all young people who are not accustomed to judging older people’s ages from experience, and even by random guessing, a larger number (representing age in this case) will have a larger range of variance than a smaller number will. however, although the pls model does not predict chronological age as accurately as the cnn does, its simplicity may capture certain aspects of biological age that are ignored by the cnn. future studies of a panel of gold standards of biological age will allow cnns to be trained to specifically estimate biological age, and a better judgement to be made of the utility of different models for predicting biological age.',\n",
       " 'as for the specific pipeline and parameters we chose in this study, we first tested the most widely used cnn architectures, googlenet, vgg with 16 layers and resnet with 50 layers. we found very similar performance between resnet with 101, 152 and 200 layers and resnet with 50 layers. therefore, in the final model, we included in the ensemble the results of only resnet with 50 layers. using just rgb images, the deep cnn models could predict age with high accuracy, with a mad of 2.90 yr when using googlenet, a mad of 3.27 yr when using vgg and a mad of 3.13 yr when using resnet. similarly, we also predicted age with only depth information, which produced a mad of 3.50 yr when using googlenet, a mad of 3.75 yr when using vgg and a mad of 3.70 yr when using resnet. an ensemble of the three cnns reaches a mad of 2.82 yr for rgb images and a mad of 3.35 yr for depth images. the final ensemble of the rgb and depth images yielded our reported mad of 2.79 yr.',\n",
       " 'we further collected parallel data from 280 han chinese individuals in beijing. we applied the cnn models trained on the large cohort to this smaller cohort and compared them with linear facial-image and transcriptome-age prediction models derived from the small cohort. outliers identified by all four agediffs significantly overlapped (',\n",
       " 'at the functional level, high agediffs all converged on the upregulation of inflammation and innate-immunity function, which is also supported by the upregulation of monocyte counts, a major player in innate immunity, and mcv, an indicator of chronic illness. our analysis highlights the functional similarity between rna-derived and 3d-facial-image-derived agediffs not only at the molecular and functional level, but also at the cellular level.',\n",
       " 'the age-related facial features, health parameters and gene expression, as well as various agediffs (except faceplsagediff) all revealed a large heterogeneity of the ageing rate at middle age, with a bimodal distribution of the old and young patterns. this suggests that young and old are the alternative steady states, and middle age is a transition stage (fig. ',\n",
       " '), implying that middle age is the ideal stage for ageing interventions. incidentally, it also avoids the complications of growth/maturation in the young group and the impact of disease status in the older group, and supports ageing-related risk screening for middle-aged people, a target group in which the benefits of implementation of therapies are likely to outweigh the potential harms of screening',\n",
       " 'finally, by scrutinizing the lifestyle choices responsible for acceleration or deceleration of agediff and their potential molecular mediators in the blood, we found many potential causal associations between lifestyle, transcript and agediff.',\n",
       " 'overall, our analyses based on various age predictors show that humans age at different rates both in the blood and on the face, but coherently and with heterogeneity peaking at middle age. the differences can be attributed to different lifestyles, which through impacting circulating factors may affect facial morphology. more-accurate cnn-based predictors enabled more-sensitive and statistically robust discoveries of associations between facial features, health and lifestyle.',\n",
       " 'despite some obvious limitations in our current study that need to be addressed in future studies, such as that individuals of advanced age were not included, that only han chinese people were included and that the current model is based only on a high-resolution 3d imaging system, our study represents a step closer to the ultimate goal of identifying actionable lifestyle choices and their molecular mediators to target ageing. the ai technology we developed here aims to easily and widely monitor ageing rates, which will greatly benefit the ever-growing ageing populations and development of effective intervention strategies. however, as this system is based on facial images, the technology is not only sensitive in regard to personal identification but potentially can be abused for unintended purposes; hence, it should be carefully guarded against any unethical use. with an increased sample size, we expect that other lifestyle parameters, their molecular mediators and facial signatures will be discovered by the same type of study in the near future.',\n",
       " 'methods',\n",
       " '. approval was obtained from ethical committees of the staff hospital of jidong oil-field of china national petroleum corporation. the approval will be renewed every 5 years. written informed consent was obtained from each of the participants. the beijing study was approved by the ethics committee of the shanghai institutes for biological sciences, chinese academy of sciences. for the detailed recruitment procedure, please refer to the ',\n",
       " '). as a requirement, volunteers sat straight and looked forward to the 3dmdface device for 1\\u2009min, without any facial expression, for the 3d facial images to be taken. the 3dmdface system returned obj-formatted 3d facial surfaces with point clouds and corresponding texture images. also for each participant, baseline information including age, sex, education level, anthropometry and lifestyle factors (for example, frequency of smoking, alcohol drinking, diet and exercise) were collected from questionnaires, weight, height and blood pressure were measured and routine blood tests were done.',\n",
       " 'three-dimensional facial images, blood and routine physical indicators (full blood count, blood basic metabolic panel and anthropometry) were collected at beijing centers for diseases control and prevention (cdc) and centers for preventive medical research. all participants provided written informed consent prior to this study. all participants (han chinese people, 169 females and 163 males) in this study had no history of facial surgery or facial abnormalities. we used the 3dmdface system to capture 3d facial images of about 40,000 vertices per face. the detailed procedure of photography capture has been described in previous work',\n",
       " 'to compare human-perceived age and cnn-predicted age, we gathered 50 volunteers to evaluate the ages of all samples. we randomly shuffled the images and asked the volunteers to guess the ages of participants by looking at their facial images. each image was evaluated by 5.33 volunteers on average (at least 3 and no more than 6), and the average guess of the volunteers was used as the human-perceived age of each face.',\n",
       " 'birth dates were obtained by the chinese-government-issued official resident identity card. age was rounded to the nearest year for model training.',\n",
       " 'the 3d facial images were stored in the obj file format and with corresponding texture images. the obj-format file contains four types of information for a 3d face surface with ',\n",
       " ', representing coordinates of each point in the corresponding texture image; and (4) multiple lines starting with ‘f’ and three groups of integers, representing that these three indexes form a triangle, which further constitutes multiple triangle meshes in the 3d facial images.',\n",
       " 'the nose tip is the most salient and stable feature point on 3d facial images. we first detected the nose-tip point on a face using sphere fitting',\n",
       " ' to fit regions over the 3d face and took the point with the smallest least square difference as the nose-tip point. to calculate the least square of every point ',\n",
       " ' as the dependent variable. taking the derivatives of the least square loss function, we generated the solution for the regression. first, we transformed the regression problem into the matrix formula:',\n",
       " '$$\\\\left[ {\\\\begin{array}{*{20}{l}} {x_1} \\\\hfill & {y_1} \\\\hfill & {z_1} \\\\hfill & 1 \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_n} \\\\hfill & {y_n} \\\\hfill & {z_n} \\\\hfill & 1 \\\\hfill \\\\end{array}} \\\\right]\\\\left[ {\\\\begin{array}{*{20}{c}} {\\\\begin{array}{*{20}{c}} {2o_x} \\\\\\\\ {2o_y} \\\\\\\\ {2o_z} \\\\end{array}} \\\\\\\\ {r^2 - o_x^2 - o_y^2 - o_z^2} \\\\end{array}} \\\\right] = \\\\left[ {\\\\begin{array}{*{20}{c}} {x_1^2 + y_1^2 + y_1^2} \\\\\\\\ \\\\vdots \\\\\\\\ {x_n^2 + y_n^2 + y_n^2} \\\\end{array}} \\\\right]$$',\n",
       " '$$x = \\\\left[ {\\\\begin{array}{*{20}{l}} {x_1} \\\\hfill & {y_1} \\\\hfill & {z_1} \\\\hfill & 1 \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_n} \\\\hfill & {y_n} \\\\hfill & {z_n} \\\\hfill & 1 \\\\hfill \\\\end{array}} \\\\right]$$',\n",
       " ', we calculated the centre and the radius of the sphere, with which we calculated the least square loss of each point on the 3d face:',\n",
       " 'although the volunteers were asked to sit straight and look forward, there were still differences in poses among 3d faces, including looking slightly left or right looking and looking up or down. as we had already identified the location of the nose tip, we corrected the face pose using points around the nose tip. assuming that the coordinate of the nose tip was (',\n",
       " '$$x = \\\\left[ {\\\\begin{array}{*{20}{c}} {\\\\begin{array}{*{20}{c}} {p_1} \\\\\\\\ {p_2} \\\\\\\\ \\\\vdots \\\\end{array}} \\\\\\\\ {p_m} \\\\end{array}} \\\\right] = \\\\left[ {\\\\begin{array}{*{20}{l}} {x_1} \\\\hfill & {y_1} \\\\hfill & {z_1} \\\\hfill \\\\\\\\ {x_2} \\\\hfill & {y_2} \\\\hfill & {z_2} \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_m} \\\\hfill & {y_m} \\\\hfill & {z_m} \\\\hfill \\\\end{array}} \\\\right]$$',\n",
       " '$$x_1 = \\\\left[ {\\\\begin{array}{*{20}{l}} {x_1 - \\\\bar x} \\\\hfill & {y_1 - \\\\bar y} \\\\hfill & {z_1 - \\\\bar z} \\\\hfill \\\\\\\\ {x_2 - \\\\bar x} \\\\hfill & {y_2 - \\\\bar y} \\\\hfill & {z_2 - \\\\bar z} \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_m - \\\\bar x} \\\\hfill & {y_m - \\\\bar y} \\\\hfill & {z_m - \\\\bar z} \\\\hfill \\\\end{array}} \\\\right]$$',\n",
       " '$$c = \\\\left[ {\\\\begin{array}{*{20}{c}} {\\\\rm{cov}\\\\left( {x,x} \\\\right)} & {\\\\rm{cov}\\\\left( {x,y} \\\\right)} & {\\\\rm{cov}\\\\left( {x,z} \\\\right)} \\\\\\\\ {\\\\rm{cov}\\\\left( {x,y} \\\\right)} & {\\\\rm{cov}\\\\left( {y,y} \\\\right)} & {\\\\rm{cov}\\\\left( {y,z} \\\\right)} \\\\\\\\ {\\\\rm{cov}\\\\left( {x,z} \\\\right)} & {\\\\rm{cov}\\\\left( {y,z} \\\\right)} & {\\\\rm{cov}\\\\left( {z,z} \\\\right)} \\\\end{array}} \\\\right]$$',\n",
       " ' represent the direction of maximum variance of the data, which is the direction along the nose bridge. the second maximum eigenvalue ',\n",
       " ' represents the direction of second maximum variance of the data, which is the direction of the nose from left to right. the minimum eigenvalue ',\n",
       " ' represent the direction of minimum variance of the data, which is the direction from the inner part of the head to the outer part of the head along the eye sight direction. the direction of ',\n",
       " '$$u = \\\\left[ {\\\\begin{array}{*{20}{c}} {\\\\gamma _2} & {\\\\gamma _1} & {\\\\gamma _3} \\\\end{array}} \\\\right] = \\\\left[ {\\\\begin{array}{*{20}{c}} {\\\\gamma _{21}} & {\\\\gamma _{11}} & {\\\\gamma _{31}} \\\\\\\\ {\\\\gamma _{22}} & {\\\\gamma _{12}} & {\\\\gamma _{32}} \\\\\\\\ {\\\\gamma _{21}} & {\\\\gamma _{13}} & {\\\\gamma _{33}} \\\\end{array}} \\\\right]$$',\n",
       " ' buffer and scan line algorithms, with sampling resolution at 0.1\\u2009cm. all rgb pixel information was kept in the projected 2d facial image.',\n",
       " 'besides detecting the nose tip, we detected another six landmarks (outer corner of left eye, inner corner of left eye, outer corner of right eye, inner corner of right eye, left mouth corner and right mouth corner) on each face. we first annotated these 6 landmarks manually for 50 females and 50 males, and trained the machine-learning algorithm (pca) to recognize these landmarks. then, all 100 samples were projected onto the ',\n",
       " ' plane using the corresponding six landmarks. for each of the 6 landmarks, the outer corner of the left eye for example, blocks centred at the landmark of size 21 × 21 pixels were used to extract the rgb texture and depth information. then, for each landmark, feature vectors with 1,764 values were extracted to represent the landmark. the outer corners of the left eyes for all 100 samples were represented by feature vectors:',\n",
       " '$$x = \\\\left[ {\\\\begin{array}{*{20}{l}} {x_{11}} \\\\hfill & {x_{12}} \\\\hfill & \\\\cdots \\\\hfill & {x_{1m}} \\\\hfill \\\\\\\\ {x_{21}} \\\\hfill & {x_{22}} \\\\hfill & \\\\cdots \\\\hfill & {x_{2m}} \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\ddots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_{n1}} \\\\hfill & {x_{n2}} \\\\hfill & \\\\cdots \\\\hfill & {x_{nm}} \\\\hfill \\\\end{array}} \\\\right]$$',\n",
       " '$$x_1 = \\\\left[ {\\\\begin{array}{*{20}{l}} {x_{11} - \\\\overline {x_{ \\\\ast 1}} } \\\\hfill & {x_{12} - \\\\overline {x_{ \\\\ast 2}} } \\\\hfill & \\\\cdots \\\\hfill & {x_{1m} - \\\\overline {x_{ \\\\ast m}} } \\\\hfill \\\\\\\\ {x_{21} - \\\\overline {x_{ \\\\ast 1}} } \\\\hfill & {x_{22} - \\\\overline {x_{ \\\\ast 2}} } \\\\hfill & \\\\cdots \\\\hfill & {x_{2m} - \\\\overline {x_{ \\\\ast m}} } \\\\hfill \\\\\\\\ \\\\vdots \\\\hfill & \\\\vdots \\\\hfill & \\\\ddots \\\\hfill & \\\\vdots \\\\hfill \\\\\\\\ {x_{n1} - \\\\overline {x_{ \\\\ast 1}} } \\\\hfill & {x_{n2} - \\\\overline {x_{ \\\\ast 2}} } \\\\hfill & \\\\cdots \\\\hfill & {x_{nm} - \\\\overline {x_{ \\\\ast m}} } \\\\hfill \\\\end{array}} \\\\right]$$',\n",
       " ' is the index used to iterate through all the samples. similarly to the pose correction, we then calculated the covariance matrix of ',\n",
       " 'we could then easily reflect the 1,764 features of the outer corner of the left eye for 100 samples into the subspace. for other faces, to annotate the outer corner the of left eye, we reflected the features of all candidate points into the established subspace. then, we represented the coordinates of the candidate points in the subspace:',\n",
       " '$$x_{{{\\\\rm{test}}\\\\_{\\\\rm{new}}}} = u\\\\left( {x_{\\\\rm{test}} - \\\\left[ {\\\\begin{array}{*{20}{l}} {\\\\bar x_{ \\\\ast 1}} \\\\hfill & {\\\\bar x_{ \\\\ast 2}} \\\\hfill & \\\\cdots \\\\hfill & {\\\\bar x_{ \\\\ast m}} \\\\hfill \\\\end{array}} \\\\right]} \\\\right)$$',\n",
       " ' is the average vector in the training set. we next defined the distance between candidate points and the outer corners of the left eye in the training set with the following formula:',\n",
       " ' in the training set. the point that reached the smallest distance from the training set was regarded as the outer corner of the left eye in the test image. similar processes were applied to the other five landmarks.',\n",
       " 'in addition to the seven landmarks detected above (nose tip, outer corner of left eye, inner corner of left eye, outer corner of right eye, inner corner of right eye, left mouth corner and right mouth corner), we detected landmarks such as the chin point, upper lip point and lower lip point. we localized points of these landmarks on the 3d face on the basis of prior knowledge. for example, the upper lip point is below the nose tip, with ',\n",
       " 'axis local maximum, and with the high red colour intensity under it because the lips have higher red colour intensity than the face skin; similarly, the lower lip point is below the upper lip point, with ',\n",
       " '-axis local maximum, and with high red colour intensity above it; and the chin point is below the lower lip point, showing a small angle from the point to the points above and below.',\n",
       " 'all 3d facial images were first preprocessed for landmark detection, posture correction and registration. different 3d faces have different numbers of points and different sizes. on the 2d face, we used dlib (version 19.8.0)',\n",
       " ' to detect the left and right profiles of the face, and then cropped the faces according the profiles and landmarks, using the left- and right-most edges as left and right boundaries, with the bottom boundary set at the chin point and the upper boundary by the coordinates of the chin point and nose-tip point (assuming the ',\n",
       " '). during the final cropping of the image, we extended each boundary by 2 pixels, and the depth image was cropped at the same place. all rgb images and deep images were resized to 224 × 224 pixels before using deep learning.',\n",
       " 'to further improve our accuracy, we used an ensemble of three cnns, googlenet, vgg with 16 layers and resnet with 50 layers to predict age. we trained and generated the results of the three networks independently, and generated an ensemble by taking their average, with the formula ',\n",
       " 'for age prediction, we replaced the last layer of the three cnns with one node without any activation functions, and we used the mean absolute difference between the predicted age and actual age as the loss function:',\n",
       " 'during training of deep cnn models, we reflected all samples from left to right, which can increase the amount of training data.',\n",
       " 'to validate the prediction ability for age using 3d facial images, we divided all our 4,719 samples into 10 groups randomly for 10-fold cross-validation. during each evaluation process, the model was trained with eight of the ten groups as a training set, hyperparameters were determined with one of the remaining groups as the validation set and the predictive performance was tested on the last group as the test set. when evaluating the models with independent datasets, we used all ten models generated from the ten cross-validation to test the datasets independently, and used the average performance level as the final prediction capability.',\n",
       " 'we drew 10 ml of total fasting blood from each participant in the early morning. plasma and pbmcs were separated using a sigma-aldrich histopaque-1077 kit. rna was extracted with trizol (invitrogen) using the protocol provided by the manufacturer. samples with rna integrity number (rin) > 8 were processed with the illumina truseq stranded total rna with ribo-zero sample preparation kit and then sequenced on an illumina hiseq 2000 machine according to the manufacturer’s instructions. paired-end reads (126\\u2009bp) were mapped to the grch38 reference human genome using star9 version 2.4.0d.',\n",
       " 'only reads with a unique match to the reference genome were kept. protein-coding gene quantification was performed using gencode version 24 annotation',\n",
       " '), version 2.3.5) was used to predict exonic circrna. human pbmc ribo-minus paired-end rna-seq raw data were mapped to the hg38 human reference genome using tophat-fusion (implemented in tophat version 2.1.1), and then were parsed by circexplorer2 to obtain circrna back spliced junction reads. circrna read counts from all samples were merged together and scaled to tpm.',\n",
       " ' scaled) were combined into one matrix as the input. the leave-one-out (loo) method (predictors were trained using all but one sample and then used to predict the age of the left-out sample) was applied to obtain the age prediction of each sample. mad was calculated by the difference between predicted age and chronological age. saturation analysis was conducted by randomly selecting a designated percentage of all the samples and training the pls model on such samples, and then was evaluated using both mad and pcc.',\n",
       " 'to study age-independent associations of agediff, we corrected agediff by fitting to a polynomial model to age as follows, with span 0.75 and degree 2:',\n",
       " 'unlike other agediffs, there are significant differences between sexes in faceperceivedagediff and facecnnperceivedagediff (',\n",
       " 'a non-overlapping sliding-window approach was used to study the relationship between agediff sd and age. samples were sorted by age, and then a non-overlapping sliding window with different bin size (100 or 20 in jidong cohort, 20 or 10 in beijing cohort) was used to group samples and calculate mean of age and s.d. of agediffs in each sliding window.',\n",
       " ' were utilized for the term-enrichment test. kegg pathway genes were downloaded from the kegg database using the rest api. the cytokine genes were collected from the immport database',\n",
       " 'with the ‘pls’ package in r, the cell fraction or another feature was treated as the dependent variable, while the 3d facial images were treated as independent variables for pls regression. the loadings of the first two components weighed by the score of each component were combined and projected to the average 3d facial image synthesized from the whole cohort.',\n",
       " '. briefly, each of the lifestyle–gene expression–agediff relationships was tested separately to classify them into mediated by, consequential to or independent of gene expression. a causal inference met the following four criteria: (1) lifestyle and agediff were correlated; (2) lifestyle was associated with gene expression after adjusting for agediff; (3) gene expression was associated with agediff after adjusting for lifestyle; and (4) lifestyle was independent of agediff after adjusting for gene expression. to summarize the ',\n",
       " ') databases; (2) human transcription factors, enzymes, transporters, receptors and ion channels downloaded from the animal transcription factor database (',\n",
       " '. three-dimensional images and other metadata sensitive to personal identification cannot be publicized or shared according to our participant consent agreement. individual sequencing raw data, as they contain genetic information, will be available on request under the condition of approval of the ethics committee of shanghai institute of nutrition and health, chinese academy of sciences abiding china human genetic resource law. mapped read counts and fpkm expression values of coding genes from the rna-seq are deposited to the public repository node at ',\n",
       " 'methods',\n",
       " 'computer methods programs biomed.',\n",
       " 'nat. methods',\n",
       " 'liu, y. et al. epigenome-wide association data implicate dna methylation as an intermediary of genetic risk in rheumatoid arthritis. ',\n",
       " 'ahmed, z. et al. accelerated lipofuscinosis and ubiquitination in granulin knockout mice suggest a role for progranulin in successful aging. ',\n",
       " 'elkabets, m. et al. human tumors instigate granulin-expressing hematopoietic cells that promote malignancy by activating stromal fibroblasts in mice. ',\n",
       " 'chitramuthu, b. p., bennett, h. p. j. & bateman, a. progranulin: a new avenue towards the understanding and treatment of neurodegenerative disease. ',\n",
       " 'ruiz, r. et al. sterol regulatory element-binding protein-1 (srebp-1) is required to regulate glycogen synthesis and gluconeogenic gene expression in mouse liver. ',\n",
       " 'oishi, y. et al. srebp1 contributes to resolution of pro-inflammatory tlr4 signaling by reprogramming fatty acid metabolism. ',\n",
       " 'schoenborn, n. l. et al. preferred clinician communication about stopping cancer screening among older us adults: results from a national survey. ',\n",
       " 'world medical association inc declaration of helsinki. ethical principles for medical research involving human subjects. ',\n",
       " 'trapnell, c. et al. differential gene and transcript expression analysis of rna-seq experiments with tophat and cufflinks. ',\n",
       " 'subramanian, a. et al. gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. ',\n",
       " 'bhattacharya, s. et al. immport, toward repurposing of open access immunological assay data for translational and clinical research. ',\n",
       " 'coppé, j.-p., desprez, p.-y., krtolica, a. & campisi, j. the senescence-associated secretory phenotype: the dark side of tumor suppression. ',\n",
       " 'this work was supported by grants from the national natural science foundation of china (91749205), china ministry of science and technology (2016yfe0108700) and shanghai municipal science and technology major project (2017shzdzx01) to j.-d.j.h.',\n",
       " 'cas key laboratory of computational biology, cas-mpg partner institute for computational biology, shanghai institute of nutrition and health, chinese academy of sciences center for excellence in molecular cell science, collaborative innovation center for genetics and developmental biology, shanghai institutes for biological sciences, chinese academy of sciences, shanghai, china',\n",
       " 'xian xia,\\xa0xingwei chen,\\xa0gang wu,\\xa0fang li,\\xa0yiyang wang,\\xa0yang chen,\\xa0mingxu chen,\\xa0xinyu wang,\\xa0weiyang chen,\\xa0bo xian,\\xa0weizhong chen,\\xa0yaqiang cao,\\xa0chi xu,\\xa0wenxuan gong,\\xa0guoyu chen,\\xa0donghong cai,\\xa0yizhen yan\\xa0&\\xa0jing-dong j. han',\n",
       " 'peking-tsinghua center for life sciences, academy for advanced interdisciplinary studies, center for quantitative biology (cqb), peking university, beijing, china',\n",
       " 'xian xia,\\xa0xingwei chen,\\xa0yiyang wang,\\xa0yang chen,\\xa0mingxu chen,\\xa0xinyu wang,\\xa0wenxuan gong,\\xa0guoyu chen,\\xa0donghong cai,\\xa0yizhen yan,\\xa0kangping liu\\xa0&\\xa0jing-dong j. han',\n",
       " 'department of hepatic surgery, eastern hepatobiliary surgery hospital, second military medical university, shanghai, china',\n",
       " 'biomedical cybernetics group, biotechnology center (biotec), center for molecular and cellular bioengineering (cmcb), center for systems biology dresden (csbd), cluster of excellence physics of life (pol), department of physics, technische universität dresden, dresden, germany',\n",
       " 'center for complex network intelligence (ccni) at the tsinghua laboratory of brain and intelligence (thbi) and department of bioengineering, tsinghua university, beijing, china',\n",
       " 'clinical research institute, shanghai general hospital, shanghai jiao tong university school of medicine, shanghai, china',\n",
       " 'j.-d.j.h. conceived and designed the study and analyses. y.z. set up the cohort and designed and collected baseline data. c.v.c., together with j.d.j.h., conceived the paradigm-shift idea to train the cnn on perceived age instead of chronological age for an ai-based perceived-age predictor. x.x. and x.c. analysed the data, with help from y.w. and c.x. y. cao, w. wei, g.c. y.y., x.x., k.l. and d.c. helped in collecting and preprocessing data. n.q., x.z. and j.j. helped to set up gpu, ai systems and training. g.w. and f.l. performed the pbmc-isolation and rna-extraction experiments. weiyang chen provided faceplsage. b.x., weizhong chen, y. cao, c.x. and w.g. helped to recruit the beijing cohorts. g.c. quantified the wrinkle and symmetry on faces. y. chen analysed circrna. x.w., m.c. and d.c. helped with data analysis. x.x., x.c., j.d.j.h, c.v.c., k.z., b.k.k. and w. wang wrote the manuscript. all authors contributed to preparation of the manuscript. g.w., f.l. and y.w. contributed equally.',\n",
       " ' springer nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.',\n",
       " ', deep learning performance in training, validation and testing datasets for age prediction. average loss (mean average difference (mad), upper panel) and accuracy (pearson correlation coefficient (pcc), lower panel) were plotted over training epochs. one epoch indicates the network weights updates over the whole training dataset for one time. ',\n",
       " ', overlap between facecnnage, facecnnperceivedage, faceperceivedage, and faceplsage in younger (left), normal (middle), and older (right) samples. the lower table shows the one-tailed fisher’s exact test p-values with light red indicate p < 0.05. ',\n",
       " ', independent validation of facecnnage (c) and facecnnperceivedage (d) on 332 facial images collected in beijing, 2012 (left) and 358 facial images collected in beijing, 2015 (right).',\n",
       " ', the standard deviation of randomly guess a number between 20–85 (n=4719, the boxes show 25%, 50% and 75% quantile and whiskers show maximum and minimum value). ',\n",
       " ', relationship between age and the standard deviation of four agediffs with bin size as 20 in jidong cohort. data are presented as mean +/- sd. ',\n",
       " ', heatmap of aging-related facial features, health parameters and rnas in beijing (2012) cohort sorted by increasing chronological age (pcc with age, fdr < 0.05). features were ranked by pcc from low to high (alb: albumin, a/g: albumin/ globulin, tp: total protein, ggt: glutamyl transpeptidase, alp: alkline phosphatase, crea: creatinine, cho: total cholesterol). ',\n",
       " ', mean absolute difference (mad) (top panel), pearson correlation coefficient (pcc) (bottom panel) saturation analysis and correlation against chronological age of transcriptomes pls age prediction for all the samples (',\n",
       " ', enriched go biological processes terms of pls top 10% (upper) or 20% (lower) loading genes. p values are derived from hypergeometric test (methods). ',\n",
       " ', overlap between faceplsage, facecnnage, rnaplsage, and facecnnperceivedage in younger (left), normal (middle), and older (right) samples. the lower table shows the one-tailed fisher’s exact test p-values with light red highlight indicate p < 0.05.',\n",
       " ', cytokines (left panels) and antigen processing and presentation (right panels) enrichment scores as a function of four agediffs. p values are derived from permutation test (methods). ',\n",
       " ', association of rna-seq deconvoluted cell type fractions and agediffs (* p<0.1, ** p<0.05, *** p<0.01 derived from two-sided t test, and * benjamini-hochberg correction derived fdr < 0.1).',\n",
       " ', the heatmap of expressed lncrnas (fpkm > 2) significantly related to chronological age (fdr < 0.1). the samples (columns) were sorted by age and lncrnas were sorted by pcc of expression to age from high to low. ',\n",
       " ', the heatmap of expressed circrnas (tpm > 2) significantly related to chronological age (fdr < 0.1). the samples (columns) were sorted by age and circrnas were sorted by pcc of expression to age from high to low. ',\n",
       " ', top three enriched terms for parent genes of age-up (top) and age-down circrnas. p values are derived from hypergeometric test (methods). ',\n",
       " 'results',\n",
       " 'discussion',\n",
       " 'methods',\n",
       " 'methods',\n",
       " 'computer methods programs biomed.',\n",
       " 'nat. methods',\n",
       " 'liu, y. et al. epigenome-wide association data implicate dna methylation as an intermediary of genetic risk in rheumatoid arthritis. ',\n",
       " 'ahmed, z. et al. accelerated lipofuscinosis and ubiquitination in granulin knockout mice suggest a role for progranulin in successful aging. ',\n",
       " 'elkabets, m. et al. human tumors instigate granulin-expressing hematopoietic cells that promote malignancy by activating stromal fibroblasts in mice. ',\n",
       " 'chitramuthu, b. p., bennett, h. p. j. & bateman, a. progranulin: a new avenue towards the understanding and treatment of neurodegenerative disease. ',\n",
       " 'ruiz, r. et al. sterol regulatory element-binding protein-1 (srebp-1) is required to regulate glycogen synthesis and gluconeogenic gene expression in mouse liver. ',\n",
       " 'oishi, y. et al. srebp1 contributes to resolution of pro-inflammatory tlr4 signaling by reprogramming fatty acid metabolism. ',\n",
       " 'schoenborn, n. l. et al. preferred clinician communication about stopping cancer screening among older us adults: results from a national survey. ',\n",
       " 'world medical association inc declaration of helsinki. ethical principles for medical research involving human subjects. ',\n",
       " 'trapnell, c. et al. differential gene and transcript expression analysis of rna-seq experiments with tophat and cufflinks. ',\n",
       " 'subramanian, a. et al. gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. ',\n",
       " 'bhattacharya, s. et al. immport, toward repurposing of open access immunological assay data for translational and clinical research. ',\n",
       " 'coppé, j.-p., desprez, p.-y., krtolica, a. & campisi, j. the senescence-associated secretory phenotype: the dark side of tumor suppression. ',\n",
       " '(function(){var g=function(a){a=new customevent(\"campaigndataloaded\",{detail:a});document.dispatchevent(a);console.log(\"campaigndataloaded custom event dispatched from: \",document)},b=google_tag_manager[\"gtm-mrvxshq\"].macro(17);if(b){var k=1500;b=google_tag_manager[\"gtm-mrvxshq\"].macro(18);b=\"link\"===b?google_tag_manager[\"gtm-mrvxshq\"].macro(19):google_tag_manager[\"gtm-mrvxshq\"].macro(20);var m=function(a,c){var h=!1,l=settimeout(function(){h=!0;c(null)},k),d=new xmlhttprequest;d.onload=function(){var e=null,f=[];if(200===d.status){try{e=json.parse(d.responsetext)}catch(p){e={}}f=e.campaigns|| []}h||(cleartimeout(l),c(f.length?f.join(\",\"):null))};d.open(\"get\",\"/platform/contextual?doi\\\\x3d\"+a);d.send()},n=function(a,c){a&&-1===a.indexof(\"not set\")?m(a,c):settimeout(c,1)};n(b,function(a){console.log(\"data returned from campaign id api is: \",a);window.campaignsforcontextualads=a;g(a);window.datalayer.push({content:{article:{campaignid:a}}})})}else window.campaignsforcontextualads=\"\",g(null)})();',\n",
       " 'document.addeventlistener(\"accessdetailsloaded\",function(a){a=a.detail||{};var b={event:\"update-access-details\"};a.institutional_business_partner_ids&&a.resolved_by||console.error(\"bpid data could not be retrieved from /exposed-details\");var c=a.institutional_business_partner_ids&&a.institutional_business_partner_ids.join?a.institutional_business_partner_ids.join(\";\"):\"\",d=a.resolved_by&&a.resolved_by.join?a.resolved_by.join(\";\"):\"\";b.user={};b.user.profile={};b.user.profile.profileinfo={resolvedby:d|| null,bpid:c||null};b.session={};b.session.authentication={};b.session.authentication.token=a.token||null;b.session.authentication.legacy={};window.datalayer.push(b);window.idpuserdataloaded=!0},!1);window.datalayer.push({event:\"accessdetailsloaded-handler-added\"});window.accessdetailsloadedhandleradded=!0;',\n",
       " 'var s=document.getelementsbytagname(\"script\")[0],p=document.createelement(\"script\");p.async=\"async\";p.src=\"https://scripts.webcontentassessor.com/scripts/93dabb8d80079a87fec7bb6f67b807fce90e1688f8957ad7ad152bfd58ea01c2\";s.parentnode.insertbefore(p,s);',\n",
       " 'element.prototype.matches||(element.prototype.matches=element.prototype.matchesselector||element.prototype.mozmatchesselector||element.prototype.msmatchesselector||element.prototype.omatchesselector||element.prototype.webkitmatchesselector||function(a){a=(this.document||this.ownerdocument).queryselectorall(a);for(var b=a.length;0<=--b&&a.item(b)!==this;);return-1<b});',\n",
       " 'var scripts=document.head.queryselectorall(\"script[async]\");array.prototype.slice.call(scripts).foreach(function(a){-1<a.src.indexof(\"gtm.js\")&&(console.log(\"the gtm script has src url:\"),console.log(a.src))});console.log(\"the ga4serverurl is:\");console.log(google_tag_manager[\"gtm-mrvxshq\"].macro(28));',\n",
       " '(function(a){if(\"function\"===typeof window.customevent)return!1;var c=function(d,b){b=b||{};var e=document.createevent(\"customevent\");e.initcustomevent(d,b.bubbles||!1,b.cancelable||!1,b.detail||a);return e};c.prototype=window.event.prototype;window.customevent=c})();var parse=function(a,c){try{return 200===a?json.parse(c):null}catch(d){return null}},dispatch=function(a){a=new customevent(\"accessdetailsloaded\",{detail:a});document.dispatchevent(a)},site=google_tag_manager[\"gtm-mrvxshq\"].macro(33),idpurl; switch(site){case \"nature\":idpurl=-1<window.location.hostname.indexof(\"local-www\")||-1<window.location.hostname.indexof(\"test-www\")?\"https://staging-idp.nature.com/exposed-details\":\"https://idp.nature.com/exposed-details\";break;case \"link\":idpurl=-1<window.location.hostname.indexof(\"link-qa\")?\"https://staging-idp.springer.com/exposed-details\":\"https://idp.springer.com/exposed-details\";break;case \"springer\":idpurl=-1<window.location.hostname.indexof(\"local-www\")||-1<window.location.hostname.indexof(\"test-www\")? \"https://staging-idp.springer.com/exposed-details\":\"https://idp.springer.com/exposed-details\"}if(void 0!==idpurl){var transport=new xmlhttprequest;transport.open(\"get\",idpurl,!0);transport.withcredentials=!0;transport.onreadystatechange=function(){4===transport.readystate&&dispatch(parse(transport.status,transport.responsetext))};transport.send()}else dispatch(null);',\n",
       " 'function createandloadads(){function h(a){\"nature\"===b&&google_tag_manager[\"gtm-mrvxshq\"].macro(58)(a);\"bmc\"===b&&google_tag_manager[\"gtm-mrvxshq\"].macro(62)(a);(\"link\"===b&&\"oscar\"===google_tag_manager[\"gtm-mrvxshq\"].macro(63)||\"springer\"===b||\"link\"===b&&!0===google_tag_manager[\"gtm-mrvxshq\"].macro(64))&&google_tag_manager[\"gtm-mrvxshq\"].macro(80)(a);\"link\"===b&&\"bunsen\"===google_tag_manager[\"gtm-mrvxshq\"].macro(81)&&google_tag_manager[\"gtm-mrvxshq\"].macro(97)(a);\"link\"===b&&\"core\"===google_tag_manager[\"gtm-mrvxshq\"].macro(98)&&google_tag_manager[\"gtm-mrvxshq\"].macro(102)(a)}var b=google_tag_manager[\"gtm-mrvxshq\"].macro(103),c=google_tag_manager[\"gtm-mrvxshq\"].macro(105);if(-1===window.location.search.indexof(\"hide_ads\\\\x3dtrue\"))if(window.adslots&& 0!==object.keys(window.adslots).length)console.log(\"ads previously loaded. will not update ad slots until next page load.\");else{window.adslots||(window.adslots={});window.getad=function(a,f){for(var d in window.adslots)if(-1<d.indexof(a)){if(\"object\"===f)return adslots[d];if(\"slot\"===f)return adslots[d].slot}};googletag.cmd.push(function(){googletag.pubads().setprivacysettings({limitedads:c});console.log(\"limitedads is \",c);googletag.pubads().setrequestnonpersonalizedads(google_tag_manager[\"gtm-mrvxshq\"].macro(107)); console.log(\"setrequestnonpersonalizedads is \",google_tag_manager[\"gtm-mrvxshq\"].macro(109));googletag.pubads().enablesinglerequest();googletag.pubads().disableinitialload()});for(var g=document.queryselectorall(\"[data-gpt]\"),e=0;g[e];++e)h(g[e]);googletag.cmd.push(function(){googletag.enableservices()});googletag.cmd.push(function(){c&&document.dispatchevent(new customevent(\"displaylimitedads\"))})}}createandloadads();']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_text = []\n",
    "\n",
    "for x in body_text:\n",
    "    if (charchar(x) and alphachars(x)) and (istitle(x) or istextblock(x)):\n",
    "        keep_text.append(x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "keep_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "455c0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbracketcount(x): return x.count('{') < 4\n",
    "def rbracketcount(x): return x.count('}') < 4\n",
    "def tagcount(x): return x.count('\".\"') < 4\n",
    "def hashcount(x): return x.count('#') < 4\n",
    "def divcount(x): return x.count('</') < 4\n",
    "def linecount(x): return x.count('||') < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc6b934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' we use cookies to make sure that our website works properly, as well as some ‘optional’ cookies to personalise content and advertising, provide social media features and analyse how people use our site. by accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the european economic area that do not offer the same data protection standards as the country where you live. you can decide which optional cookies to accept by clicking on ‘manage settings’, where you can also find more information about how your personal data is processed.  further information can be found in our ',\n",
       " 'thank you for visiting nature.com. you are using a browser version with limited support for css. to obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in internet explorer). in the meantime, to ensure continued support, we are displaying the site without styles and javascript.',\n",
       " 'show results from',\n",
       " 'not all individuals age at the same rate. methods such as the ‘methylation clock’ are invasive, rely on expensive assays of tissue samples and infer the ageing rate by training on chronological age, which is used as a reference for prediction errors. here, we develop models based on convoluted neural networks through training on non-invasive three-dimensional (3d) facial images of approximately 5,000 han chinese individuals that achieve an average difference between chronological or perceived age and predicted age of ±2.8 and 2.9 yr, respectively. we further profile blood transcriptomes from 280 individuals and infer the molecular regulators mediating the impact of lifestyle on the facial-ageing rate through a causal-inference model. these relationships have been deposited and visualized in the human blood gene expression—3d facial image (hub-fi) database. overall, we find that humans age at different rates both in the blood and in the face, but do so coherently and with heterogeneity peaking at middle age. our study provides an example of how artificial intelligence can be leveraged to determine the perceived age of humans as a marker of biological age, while no longer relying on prediction errors of chronological age, and to estimate the heterogeneity of ageing rates within a population.',\n",
       " 'ageing is a major risk factor for many complex human diseases. rates of biological ageing are highly variable among individuals of the same chronological age. to quantify ageing, ideally, biological age rather than chronological age should be assessed; however, because of the lack of a gold standard for biological age, the population average of chronological age is often assumed to be the standard of biological age. the deviators or outliers of the average or standard curve are defined and often substantiated as fast or slow agers by other physiological or molecular parameters. on the basis of this assumption, many methods have been developed to quantify ageing. for example, predicting age using the transcriptome in human peripheral blood has a mean absolute difference (mad) between chronological age and predicted biological age of 7.8 yr (ref. ',\n",
       " '. however, because the transcriptome, dna methylome and proteome have to be measured in blood cells or other tissues, invasiveness and high costs preclude their application to large-scale screens and routine physical examinations.',\n",
       " 'facial images have been used in traditional chinese medicine as a major diagnosis tool for evaluating health and disease status. this practice originated more than 2,000 years ago',\n",
       " '. our previous work has established 3d human facial image as an ageing marker, generated a partial least squares regression (plsr) model and used the difference between chronological and predicted age (agediff) to identify outliers in the ageing rate',\n",
       " ', but no biological process has been directly linked to differential ageing rates (or agediff) across individuals. indeed, the ageing rate might be associated with a subset of ageing-related changes that are more modifiable by environment, diet, lifestyle or variations in genetic background across different individuals than the genetically hardcoded programme that is fatefully played out for a species. thus, an understanding of the molecular events contributing to agediff is actionable and pertinent to understanding healthy ageing.',\n",
       " '. benefiting from these highly efficient cnn architectures, we trained three classic cnns (inception, visual geometry group (vgg) and resnet) using the large datasets in imagenet. we then applied them to 3d facial images from a large cohort of 4,719 individuals so they could learn age by transfer learning. in combining the results from the 3 cnns, the accuracy of age and perceived-age prediction reached a mad of 2.79 and 2.90 yr, respectively. this allowed us to examine ageing-rate heterogeneity across individuals during ageing, which was otherwise missed by our previous linear plsr model. our cnn for perceived-age prediction is designed to learn a representation of biological age instead of chronological age, which is supported by its detection of much-stronger associations of lifestyle and health parameters with ageing than those found by a chronological-age predictor. we used a statistical test',\n",
       " ', coupled with peripheral blood mononuclear cell (pbmc) transcriptome analysis, and built a causal-inference network that reveals circulation factors mediating lifestyle impacts on facial morphologies from blood transcriptomes. we deposited and visualized the associations and inferred causal relationships in the hub-fi (',\n",
       " 'results',\n",
       " 'to construct a highly accurate age-estimating model from 3d facial images, we collected 4,719 facial images from han chinese individuals in north china (jidong) with the 3dmdface system, together with corresponding age, sex, physical-examination and questionnaire information (supplementary table ',\n",
       " '). we developed a fully automated pipeline for analysis of 3d facial images, including pose correction, landmark identification and projection of depth and red, green and blue (rgb) colour of a 3d image onto two-dimensional (2d) images with four channels, for face registration and deep learning. we then used these 2d images to train the cnn model to predict chronological age (facecnnage) (fig. ',\n",
       " 'methods',\n",
       " 'methods',\n",
       " '). because a cnn trained on chronological age by optimizing prediction accuracy for chronological age might not be optimized to detect biological age, we trained another cnn model to predict perceived age, which might better reflect the health state',\n",
       " ', termed facecnnperceivedage. this model also achieved a high accuracy, with a mad of 2.90 yr for perceived age and 4.10 yr for chronological age (fig. ',\n",
       " '). we then examined the consistency of agediffs or outliers (|agediff| > mad) given by different models and found that they are highly correlated (supplementary table ',\n",
       " ', the large amount of imaging data we collected and the fully automated pipeline for analysis of 3d facial images (landmark identification and face registration) we developed here enabled us to train cnns to predict chronological and perceived age in a cohort of 4,719 individuals (jidong) by cross-validation and by validation in two independent cohorts of ~300 individuals each (beijing 2012 and beijing 2015). the imagenet pretrained weights of inception (inception_v1), vgg (vgg_16) and resnet (resnet_50) were transferred to learn age or perceived age. average faces of the cohort are used for illustration. ageing rate, as defined by predicted versus chronological age (agediff), was examined for associations with health and lifestyle in the jidong cohort. ribo-minus rna-seq of blood pbmcs was generated for the beijing 2012 cohort, and was used to infer the molecular mediators of lifestyle impact on ageing-rate variations. ',\n",
       " ', association-strength network of 4 agediffs and health parameters, corrected for chronological age, filtered by fdr\\u2009<\\u20090.1. bmd, bone mineral density; dbp, diastolic blood pressure; sbp, systolic blood pressure; bmi, body mass index; neccir, neck circumference; abdcir, abdominal circumference; wstcir, waist circumference; hipcir, hip circumference; cr, creatinine; akp, alkaline phosphatase; alt, alanine aminotransfersase; ast, aspartate transaminase; tc, total cholesterol; apoa, apolipoprotein a; apob, apolipoprotein b; gt, transglutaminase; fbg, fasting blood glucose; ldl, low-density lipoprotein; tg, triglycerides. ',\n",
       " ', association network between lifestyle and agediffs in the jidong cohort. edges are filtered by fdr\\u2009<\\u20090.1. smoking, smoker or non-smoker; cignumber, average number of cigarettes per day; cigpasyear, number of years of passive smoking; snorefreq, frequency of snoring per week; snoresound, whether the sound of a snore is louder than speaking voice; snoreapnoea: whether snoring is coupled with apnoea; alchohol, average intake of alcohol per day; salt, average intake of salt per day; dyehair, whether have hair dyed in the last three months; fruit, frequency of consuming fruits; vegetable, frequency of consuming vegetables; dair, frequency of consuming dairy products; exhighmin, average length of vigorous exercise per day.',\n",
       " 'to validate the cnn models in independent cohorts, we predicted the ages of people in 332 images from the 2012 beijing cohort (supplementary table ',\n",
       " '; these images have only half the resolution of those in the other cohorts) and in 358 images from the 2015 beijing cohort (supplementary table ',\n",
       " ') with the cnn models that learnt from the large jidong cohort. we achieved a mad of 3.85 yr for data collected in 2012 and of 3.92 yr for data collected in 2015 for facecnnage, and a mad of 6.66 yr for 2012 and of 4.12 yr for 2015 for facecnnperceivedage (extended data fig. ',\n",
       " '). as a comparison, the pls model achieved mad\\u2009=\\u20096.15 and 4.81 yr for the 2012 and 2015 beijing cohorts, respectively. these results suggest that the cnn models achieve superior accuracy not only over all other linear models by cross-validation in the same cohort but also in at least two other independent cohorts. it should be noted that, due to the small sample sizes of the beijing cohorts, we could not do the opposite, that is train the cnn models on the beijing cohorts and validate them on the jidong cohort.',\n",
       " 'to examine the biological relevance of agediffs, we next examined the association of agediffs with health parameters corrected for age (false-discovery rate (fdr)\\u2009<\\u20090.1) in the jidong cohort. indices related to obesity, blood pressure, transglutaminase, alkaline phosphatase and cholesterol were among the factors that were most strongly associated with all agediffs, whereas bone mineral density and creatinine were significantly negatively associated with three out of four agediffs. interestingly, among all four agediffs, facecnnperceivedagediff associated with remarkably more health parameters than other agediffs did (fig. ',\n",
       " '), indicating that it could be a superior predictor of health, even when compared with the model’s training data—human-perceived age.',\n",
       " 'to uncover the associations of lifestyles factors with differential ageing rates, we determined the association between quantitative lifestyle parameters with agediffs in the jidong cohort. smoking, number of cigarettes and years of passive smoking were linked to all four agediffs as the factors that most strongly increased the ageing rate. frequency of snoring, sound of snoring and apnoea during snoring were linked to all but faceplsagediff. among factors that decreased the ageing rate, dairy intake was linked to all four agediffs. the associations identified by facecnnperceivedagediff essentially captured all those found by facecnnagediff or by faceperceivedagediff, but captured a greater number of associations (fig. ',\n",
       " '). this suggests that both are optimized to accurately detect the ageing rate, with facecnnperceivedagediff being a better estimate of the biological ageing rate than all other age predictors are, including perceived age itself. similar associations can be observed in the smaller beijing 2012 cohort (extended data fig. ',\n",
       " 'in contrast to the s.d. expected from randomly guessing a number between 20–85, which is highest at young and old age (extended data fig. ',\n",
       " '), the heterogeneity of the ageing rate precisely captured by facecnnagediff and facecnnperceivedagediff peaked at middle age (fig. ',\n",
       " '). faceperceivedagediff also peaked at middle age, although it plateaued afterwards in males. faceplsagediff, however, is very different in that it shows a monotonic increase in s.d. with increasing chronological age and an s.d. that appears random at old age. these patterns are insensitive to the bin size (moving window) (',\n",
       " 'methods',\n",
       " '). similar patterns can be observed in the smaller beijing cohort. using broken-stick regression to pinpoint the breakpoint in the regression line, we found that all four agediffs predominately show a breakpoint peaking at middle age (extended data fig. ',\n",
       " ', heatmap of facial features in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1 in females and in males). features are ranked by pcc from lowest to highest in females and in males. ',\n",
       " ', a heatmap of health parameters in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1). features are ordered as in ',\n",
       " 'previous findings show that for human brain ageing transcriptomes, unlike those of very young or very old individuals, middle-aged individuals display high heterogeneity',\n",
       " '. we observed a similar pattern when all samples were visualized by a heatmap of age-related quantitative facial features (fig. ',\n",
       " 'using the cohort that we collected from the beijing area (beijing 2012), we extracted and sequenced the ribo-minus rna from pbmcs of 280 individuals with matching 3d facial images (supplementary table ',\n",
       " '). we performed plsr analysis on transcriptomes to predict chronological age in the same way that we did for 3d facial images',\n",
       " '). like the s.d. of agediff detected by cnn in both the large and the small cohort, rnaplsagediff in this small cohort peaked at middle age (around 40–50 yr old) (extended data fig. ',\n",
       " '). similarly, with broken-stick regression, we found that all four agediffs predominately showed a breakpoint peaking at middle age in the beijing 2012 cohort (extended data fig. ',\n",
       " 'we also applied the facecnnage and facecnnperceivedage cnn models that learnt from the large jidong cohort to the 280 samples and compared them with plsr-derived models faceplsage (trained on the 280 3d facial images) and rnaplsage. despite being derived from different machine-learning algorithms, different training sets and different data types, the agediffs predicted by various models significantly correlated with each other, with higher correlation of rna with cnn-based models than with the facial pls model (supplementary table ',\n",
       " '). moreover, the outliers identified by rnaplsage significantly overlapped with the two cnn-based models in both fast and slow agers (',\n",
       " 'to identify the blood transcriptome differences associated with differential facial-ageing rates, we compared the kyoto encyclopedia of genes and genomes (kegg) pathways with gene expression that was correlated with at least two of the four estimated agediffs or with age (fig. ',\n",
       " '). among pathways positively correlated with agediffs (fdr\\u2009<\\u20090.1), most were also positively correlated with age and inflammation, such as those linked to ',\n",
       " ', salmonella infection and shigellosis. and, similarly to age, agediffs tended to be consistently negatively correlated with biogenesis of ribosome and transfer rna. although all four agediffs were uncorrelated with chronological age after age correction, the molecular pathways that correlated with age and the four agediffs were largely consistent, indicating that the acceleration or deceleration of ageing detected by agediffs measurements is largely consistent with the ageing process at the pathway level.',\n",
       " ', distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on monocyte number derived from haematology analyser (two-sided ',\n",
       " ', distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on deconvoluted naive cd4',\n",
       " ', distribution of facecnnagediff (left) or facecnnperceivedagediff (middle) between the top and bottom 10% of samples on mcv (two-sided ',\n",
       " 'we then sought to further verify the agediff–inflammation association by examining whether inflammatory gene sets are positively related to agediffs. cytokine expression was positively related to faceplsagediff, rnaplsagediff and facecnnagediff (kolmogorov–smirnov (ks) test, nominal ',\n",
       " '\\u2009<\\u20090.05), but not facecnnperceivedagediff. innate-immunity-related genes, such as those linked to antigen processing and presentation, were positively related to all four agediffs (ks test, extended data fig. ',\n",
       " '). in summary, all four agediffs were significantly positively related to inflammation and innate-immunity processes, which are also important features of ageing per se.',\n",
       " ', we found that the monocyte fraction was significantly positively associated with faceplsagediff, and the direction was consistent, although not significant, with its association with the other three agediffs across all individuals (extended data fig. ',\n",
       " '). the plsr components 1 and 2 of 3d facial images regressed to monocyte fractions most significantly mapped to shrinkage of the forehead (fig. ',\n",
       " '), which is in agreement with the negative association between inflammatory biomarkers, including interleukin-6, osteoprotegerin and tumour necrosis factor-α, and brain volume as measured by magnetic resonance imaging',\n",
       " ' t cells were consistently negatively associated with all four agediffs, although the association was significant for only faceplsagediff and for rnaplsagediff (fig. ',\n",
       " '). the plsr components 1 and 2 of 3d facial changes to this cell fraction showed mapping to a reduction of under-eye puffiness (fig. ',\n",
       " 'in addition, both cnn-derived agediffs were significantly associated with the mean corpuscular volume of erythrocytes (mcv), a known chronic-illness indicator that is positively associated with ageing',\n",
       " ', between more-extreme samples (compared between the top and bottom 10% of samples; the association was marginal if the comparison was between the top and bottom 20% of samples). the facial pattern was similar to that associated with the monocyte fraction (fig. ',\n",
       " 'our parallel measurement of lifestyles, blood cell transcriptome and agediffs for the same individuals in the beijing 2012 cohort offered an opportunity to examine the molecular mediators of the impact of lifestyle on facial agediff. we thus generated a tripartite network of lifestyle–transcriptome–agediff using a causal-inference framework',\n",
       " ' querying all transcriptome clusters, encode transcription factors, signalling and epigenetic factors and cytokines as potential mediators (',\n",
       " 'methods',\n",
       " ' was also inferred to be a mediator by which alcohol drinking (measured in ‘drunkenness days per week’) increased facecnnagediff. zz-type zinc-finger-containing protein 3 (encoded by ',\n",
       " '), involved in chromatin organization, was inferred to be the mediator of yoghurt’s negative effect on facecnnagediff, and to lower ',\n",
       " ' to negatively affect facecnnperceivedagediff. rnaplsagediff had its own separate subnetwork, in which consumption of stem and root crops (for example, potato) were positively related to rnaplsagediff, mediated by tumour protein p53 (encoded by ',\n",
       " '\\u2009<\\u20090.05 and fdr\\u2009<\\u20090.1). interestingly, semaphorin is a chemokine, while granulin (cleaved from grn, the granulin precursor) is also a secreted factor playing important roles in the development of the central nervous system',\n",
       " '. overall, the network can be partitioned into four modules on the basis of connectivity density: the first, mostly affecting faceplsagediff and partially affecting facecnnagediff, is enriched for proteolysis; the second, mostly affecting facecnnagediff, is enriched for glycoprotein, protease and lysosome; the third, mostly affecting facecnnagediff, is enriched for transmembrane proteins and zinc-finger transcription factors; and the fourth, exclusively affecting rnaplsagediff, is enriched for response to antibiotics and ultraviolet radiation (fig. ',\n",
       " 'methods',\n",
       " ') from lifestyle factors to agediffs via molecular mediators (transcription factors, cytokines, regulatory genes and commonly expressed non-coding rnas) among all samples (',\n",
       " 'ribo-minus rna sequencing (rna-seq) allowed us to simultaneously examine coding and non-coding rna changes during human ageing. we found 935 long non-coding rnas (lncrnas) that were commonly expressed (fragments per kilobase of transcript per million reads mapped (fpkm)\\u2009>\\u20092) in at least a quarter of samples. among them, 62 and 210 were up- and downregulated by age, respectively (fdr\\u2009<\\u20090.1) (extended data fig. ',\n",
       " '). we found 5,002 circular rnas (circrnas) commonly expressed (transcripts per million (tpm)\\u2009>\\u20092) in at least a quarter of samples. among them, 41 and 8 were up- and downregulated with age, respectively (fdr\\u2009<\\u20090.1) (extended data fig. ',\n",
       " ', total circrna level shows no significant association with agediffs, implicating it to more likely be a consequence of ageing.',\n",
       " 'we applied the same causal-inference approach to only the outliers defined by all four agediffs because we assumed that some associations might be significant only in more-extreme samples. indeed, we found a very different set of associations among the outliers as compared with those of the whole cohort. ice-cream intake was inferred to be positively related to faceplsagediff through two circrnas and to facecnnagediff through ae binding protein 1 (encoded by ',\n",
       " '). yoghurt was negatively related to facecnnagediff and facecnnperceivedagediff through a few lncrnas and circrnas among the outliers (',\n",
       " 'to facilitate the full utilization of this dataset, we developed the hub-fi database for querying and visualizing health status and transcript changes associated with facial-ageing features, and the impacts of different lifestyles.',\n",
       " 'discussion',\n",
       " 'in this study, we developed deep-learning cnn models that made age predictions based on high-resolution 3d facial images with high accuracy in a large cohort of ~5,000 people. cnn models identified a larger number of associations, that were stronger in significance, of ageing with health parameters and lifestyles, demonstrating that these models are a high-accuracy method for estimation of the ageing rate that can be complementary to other methods. despite there being relatively fewer samples of very old ages (>70 yr) included for age prediction in our work, we consistently found many lifestyle and health parameters associated with various agediffs, in particular the agediff given by the artificial intelligence (ai)-based perceived-age predictor (facecnnperceivedagediff). the observation that the ai model often outperforms the pls model is probably because the ai predictor is less sensitive to imbalanced data structures. in fact, facecnnperceivedagediff not only is associated with many more health parameters but also is more highly significantly associated with blood pressure than are the other three agediffs (supplementary table ',\n",
       " '). this suggests that our age predictors, in particular the ai-based predictor of perceived age, are superior health estimators. unlike using chronological age in machine learning, the unique advantage of using perceived age as a health biomarker has been illustrated before by the christensen group in danish twins',\n",
       " '. here, we trained an ai predictor to learn how humans perceive other people’s ages, which reliably captured human perception and even corrected some human errors through regularization, hence generating a health predictor that is even more accurate than perceived age (the training standards). although cnns could give a much more accurate prediction of chronological age by optimizing chronological-age prediction, such prediction might ignore the deviations of biological age from chronological age. this is partially circumvented by training the cnn to learn perceived age, even though perceived age may not be a true reflection of biological age. the perceivedage s.d. generally increased with chronological age (pcc = 0.248, ',\n",
       " '). this is perhaps because the judges of age were all young people who are not accustomed to judging older people’s ages from experience, and even by random guessing, a larger number (representing age in this case) will have a larger range of variance than a smaller number will. however, although the pls model does not predict chronological age as accurately as the cnn does, its simplicity may capture certain aspects of biological age that are ignored by the cnn. future studies of a panel of gold standards of biological age will allow cnns to be trained to specifically estimate biological age, and a better judgement to be made of the utility of different models for predicting biological age.',\n",
       " 'as for the specific pipeline and parameters we chose in this study, we first tested the most widely used cnn architectures, googlenet, vgg with 16 layers and resnet with 50 layers. we found very similar performance between resnet with 101, 152 and 200 layers and resnet with 50 layers. therefore, in the final model, we included in the ensemble the results of only resnet with 50 layers. using just rgb images, the deep cnn models could predict age with high accuracy, with a mad of 2.90 yr when using googlenet, a mad of 3.27 yr when using vgg and a mad of 3.13 yr when using resnet. similarly, we also predicted age with only depth information, which produced a mad of 3.50 yr when using googlenet, a mad of 3.75 yr when using vgg and a mad of 3.70 yr when using resnet. an ensemble of the three cnns reaches a mad of 2.82 yr for rgb images and a mad of 3.35 yr for depth images. the final ensemble of the rgb and depth images yielded our reported mad of 2.79 yr.',\n",
       " 'we further collected parallel data from 280 han chinese individuals in beijing. we applied the cnn models trained on the large cohort to this smaller cohort and compared them with linear facial-image and transcriptome-age prediction models derived from the small cohort. outliers identified by all four agediffs significantly overlapped (',\n",
       " 'at the functional level, high agediffs all converged on the upregulation of inflammation and innate-immunity function, which is also supported by the upregulation of monocyte counts, a major player in innate immunity, and mcv, an indicator of chronic illness. our analysis highlights the functional similarity between rna-derived and 3d-facial-image-derived agediffs not only at the molecular and functional level, but also at the cellular level.',\n",
       " 'the age-related facial features, health parameters and gene expression, as well as various agediffs (except faceplsagediff) all revealed a large heterogeneity of the ageing rate at middle age, with a bimodal distribution of the old and young patterns. this suggests that young and old are the alternative steady states, and middle age is a transition stage (fig. ',\n",
       " '), implying that middle age is the ideal stage for ageing interventions. incidentally, it also avoids the complications of growth/maturation in the young group and the impact of disease status in the older group, and supports ageing-related risk screening for middle-aged people, a target group in which the benefits of implementation of therapies are likely to outweigh the potential harms of screening',\n",
       " 'finally, by scrutinizing the lifestyle choices responsible for acceleration or deceleration of agediff and their potential molecular mediators in the blood, we found many potential causal associations between lifestyle, transcript and agediff.',\n",
       " 'overall, our analyses based on various age predictors show that humans age at different rates both in the blood and on the face, but coherently and with heterogeneity peaking at middle age. the differences can be attributed to different lifestyles, which through impacting circulating factors may affect facial morphology. more-accurate cnn-based predictors enabled more-sensitive and statistically robust discoveries of associations between facial features, health and lifestyle.',\n",
       " 'despite some obvious limitations in our current study that need to be addressed in future studies, such as that individuals of advanced age were not included, that only han chinese people were included and that the current model is based only on a high-resolution 3d imaging system, our study represents a step closer to the ultimate goal of identifying actionable lifestyle choices and their molecular mediators to target ageing. the ai technology we developed here aims to easily and widely monitor ageing rates, which will greatly benefit the ever-growing ageing populations and development of effective intervention strategies. however, as this system is based on facial images, the technology is not only sensitive in regard to personal identification but potentially can be abused for unintended purposes; hence, it should be carefully guarded against any unethical use. with an increased sample size, we expect that other lifestyle parameters, their molecular mediators and facial signatures will be discovered by the same type of study in the near future.',\n",
       " 'methods',\n",
       " '. approval was obtained from ethical committees of the staff hospital of jidong oil-field of china national petroleum corporation. the approval will be renewed every 5 years. written informed consent was obtained from each of the participants. the beijing study was approved by the ethics committee of the shanghai institutes for biological sciences, chinese academy of sciences. for the detailed recruitment procedure, please refer to the ',\n",
       " '). as a requirement, volunteers sat straight and looked forward to the 3dmdface device for 1\\u2009min, without any facial expression, for the 3d facial images to be taken. the 3dmdface system returned obj-formatted 3d facial surfaces with point clouds and corresponding texture images. also for each participant, baseline information including age, sex, education level, anthropometry and lifestyle factors (for example, frequency of smoking, alcohol drinking, diet and exercise) were collected from questionnaires, weight, height and blood pressure were measured and routine blood tests were done.',\n",
       " 'three-dimensional facial images, blood and routine physical indicators (full blood count, blood basic metabolic panel and anthropometry) were collected at beijing centers for diseases control and prevention (cdc) and centers for preventive medical research. all participants provided written informed consent prior to this study. all participants (han chinese people, 169 females and 163 males) in this study had no history of facial surgery or facial abnormalities. we used the 3dmdface system to capture 3d facial images of about 40,000 vertices per face. the detailed procedure of photography capture has been described in previous work',\n",
       " 'to compare human-perceived age and cnn-predicted age, we gathered 50 volunteers to evaluate the ages of all samples. we randomly shuffled the images and asked the volunteers to guess the ages of participants by looking at their facial images. each image was evaluated by 5.33 volunteers on average (at least 3 and no more than 6), and the average guess of the volunteers was used as the human-perceived age of each face.',\n",
       " 'birth dates were obtained by the chinese-government-issued official resident identity card. age was rounded to the nearest year for model training.',\n",
       " 'the 3d facial images were stored in the obj file format and with corresponding texture images. the obj-format file contains four types of information for a 3d face surface with ',\n",
       " ', representing coordinates of each point in the corresponding texture image; and (4) multiple lines starting with ‘f’ and three groups of integers, representing that these three indexes form a triangle, which further constitutes multiple triangle meshes in the 3d facial images.',\n",
       " 'the nose tip is the most salient and stable feature point on 3d facial images. we first detected the nose-tip point on a face using sphere fitting',\n",
       " ' to fit regions over the 3d face and took the point with the smallest least square difference as the nose-tip point. to calculate the least square of every point ',\n",
       " ' as the dependent variable. taking the derivatives of the least square loss function, we generated the solution for the regression. first, we transformed the regression problem into the matrix formula:',\n",
       " ', we calculated the centre and the radius of the sphere, with which we calculated the least square loss of each point on the 3d face:',\n",
       " 'although the volunteers were asked to sit straight and look forward, there were still differences in poses among 3d faces, including looking slightly left or right looking and looking up or down. as we had already identified the location of the nose tip, we corrected the face pose using points around the nose tip. assuming that the coordinate of the nose tip was (',\n",
       " ' represent the direction of maximum variance of the data, which is the direction along the nose bridge. the second maximum eigenvalue ',\n",
       " ' represents the direction of second maximum variance of the data, which is the direction of the nose from left to right. the minimum eigenvalue ',\n",
       " ' represent the direction of minimum variance of the data, which is the direction from the inner part of the head to the outer part of the head along the eye sight direction. the direction of ',\n",
       " ' buffer and scan line algorithms, with sampling resolution at 0.1\\u2009cm. all rgb pixel information was kept in the projected 2d facial image.',\n",
       " 'besides detecting the nose tip, we detected another six landmarks (outer corner of left eye, inner corner of left eye, outer corner of right eye, inner corner of right eye, left mouth corner and right mouth corner) on each face. we first annotated these 6 landmarks manually for 50 females and 50 males, and trained the machine-learning algorithm (pca) to recognize these landmarks. then, all 100 samples were projected onto the ',\n",
       " ' plane using the corresponding six landmarks. for each of the 6 landmarks, the outer corner of the left eye for example, blocks centred at the landmark of size 21 × 21 pixels were used to extract the rgb texture and depth information. then, for each landmark, feature vectors with 1,764 values were extracted to represent the landmark. the outer corners of the left eyes for all 100 samples were represented by feature vectors:',\n",
       " ' is the index used to iterate through all the samples. similarly to the pose correction, we then calculated the covariance matrix of ',\n",
       " 'we could then easily reflect the 1,764 features of the outer corner of the left eye for 100 samples into the subspace. for other faces, to annotate the outer corner the of left eye, we reflected the features of all candidate points into the established subspace. then, we represented the coordinates of the candidate points in the subspace:',\n",
       " ' is the average vector in the training set. we next defined the distance between candidate points and the outer corners of the left eye in the training set with the following formula:',\n",
       " ' in the training set. the point that reached the smallest distance from the training set was regarded as the outer corner of the left eye in the test image. similar processes were applied to the other five landmarks.',\n",
       " 'in addition to the seven landmarks detected above (nose tip, outer corner of left eye, inner corner of left eye, outer corner of right eye, inner corner of right eye, left mouth corner and right mouth corner), we detected landmarks such as the chin point, upper lip point and lower lip point. we localized points of these landmarks on the 3d face on the basis of prior knowledge. for example, the upper lip point is below the nose tip, with ',\n",
       " 'axis local maximum, and with the high red colour intensity under it because the lips have higher red colour intensity than the face skin; similarly, the lower lip point is below the upper lip point, with ',\n",
       " '-axis local maximum, and with high red colour intensity above it; and the chin point is below the lower lip point, showing a small angle from the point to the points above and below.',\n",
       " 'all 3d facial images were first preprocessed for landmark detection, posture correction and registration. different 3d faces have different numbers of points and different sizes. on the 2d face, we used dlib (version 19.8.0)',\n",
       " ' to detect the left and right profiles of the face, and then cropped the faces according the profiles and landmarks, using the left- and right-most edges as left and right boundaries, with the bottom boundary set at the chin point and the upper boundary by the coordinates of the chin point and nose-tip point (assuming the ',\n",
       " '). during the final cropping of the image, we extended each boundary by 2 pixels, and the depth image was cropped at the same place. all rgb images and deep images were resized to 224 × 224 pixels before using deep learning.',\n",
       " 'to further improve our accuracy, we used an ensemble of three cnns, googlenet, vgg with 16 layers and resnet with 50 layers to predict age. we trained and generated the results of the three networks independently, and generated an ensemble by taking their average, with the formula ',\n",
       " 'for age prediction, we replaced the last layer of the three cnns with one node without any activation functions, and we used the mean absolute difference between the predicted age and actual age as the loss function:',\n",
       " 'during training of deep cnn models, we reflected all samples from left to right, which can increase the amount of training data.',\n",
       " 'to validate the prediction ability for age using 3d facial images, we divided all our 4,719 samples into 10 groups randomly for 10-fold cross-validation. during each evaluation process, the model was trained with eight of the ten groups as a training set, hyperparameters were determined with one of the remaining groups as the validation set and the predictive performance was tested on the last group as the test set. when evaluating the models with independent datasets, we used all ten models generated from the ten cross-validation to test the datasets independently, and used the average performance level as the final prediction capability.',\n",
       " 'we drew 10 ml of total fasting blood from each participant in the early morning. plasma and pbmcs were separated using a sigma-aldrich histopaque-1077 kit. rna was extracted with trizol (invitrogen) using the protocol provided by the manufacturer. samples with rna integrity number (rin) > 8 were processed with the illumina truseq stranded total rna with ribo-zero sample preparation kit and then sequenced on an illumina hiseq 2000 machine according to the manufacturer’s instructions. paired-end reads (126\\u2009bp) were mapped to the grch38 reference human genome using star9 version 2.4.0d.',\n",
       " 'only reads with a unique match to the reference genome were kept. protein-coding gene quantification was performed using gencode version 24 annotation',\n",
       " '), version 2.3.5) was used to predict exonic circrna. human pbmc ribo-minus paired-end rna-seq raw data were mapped to the hg38 human reference genome using tophat-fusion (implemented in tophat version 2.1.1), and then were parsed by circexplorer2 to obtain circrna back spliced junction reads. circrna read counts from all samples were merged together and scaled to tpm.',\n",
       " ' scaled) were combined into one matrix as the input. the leave-one-out (loo) method (predictors were trained using all but one sample and then used to predict the age of the left-out sample) was applied to obtain the age prediction of each sample. mad was calculated by the difference between predicted age and chronological age. saturation analysis was conducted by randomly selecting a designated percentage of all the samples and training the pls model on such samples, and then was evaluated using both mad and pcc.',\n",
       " 'to study age-independent associations of agediff, we corrected agediff by fitting to a polynomial model to age as follows, with span 0.75 and degree 2:',\n",
       " 'unlike other agediffs, there are significant differences between sexes in faceperceivedagediff and facecnnperceivedagediff (',\n",
       " 'a non-overlapping sliding-window approach was used to study the relationship between agediff sd and age. samples were sorted by age, and then a non-overlapping sliding window with different bin size (100 or 20 in jidong cohort, 20 or 10 in beijing cohort) was used to group samples and calculate mean of age and s.d. of agediffs in each sliding window.',\n",
       " ' were utilized for the term-enrichment test. kegg pathway genes were downloaded from the kegg database using the rest api. the cytokine genes were collected from the immport database',\n",
       " 'with the ‘pls’ package in r, the cell fraction or another feature was treated as the dependent variable, while the 3d facial images were treated as independent variables for pls regression. the loadings of the first two components weighed by the score of each component were combined and projected to the average 3d facial image synthesized from the whole cohort.',\n",
       " '. briefly, each of the lifestyle–gene expression–agediff relationships was tested separately to classify them into mediated by, consequential to or independent of gene expression. a causal inference met the following four criteria: (1) lifestyle and agediff were correlated; (2) lifestyle was associated with gene expression after adjusting for agediff; (3) gene expression was associated with agediff after adjusting for lifestyle; and (4) lifestyle was independent of agediff after adjusting for gene expression. to summarize the ',\n",
       " ') databases; (2) human transcription factors, enzymes, transporters, receptors and ion channels downloaded from the animal transcription factor database (',\n",
       " '. three-dimensional images and other metadata sensitive to personal identification cannot be publicized or shared according to our participant consent agreement. individual sequencing raw data, as they contain genetic information, will be available on request under the condition of approval of the ethics committee of shanghai institute of nutrition and health, chinese academy of sciences abiding china human genetic resource law. mapped read counts and fpkm expression values of coding genes from the rna-seq are deposited to the public repository node at ',\n",
       " 'methods',\n",
       " 'computer methods programs biomed.',\n",
       " 'nat. methods',\n",
       " 'liu, y. et al. epigenome-wide association data implicate dna methylation as an intermediary of genetic risk in rheumatoid arthritis. ',\n",
       " 'ahmed, z. et al. accelerated lipofuscinosis and ubiquitination in granulin knockout mice suggest a role for progranulin in successful aging. ',\n",
       " 'elkabets, m. et al. human tumors instigate granulin-expressing hematopoietic cells that promote malignancy by activating stromal fibroblasts in mice. ',\n",
       " 'chitramuthu, b. p., bennett, h. p. j. & bateman, a. progranulin: a new avenue towards the understanding and treatment of neurodegenerative disease. ',\n",
       " 'ruiz, r. et al. sterol regulatory element-binding protein-1 (srebp-1) is required to regulate glycogen synthesis and gluconeogenic gene expression in mouse liver. ',\n",
       " 'oishi, y. et al. srebp1 contributes to resolution of pro-inflammatory tlr4 signaling by reprogramming fatty acid metabolism. ',\n",
       " 'schoenborn, n. l. et al. preferred clinician communication about stopping cancer screening among older us adults: results from a national survey. ',\n",
       " 'world medical association inc declaration of helsinki. ethical principles for medical research involving human subjects. ',\n",
       " 'trapnell, c. et al. differential gene and transcript expression analysis of rna-seq experiments with tophat and cufflinks. ',\n",
       " 'subramanian, a. et al. gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. ',\n",
       " 'bhattacharya, s. et al. immport, toward repurposing of open access immunological assay data for translational and clinical research. ',\n",
       " 'coppé, j.-p., desprez, p.-y., krtolica, a. & campisi, j. the senescence-associated secretory phenotype: the dark side of tumor suppression. ',\n",
       " 'this work was supported by grants from the national natural science foundation of china (91749205), china ministry of science and technology (2016yfe0108700) and shanghai municipal science and technology major project (2017shzdzx01) to j.-d.j.h.',\n",
       " 'cas key laboratory of computational biology, cas-mpg partner institute for computational biology, shanghai institute of nutrition and health, chinese academy of sciences center for excellence in molecular cell science, collaborative innovation center for genetics and developmental biology, shanghai institutes for biological sciences, chinese academy of sciences, shanghai, china',\n",
       " 'xian xia,\\xa0xingwei chen,\\xa0gang wu,\\xa0fang li,\\xa0yiyang wang,\\xa0yang chen,\\xa0mingxu chen,\\xa0xinyu wang,\\xa0weiyang chen,\\xa0bo xian,\\xa0weizhong chen,\\xa0yaqiang cao,\\xa0chi xu,\\xa0wenxuan gong,\\xa0guoyu chen,\\xa0donghong cai,\\xa0yizhen yan\\xa0&\\xa0jing-dong j. han',\n",
       " 'peking-tsinghua center for life sciences, academy for advanced interdisciplinary studies, center for quantitative biology (cqb), peking university, beijing, china',\n",
       " 'xian xia,\\xa0xingwei chen,\\xa0yiyang wang,\\xa0yang chen,\\xa0mingxu chen,\\xa0xinyu wang,\\xa0wenxuan gong,\\xa0guoyu chen,\\xa0donghong cai,\\xa0yizhen yan,\\xa0kangping liu\\xa0&\\xa0jing-dong j. han',\n",
       " 'department of hepatic surgery, eastern hepatobiliary surgery hospital, second military medical university, shanghai, china',\n",
       " 'biomedical cybernetics group, biotechnology center (biotec), center for molecular and cellular bioengineering (cmcb), center for systems biology dresden (csbd), cluster of excellence physics of life (pol), department of physics, technische universität dresden, dresden, germany',\n",
       " 'center for complex network intelligence (ccni) at the tsinghua laboratory of brain and intelligence (thbi) and department of bioengineering, tsinghua university, beijing, china',\n",
       " 'clinical research institute, shanghai general hospital, shanghai jiao tong university school of medicine, shanghai, china',\n",
       " 'j.-d.j.h. conceived and designed the study and analyses. y.z. set up the cohort and designed and collected baseline data. c.v.c., together with j.d.j.h., conceived the paradigm-shift idea to train the cnn on perceived age instead of chronological age for an ai-based perceived-age predictor. x.x. and x.c. analysed the data, with help from y.w. and c.x. y. cao, w. wei, g.c. y.y., x.x., k.l. and d.c. helped in collecting and preprocessing data. n.q., x.z. and j.j. helped to set up gpu, ai systems and training. g.w. and f.l. performed the pbmc-isolation and rna-extraction experiments. weiyang chen provided faceplsage. b.x., weizhong chen, y. cao, c.x. and w.g. helped to recruit the beijing cohorts. g.c. quantified the wrinkle and symmetry on faces. y. chen analysed circrna. x.w., m.c. and d.c. helped with data analysis. x.x., x.c., j.d.j.h, c.v.c., k.z., b.k.k. and w. wang wrote the manuscript. all authors contributed to preparation of the manuscript. g.w., f.l. and y.w. contributed equally.',\n",
       " ' springer nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.',\n",
       " ', deep learning performance in training, validation and testing datasets for age prediction. average loss (mean average difference (mad), upper panel) and accuracy (pearson correlation coefficient (pcc), lower panel) were plotted over training epochs. one epoch indicates the network weights updates over the whole training dataset for one time. ',\n",
       " ', overlap between facecnnage, facecnnperceivedage, faceperceivedage, and faceplsage in younger (left), normal (middle), and older (right) samples. the lower table shows the one-tailed fisher’s exact test p-values with light red indicate p < 0.05. ',\n",
       " ', independent validation of facecnnage (c) and facecnnperceivedage (d) on 332 facial images collected in beijing, 2012 (left) and 358 facial images collected in beijing, 2015 (right).',\n",
       " ', the standard deviation of randomly guess a number between 20–85 (n=4719, the boxes show 25%, 50% and 75% quantile and whiskers show maximum and minimum value). ',\n",
       " ', relationship between age and the standard deviation of four agediffs with bin size as 20 in jidong cohort. data are presented as mean +/- sd. ',\n",
       " ', heatmap of aging-related facial features, health parameters and rnas in beijing (2012) cohort sorted by increasing chronological age (pcc with age, fdr < 0.05). features were ranked by pcc from low to high (alb: albumin, a/g: albumin/ globulin, tp: total protein, ggt: glutamyl transpeptidase, alp: alkline phosphatase, crea: creatinine, cho: total cholesterol). ',\n",
       " ', mean absolute difference (mad) (top panel), pearson correlation coefficient (pcc) (bottom panel) saturation analysis and correlation against chronological age of transcriptomes pls age prediction for all the samples (',\n",
       " ', enriched go biological processes terms of pls top 10% (upper) or 20% (lower) loading genes. p values are derived from hypergeometric test (methods). ',\n",
       " ', overlap between faceplsage, facecnnage, rnaplsage, and facecnnperceivedage in younger (left), normal (middle), and older (right) samples. the lower table shows the one-tailed fisher’s exact test p-values with light red highlight indicate p < 0.05.',\n",
       " ', cytokines (left panels) and antigen processing and presentation (right panels) enrichment scores as a function of four agediffs. p values are derived from permutation test (methods). ',\n",
       " ', association of rna-seq deconvoluted cell type fractions and agediffs (* p<0.1, ** p<0.05, *** p<0.01 derived from two-sided t test, and * benjamini-hochberg correction derived fdr < 0.1).',\n",
       " ', the heatmap of expressed lncrnas (fpkm > 2) significantly related to chronological age (fdr < 0.1). the samples (columns) were sorted by age and lncrnas were sorted by pcc of expression to age from high to low. ',\n",
       " ', the heatmap of expressed circrnas (tpm > 2) significantly related to chronological age (fdr < 0.1). the samples (columns) were sorted by age and circrnas were sorted by pcc of expression to age from high to low. ',\n",
       " ', top three enriched terms for parent genes of age-up (top) and age-down circrnas. p values are derived from hypergeometric test (methods). ',\n",
       " 'results',\n",
       " 'discussion',\n",
       " 'methods',\n",
       " 'methods',\n",
       " 'computer methods programs biomed.',\n",
       " 'nat. methods',\n",
       " 'liu, y. et al. epigenome-wide association data implicate dna methylation as an intermediary of genetic risk in rheumatoid arthritis. ',\n",
       " 'ahmed, z. et al. accelerated lipofuscinosis and ubiquitination in granulin knockout mice suggest a role for progranulin in successful aging. ',\n",
       " 'elkabets, m. et al. human tumors instigate granulin-expressing hematopoietic cells that promote malignancy by activating stromal fibroblasts in mice. ',\n",
       " 'chitramuthu, b. p., bennett, h. p. j. & bateman, a. progranulin: a new avenue towards the understanding and treatment of neurodegenerative disease. ',\n",
       " 'ruiz, r. et al. sterol regulatory element-binding protein-1 (srebp-1) is required to regulate glycogen synthesis and gluconeogenic gene expression in mouse liver. ',\n",
       " 'oishi, y. et al. srebp1 contributes to resolution of pro-inflammatory tlr4 signaling by reprogramming fatty acid metabolism. ',\n",
       " 'schoenborn, n. l. et al. preferred clinician communication about stopping cancer screening among older us adults: results from a national survey. ',\n",
       " 'world medical association inc declaration of helsinki. ethical principles for medical research involving human subjects. ',\n",
       " 'trapnell, c. et al. differential gene and transcript expression analysis of rna-seq experiments with tophat and cufflinks. ',\n",
       " 'subramanian, a. et al. gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. ',\n",
       " 'bhattacharya, s. et al. immport, toward repurposing of open access immunological assay data for translational and clinical research. ',\n",
       " 'coppé, j.-p., desprez, p.-y., krtolica, a. & campisi, j. the senescence-associated secretory phenotype: the dark side of tumor suppression. ',\n",
       " 'var s=document.getelementsbytagname(\"script\")[0],p=document.createelement(\"script\");p.async=\"async\";p.src=\"https://scripts.webcontentassessor.com/scripts/93dabb8d80079a87fec7bb6f67b807fce90e1688f8957ad7ad152bfd58ea01c2\";s.parentnode.insertbefore(p,s);',\n",
       " 'var scripts=document.head.queryselectorall(\"script[async]\");array.prototype.slice.call(scripts).foreach(function(a){-1<a.src.indexof(\"gtm.js\")&&(console.log(\"the gtm script has src url:\"),console.log(a.src))});console.log(\"the ga4serverurl is:\");console.log(google_tag_manager[\"gtm-mrvxshq\"].macro(28));']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cull_text = []\n",
    "\n",
    "for x in keep_text:\n",
    "    if lbracketcount(x) and rbracketcount(x) and tagcount(x) and hashcount(x) and divcount(x) and linecount(x):\n",
    "        cull_text.append(x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "cull_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe7cae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_candidates = []\n",
    "\n",
    "for i, x in enumerate(keep_text):\n",
    "    \n",
    "    method_following = []\n",
    "    method_text = []\n",
    "    \n",
    "    if methodtitle(x) == True:\n",
    "        method_following = keep_text[i:] #list of all elements following and including methods title\n",
    "        \n",
    "        for i, x in enumerate(method_following):\n",
    "            if 'esult' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"result title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            elif 'iscussion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"discussion title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            elif 'onclusion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                #print(\"conclusion title!\")\n",
    "                method_text = method_following[:i]\n",
    "                break\n",
    "            else:\n",
    "                method_text = method_following\n",
    "        \n",
    "        method = ' '.join(method_text)\n",
    "        method_candidates.append(method)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "len(method_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c11199c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'methods ). similar patterns can be observed in the smaller beijing cohort. using broken-stick regression to pinpoint the breakpoint in the regression line, we found that all four agediffs predominately show a breakpoint peaking at middle age (extended data fig.  , heatmap of facial features in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1 in females and in males). features are ranked by pcc from lowest to highest in females and in males.  , a heatmap of health parameters in the jidong cohort sorted by increasing chronological age (pcc with age, fdr\\u2009<\\u20090.1 and |pcc| > 0.1). features are ordered as in  previous findings show that for human brain ageing transcriptomes, unlike those of very young or very old individuals, middle-aged individuals display high heterogeneity . we observed a similar pattern when all samples were visualized by a heatmap of age-related quantitative facial features (fig.  using the cohort that we collected from the beijing area (beijing 2012), we extracted and sequenced the ribo-minus rna from pbmcs of 280 individuals with matching 3d facial images (supplementary table  ). we performed plsr analysis on transcriptomes to predict chronological age in the same way that we did for 3d facial images ). like the s.d. of agediff detected by cnn in both the large and the small cohort, rnaplsagediff in this small cohort peaked at middle age (around 40–50 yr old) (extended data fig.  ). similarly, with broken-stick regression, we found that all four agediffs predominately showed a breakpoint peaking at middle age in the beijing 2012 cohort (extended data fig.  we also applied the facecnnage and facecnnperceivedage cnn models that learnt from the large jidong cohort to the 280 samples and compared them with plsr-derived models faceplsage (trained on the 280 3d facial images) and rnaplsage. despite being derived from different machine-learning algorithms, different training sets and different data types, the agediffs predicted by various models significantly correlated with each other, with higher correlation of rna with cnn-based models than with the facial pls model (supplementary table  ). moreover, the outliers identified by rnaplsage significantly overlapped with the two cnn-based models in both fast and slow agers ( to identify the blood transcriptome differences associated with differential facial-ageing rates, we compared the kyoto encyclopedia of genes and genomes (kegg) pathways with gene expression that was correlated with at least two of the four estimated agediffs or with age (fig.  ). among pathways positively correlated with agediffs (fdr\\u2009<\\u20090.1), most were also positively correlated with age and inflammation, such as those linked to  , salmonella infection and shigellosis. and, similarly to age, agediffs tended to be consistently negatively correlated with biogenesis of ribosome and transfer rna. although all four agediffs were uncorrelated with chronological age after age correction, the molecular pathways that correlated with age and the four agediffs were largely consistent, indicating that the acceleration or deceleration of ageing detected by agediffs measurements is largely consistent with the ageing process at the pathway level. , distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on monocyte number derived from haematology analyser (two-sided  , distribution of faceplsagediff (left) or rnaplsagediff (middle) between the top and bottom 20% of samples on deconvoluted naive cd4 , distribution of facecnnagediff (left) or facecnnperceivedagediff (middle) between the top and bottom 10% of samples on mcv (two-sided  we then sought to further verify the agediff–inflammation association by examining whether inflammatory gene sets are positively related to agediffs. cytokine expression was positively related to faceplsagediff, rnaplsagediff and facecnnagediff (kolmogorov–smirnov (ks) test, nominal  \\u2009<\\u20090.05), but not facecnnperceivedagediff. innate-immunity-related genes, such as those linked to antigen processing and presentation, were positively related to all four agediffs (ks test, extended data fig.  ). in summary, all four agediffs were significantly positively related to inflammation and innate-immunity processes, which are also important features of ageing per se. , we found that the monocyte fraction was significantly positively associated with faceplsagediff, and the direction was consistent, although not significant, with its association with the other three agediffs across all individuals (extended data fig.  ). the plsr components 1 and 2 of 3d facial images regressed to monocyte fractions most significantly mapped to shrinkage of the forehead (fig.  ), which is in agreement with the negative association between inflammatory biomarkers, including interleukin-6, osteoprotegerin and tumour necrosis factor-α, and brain volume as measured by magnetic resonance imaging  t cells were consistently negatively associated with all four agediffs, although the association was significant for only faceplsagediff and for rnaplsagediff (fig.  ). the plsr components 1 and 2 of 3d facial changes to this cell fraction showed mapping to a reduction of under-eye puffiness (fig.  in addition, both cnn-derived agediffs were significantly associated with the mean corpuscular volume of erythrocytes (mcv), a known chronic-illness indicator that is positively associated with ageing , between more-extreme samples (compared between the top and bottom 10% of samples; the association was marginal if the comparison was between the top and bottom 20% of samples). the facial pattern was similar to that associated with the monocyte fraction (fig.  our parallel measurement of lifestyles, blood cell transcriptome and agediffs for the same individuals in the beijing 2012 cohort offered an opportunity to examine the molecular mediators of the impact of lifestyle on facial agediff. we thus generated a tripartite network of lifestyle–transcriptome–agediff using a causal-inference framework  querying all transcriptome clusters, encode transcription factors, signalling and epigenetic factors and cytokines as potential mediators ( methods  was also inferred to be a mediator by which alcohol drinking (measured in ‘drunkenness days per week’) increased facecnnagediff. zz-type zinc-finger-containing protein 3 (encoded by  ), involved in chromatin organization, was inferred to be the mediator of yoghurt’s negative effect on facecnnagediff, and to lower   to negatively affect facecnnperceivedagediff. rnaplsagediff had its own separate subnetwork, in which consumption of stem and root crops (for example, potato) were positively related to rnaplsagediff, mediated by tumour protein p53 (encoded by  \\u2009<\\u20090.05 and fdr\\u2009<\\u20090.1). interestingly, semaphorin is a chemokine, while granulin (cleaved from grn, the granulin precursor) is also a secreted factor playing important roles in the development of the central nervous system . overall, the network can be partitioned into four modules on the basis of connectivity density: the first, mostly affecting faceplsagediff and partially affecting facecnnagediff, is enriched for proteolysis; the second, mostly affecting facecnnagediff, is enriched for glycoprotein, protease and lysosome; the third, mostly affecting facecnnagediff, is enriched for transmembrane proteins and zinc-finger transcription factors; and the fourth, exclusively affecting rnaplsagediff, is enriched for response to antibiotics and ultraviolet radiation (fig.  methods ) from lifestyle factors to agediffs via molecular mediators (transcription factors, cytokines, regulatory genes and commonly expressed non-coding rnas) among all samples ( ribo-minus rna sequencing (rna-seq) allowed us to simultaneously examine coding and non-coding rna changes during human ageing. we found 935 long non-coding rnas (lncrnas) that were commonly expressed (fragments per kilobase of transcript per million reads mapped (fpkm)\\u2009>\\u20092) in at least a quarter of samples. among them, 62 and 210 were up- and downregulated by age, respectively (fdr\\u2009<\\u20090.1) (extended data fig.  ). we found 5,002 circular rnas (circrnas) commonly expressed (transcripts per million (tpm)\\u2009>\\u20092) in at least a quarter of samples. among them, 41 and 8 were up- and downregulated with age, respectively (fdr\\u2009<\\u20090.1) (extended data fig.  , total circrna level shows no significant association with agediffs, implicating it to more likely be a consequence of ageing. we applied the same causal-inference approach to only the outliers defined by all four agediffs because we assumed that some associations might be significant only in more-extreme samples. indeed, we found a very different set of associations among the outliers as compared with those of the whole cohort. ice-cream intake was inferred to be positively related to faceplsagediff through two circrnas and to facecnnagediff through ae binding protein 1 (encoded by  ). yoghurt was negatively related to facecnnagediff and facecnnperceivedagediff through a few lncrnas and circrnas among the outliers ( to facilitate the full utilization of this dataset, we developed the hub-fi database for querying and visualizing health status and transcript changes associated with facial-ageing features, and the impacts of different lifestyles.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_candidates[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70398639",
   "metadata": {},
   "source": [
    "# scrape urls - loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74149bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_doi = doi_list[1950:2000]\n",
    "#test_pmid = pmid_list[1950:2000]\n",
    "#test_url = url_list[1950:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b811d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditions\n",
    "\n",
    "def alphachars(x): return sum(a.isalpha() for a in x) > 4\n",
    "def charchar(x): return bool(re.match(r\".*[a-zA-Z][a-zA-Z].*\", x)) == True\n",
    "def istitle(x): return ((('method' in x) or ('material' in x) or ('result' in x) or ('discussion' in x) or ('conclusion' in x)\n",
    "                        or ('references' in x) or ('bibliography' in x)) \n",
    "                        and (sum(l.isalpha() for l in x) < 30))\n",
    "def istextblock(x): return sum(l.isalpha() for l in x) > 100\n",
    "def methodtitle(x): return ((('method' in x)) and (sum(l.isalpha() for l in x)<30)) #or ('material' in x)\n",
    "\n",
    "## symbol cleaning\n",
    "\n",
    "def lbracketcount(x): return x.count('{') < 4\n",
    "def rbracketcount(x): return x.count('}') < 4\n",
    "def tagcount(x): return x.count('\".\"') < 4\n",
    "def hashcount(x): return x.count('#') < 4\n",
    "def divcount(x): return x.count('</') < 4\n",
    "def linecount(x): return x.count('||') < 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab985aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318aa3a54b8f4544a6847349fe2a086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\anaconda3\\envs\\scraper\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: session deleted because of page crash\nfrom tab crashed\n  (Session info: chrome=102.0.5005.63)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0073D953+2414931]\n\tOrdinal0 [0x006CF5E1+1963489]\n\tOrdinal0 [0x005BC580+836992]\n\tOrdinal0 [0x005AD517+775447]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005ACEBC+773820]\n\tOrdinal0 [0x005C2197+860567]\n\tOrdinal0 [0x00614B55+1198933]\n\tOrdinal0 [0x006042B6+1131190]\n\tOrdinal0 [0x005DE860+976992]\n\tOrdinal0 [0x005DF756+980822]\n\tGetHandleVerifier [0x009ACC62+2510274]\n\tGetHandleVerifier [0x0099F760+2455744]\n\tGetHandleVerifier [0x007CEABA+551962]\n\tGetHandleVerifier [0x007CD916+547446]\n\tOrdinal0 [0x006D5F3B+1990459]\n\tOrdinal0 [0x006DA898+2009240]\n\tOrdinal0 [0x006DA985+2009477]\n\tOrdinal0 [0x006E3AD1+2046673]\n\tBaseThreadInitThunk [0x75DEFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77407A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77407A4E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8924\\3471445015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m## set up chrome driver and get link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'C:\\chromedriver\\chromedriver.exe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m## get page source and xpath extract all body text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\scraper\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: session deleted because of page crash\nfrom tab crashed\n  (Session info: chrome=102.0.5005.63)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0073D953+2414931]\n\tOrdinal0 [0x006CF5E1+1963489]\n\tOrdinal0 [0x005BC580+836992]\n\tOrdinal0 [0x005AD517+775447]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005AC565+771429]\n\tOrdinal0 [0x005ACB68+772968]\n\tOrdinal0 [0x005ACAF8+772856]\n\tOrdinal0 [0x005B2D5A+798042]\n\tOrdinal0 [0x005ADD3B+777531]\n\tOrdinal0 [0x005AE265+778853]\n\tOrdinal0 [0x005AE04F+778319]\n\tOrdinal0 [0x005AD646+775750]\n\tOrdinal0 [0x005ACEBC+773820]\n\tOrdinal0 [0x005C2197+860567]\n\tOrdinal0 [0x00614B55+1198933]\n\tOrdinal0 [0x006042B6+1131190]\n\tOrdinal0 [0x005DE860+976992]\n\tOrdinal0 [0x005DF756+980822]\n\tGetHandleVerifier [0x009ACC62+2510274]\n\tGetHandleVerifier [0x0099F760+2455744]\n\tGetHandleVerifier [0x007CEABA+551962]\n\tGetHandleVerifier [0x007CD916+547446]\n\tOrdinal0 [0x006D5F3B+1990459]\n\tOrdinal0 [0x006DA898+2009240]\n\tOrdinal0 [0x006DA985+2009477]\n\tOrdinal0 [0x006E3AD1+2046673]\n\tBaseThreadInitThunk [0x75DEFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77407A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77407A4E+238]\n"
     ]
    }
   ],
   "source": [
    "methods_list = []\n",
    "\n",
    "for url in tqdm(url_list):\n",
    "    \n",
    "    ## refresh lists\n",
    "    keep_text = []\n",
    "    cull_text = []\n",
    "    method_candidates = []\n",
    "    \n",
    "    ## set up chrome driver and get link\n",
    "    driver = webdriver.Chrome(options=options, executable_path=r'C:\\chromedriver\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "\n",
    "    ## get page source and xpath extract all body text\n",
    "    page = driver.page_source\n",
    "    tree = html.fromstring(page)\n",
    "    body_text = tree.xpath('//body/descendant-or-self::*/text()')\n",
    "    \n",
    "    ## stop driver\n",
    "    driver.quit()\n",
    "    \n",
    "    ## cleaning and convert to lower case\n",
    "    body_text = [x.replace('\\n', ' ') for x in body_text]\n",
    "    body_text = [x.replace('    ', ' ') for x in body_text]\n",
    "    body_text = [x.replace('   ', ' ') for x in body_text]\n",
    "    body_text = [x.replace('  ', ' ') for x in body_text]\n",
    "    body_text = [x.lower() for x in body_text]\n",
    "    \n",
    "    ## keep list elements if conforms to conditions\n",
    "    for x in body_text:\n",
    "        if (charchar(x) and alphachars(x)) and (istitle(x) or istextblock(x)):\n",
    "            keep_text.append(x)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for x in keep_text:\n",
    "        if (lbracketcount(x) and rbracketcount(x) and tagcount(x) and hashcount(x) and divcount(x) and linecount(x)):\n",
    "            cull_text.append(x)\n",
    "        else:\n",
    "            continue\n",
    "                 \n",
    "    #########\n",
    "    #########\n",
    "    #########\n",
    "    \n",
    "    ## now pull out methods titles and text that follows, up to first occurance of 'results/discussion/conclusion title'\n",
    "    ## all candidates joined as strings, and held in method_candidates\n",
    "    \n",
    "    for i, x in enumerate(cull_text):    \n",
    "        method_following = [] #list of all elements following and including methods title\n",
    "        method_only = [] #list of all elements inbetween 'method' title and next section title\n",
    "\n",
    "        if methodtitle(x) == True:\n",
    "            method_following = cull_text[i:] \n",
    "            \n",
    "            for i, x in enumerate(method_following):\n",
    "                if 'result' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"result title!\")\n",
    "                    method_only = method_following[:i]\n",
    "                    break\n",
    "                elif 'discussion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"discussion title!\")\n",
    "                    method_only = method_following[:i]                \n",
    "                    break\n",
    "                elif 'conclusion' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"conclusion title!\")\n",
    "                    method_only = method_following[:i]               \n",
    "                    break\n",
    "                elif 'references' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"reference title!\")\n",
    "                    method_only = method_following[:i]            \n",
    "                    break\n",
    "                elif 'bibliography' in x and sum(l.isalpha() for l in x) <  30:\n",
    "                    #print(\"reference title!\")\n",
    "                    method_only = method_following[:i]                 \n",
    "                    break                      \n",
    "                else:\n",
    "                    method_only = method_following #if none of these are found to end text block, then take the whole text block\n",
    "    \n",
    "            method_string = ' '.join(method_only)        \n",
    "            method_candidates.append(method_string)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    methods_list.append(method_candidates) # each paper now has a list of method candidates (each is a string)\n",
    "\n",
    "print(len(methods_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8af1794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2440"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(methods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08454ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_doi_list = doi_list[0:2440]\n",
    "temp_pmid_list = pmid_list[0:2440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e92a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'doi':temp_doi_list, 'pmid':temp_pmid_list, 'methods_candidates':methods_list})\n",
    "\n",
    "results_df.to_csv('output/html_parse_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dbd73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df = pd.DataFrame(results_df['methods_candidates'].tolist())\n",
    "explode_df['pmid'] = temp_pmid_list\n",
    "explode_df.to_csv('output/html_explode_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872a12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbe8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165daaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8be365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005668d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
